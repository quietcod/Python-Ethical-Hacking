#!/usr/bin/env python3
"""
Recon Wrapper - All-in-One Consolidated Version
Comprehensive Reconnaissance Tool with all modules embedded
Author: Consolidated from modular version
Date: 2025-08-18

A comprehensive reconnaissance wrapper that integrates multiple scanning tools
and generates detailed reports for penetration testing and security assessments.

Features:
    ‚Ä¢ Port Scanning (Nmap, Masscan, Hybrid)
    ‚Ä¢ Subdomain Enumeration (multi-tool, DNSSEC, zone transfer)
    ‚Ä¢ Web Application Scanning (Nikto, tech stack, CMS, API fuzzing)
    ‚Ä¢ SSL/TLS Analysis (Heartbleed, POODLE, BEAST, DROWN, weak ciphers)
    ‚Ä¢ OSINT Collection (DNS, Wayback Machine, GitHub dorking)
    ‚Ä¢ Screenshot Capture
    ‚Ä¢ Advanced Directory Discovery (gobuster, ffuf, feroxbuster)
    ‚Ä¢ Vulnerability Scanning (CVE mapping, vulners, vulscan)
    ‚Ä¢ Risk Scoring and Assessment (CVSS v3.1)
    ‚Ä¢ Compliance Mapping (OWASP Top 10, NIST, PCI DSS, ISO27001)
    ‚Ä¢ Multi-format Reporting (CSV, Excel, Word, PPTX, PDF)
    ‚Ä¢ Historical Baseline Tracking
    ‚Ä¢ Evidence Collection (screenshots, packets, logs)
    ‚Ä¢ API Endpoint Discovery and Fuzzing
    ‚Ä¢ Technology Stack Detection (Wappalyzer-style)
    ‚Ä¢ Advanced Error Handling and Fallbacks
    ‚Ä¢ Production-ready for authorized security testing
"""

import argparse
import ipaddress
import os
import sys
import json
import subprocess
import threading
import time
import csv
from datetime import datetime
from pathlib import Path
import xml.etree.ElementTree as ET
import re
import requests
import logging
from concurrent.futures import ThreadPoolExecutor
import socket
import ssl
import hashlib
import base64
from urllib.parse import urlparse, urljoin
import dns.resolver
try:
    import dns.query
    import dns.zone
    import dns.exception
    HAS_DNS_QUERY = True
except ImportError:
    HAS_DNS_QUERY = False

# Advanced reporting dependencies
try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    import plotly.offline as pyo
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

try:
    from jinja2 import Template, Environment, FileSystemLoader
    HAS_JINJA2 = True
except ImportError:
    HAS_JINJA2 = False

try:
    import sqlite3
    HAS_SQLITE = True
except ImportError:
    HAS_SQLITE = False

try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib import colors
    from reportlab.graphics.shapes import Drawing
    from reportlab.graphics.charts.piecharts import Pie
    from reportlab.graphics.charts.barcharts import VerticalBarChart
    HAS_REPORTLAB = True
except ImportError:
    HAS_REPORTLAB = False

try:
    import weasyprint
    HAS_WEASYPRINT = True
except ImportError:
    HAS_WEASYPRINT = False

# Try to import optional dependencies
try:
    import whois
    HAS_WHOIS = True
except ImportError:
    HAS_WHOIS = False
    
try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    HAS_SELENIUM = True
except ImportError:
    HAS_SELENIUM = False

try:
    import OpenSSL
    import cryptography
    from cryptography import x509
    from cryptography.hazmat.backends import default_backend
    from cryptography.hazmat.primitives import serialization, hashes
    HAS_CRYPTO = True
except ImportError:
    HAS_CRYPTO = False

# Progress tracking and enhanced UI dependencies
try:
    from tqdm import tqdm
    import colorama
    from colorama import Fore, Back, Style
    colorama.init()  # Initialize colorama for Windows compatibility
    HAS_PROGRESS = True
except ImportError:
    HAS_PROGRESS = False

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False


# ============================== RESOURCE MONITOR ==============================
class ResourceMonitor:
    """Monitor system resources during reconnaissance"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.monitoring = False
        self.monitor_thread = None
        
    def get_system_stats(self):
        """Get current system resource usage"""
        if not HAS_PSUTIL:
            return {
                'cpu_percent': 0,
                'memory_percent': 0,
                'memory_available_mb': 0,
                'status': 'psutil_unavailable'
            }
        
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            return {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'memory_available_mb': memory.available / (1024 * 1024),
                'status': 'active'
            }
        except Exception as e:
            self.logger.warning(f"Error getting system stats: {str(e)}")
            return {
                'cpu_percent': 0,
                'memory_percent': 0,
                'memory_available_mb': 0,
                'status': 'error'
            }
    
    def check_resource_limits(self):
        """Check if system is within resource limits"""
        stats = self.get_system_stats()
        
        if stats['status'] != 'active':
            return True  # Assume OK if monitoring unavailable
        
        cpu_limit = self.config.get('performance', 'cpu_limit_percent', 80)
        memory_limit = self.config.get('performance', 'memory_limit_mb', 1024)
        
        # Check CPU usage
        if stats['cpu_percent'] > cpu_limit:
            self.logger.warning(f"High CPU usage: {stats['cpu_percent']:.1f}% (limit: {cpu_limit}%)")
            return False
        
        # Check available memory
        if stats['memory_available_mb'] < memory_limit:
            self.logger.warning(f"Low memory: {stats['memory_available_mb']:.1f}MB available (limit: {memory_limit}MB)")
            return False
        
        return True
    
    def wait_for_resources(self, max_wait=60):
        """Wait for system resources to become available"""
        if not self.config.get('performance', 'resource_monitoring', True):
            return True
        
        start_time = time.time()
        while time.time() - start_time < max_wait:
            if self.check_resource_limits():
                return True
            
            self.logger.info("Waiting for system resources to become available...")
            time.sleep(5)
        
        self.logger.warning("Resource limits still exceeded after waiting, proceeding anyway")
        return False


# ============================== PROGRESS TRACKER ==============================
class ProgressTracker:
    """Real-time progress tracking and status updates for reconnaissance modules"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.start_time = time.time()
        self.current_module = ""
        self.current_operation = ""
        self.progress_bars = {}
        self.module_timings = {}
        self.total_modules = 0
        self.completed_modules = 0
        self.discoveries = []
        
        # Enable/disable features based on availability
        self.use_colors = HAS_PROGRESS and self.config.get('ui', 'colors', True)
        self.use_progress_bars = HAS_PROGRESS and self.config.get('ui', 'progress_bars', True)
        
        # Color scheme
        if self.use_colors:
            self.colors = {
                'info': Fore.CYAN,
                'success': Fore.GREEN,
                'warning': Fore.YELLOW,
                'error': Fore.RED,
                'highlight': Fore.MAGENTA,
                'reset': Style.RESET_ALL,
                'bold': Style.BRIGHT
            }
        else:
            self.colors = {key: '' for key in ['info', 'success', 'warning', 'error', 'highlight', 'reset', 'bold']}
    
    def start_scan(self, target, scan_type, estimated_modules=8):
        """Initialize scan progress tracking"""
        self.target = target
        self.scan_type = scan_type
        self.total_modules = estimated_modules
        self.start_time = time.time()
        self.completed_modules = 0
        
        print(f"\n{self.colors['bold']}{self.colors['info']}üöÄ Starting {scan_type} reconnaissance on: {target}{self.colors['reset']}")
        print(f"{self.colors['info']}üìä Estimated modules: {estimated_modules}{self.colors['reset']}")
        print(f"{self.colors['info']}‚è∞ Started at: {datetime.now().strftime('%H:%M:%S')}{self.colors['reset']}\n")
    
    def start_module(self, module_name, description="", estimated_tasks=None):
        """Start tracking a reconnaissance module"""
        self.current_module = module_name
        self.module_start_time = time.time()
        
        # Calculate overall progress
        overall_progress = (self.completed_modules / self.total_modules) * 100 if self.total_modules > 0 else 0
        
        print(f"{self.colors['highlight']}üìç Module {self.completed_modules + 1}/{self.total_modules}: {module_name}{self.colors['reset']}")
        if description:
            print(f"   {self.colors['info']}‚ÑπÔ∏è  {description}{self.colors['reset']}")
        print(f"   {self.colors['info']}üìà Overall Progress: {overall_progress:.1f}%{self.colors['reset']}")
        
        # Create progress bar for this module if enabled and estimated tasks provided
        if self.use_progress_bars and estimated_tasks:
            self.progress_bars[module_name] = tqdm(
                total=estimated_tasks,
                desc=f"   {module_name}",
                unit="task",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
                ncols=80
            )
    
    def update_operation(self, operation, details=""):
        """Update current operation within a module"""
        self.current_operation = operation
        
        if details:
            print(f"   {self.colors['info']}üîÑ {operation}: {details}{self.colors['reset']}")
        else:
            print(f"   {self.colors['info']}üîÑ {operation}{self.colors['reset']}")
    
    def update_progress(self, module_name=None, increment=1, message=""):
        """Update progress for current module"""
        module = module_name or self.current_module
        
        if module in self.progress_bars:
            self.progress_bars[module].update(increment)
            if message:
                self.progress_bars[module].set_postfix_str(message)
    
    def log_discovery(self, discovery_type, item, details=""):
        """Log a discovery (subdomain, port, vulnerability, etc.)"""
        discovery = {
            'type': discovery_type,
            'item': item,
            'details': details,
            'timestamp': datetime.now(),
            'module': self.current_module
        }
        self.discoveries.append(discovery)
        
        # Real-time discovery notification
        if details:
            print(f"   {self.colors['success']}‚ú® Found {discovery_type}: {item} ({details}){self.colors['reset']}")
        else:
            print(f"   {self.colors['success']}‚ú® Found {discovery_type}: {item}{self.colors['reset']}")
    
    def log_error(self, error_msg, suggestion="", error_type="warning"):
        """Log an error with user-friendly messaging and suggestions"""
        color = self.colors['error'] if error_type == 'error' else self.colors['warning']
        icon = "‚ùå" if error_type == 'error' else "‚ö†Ô∏è"
        
        print(f"   {color}{icon} {error_msg}{self.colors['reset']}")
        
        if suggestion:
            print(f"   {self.colors['info']}üí° Suggestion: {suggestion}{self.colors['reset']}")
    
    def complete_module(self, module_name=None, summary=""):
        """Mark a module as completed"""
        module = module_name or self.current_module
        
        # Close progress bar if exists
        if module in self.progress_bars:
            self.progress_bars[module].close()
            del self.progress_bars[module]
        
        # Calculate module execution time
        if hasattr(self, 'module_start_time'):
            execution_time = time.time() - self.module_start_time
            self.module_timings[module] = execution_time
        else:
            execution_time = 0
        
        self.completed_modules += 1
        
        print(f"   {self.colors['success']}‚úÖ {module} completed in {execution_time:.1f}s{self.colors['reset']}")
        if summary:
            print(f"   {self.colors['info']}üìã {summary}{self.colors['reset']}")
        print()  # Add spacing between modules
    
    def show_intermediate_summary(self):
        """Show intermediate scan summary"""
        elapsed = time.time() - self.start_time
        progress = (self.completed_modules / self.total_modules) * 100 if self.total_modules > 0 else 0
        
        print(f"\n{self.colors['highlight']}üìä SCAN PROGRESS SUMMARY{self.colors['reset']}")
        print(f"   {self.colors['info']}üéØ Target: {getattr(self, 'target', 'Unknown')}{self.colors['reset']}")
        print(f"   {self.colors['info']}‚è±Ô∏è  Elapsed: {elapsed:.0f}s{self.colors['reset']}")
        print(f"   {self.colors['info']}üìà Progress: {progress:.1f}% ({self.completed_modules}/{self.total_modules} modules){self.colors['reset']}")
        print(f"   {self.colors['info']}üîç Discoveries: {len(self.discoveries)} items found{self.colors['reset']}")
        
        # Show recent discoveries
        if self.discoveries:
            recent = self.discoveries[-3:]  # Show last 3 discoveries
            print(f"   {self.colors['success']}‚ú® Recent discoveries:{self.colors['reset']}")
            for disc in recent:
                print(f"      ‚Ä¢ {disc['type']}: {disc['item']}")
        print()
    
    def complete_scan(self):
        """Complete the scan and show final summary"""
        total_time = time.time() - self.start_time
        
        print(f"\n{self.colors['bold']}{self.colors['success']}üéâ RECONNAISSANCE COMPLETED!{self.colors['reset']}")
        print(f"{self.colors['info']}‚è±Ô∏è  Total Duration: {total_time:.1f}s ({total_time/60:.1f} minutes){self.colors['reset']}")
        print(f"{self.colors['info']}üìä Modules Completed: {self.completed_modules}/{self.total_modules}{self.colors['reset']}")
        print(f"{self.colors['info']}üîç Total Discoveries: {len(self.discoveries)}{self.colors['reset']}")
        
        # Show discovery breakdown
        if self.discoveries:
            discovery_types = {}
            for disc in self.discoveries:
                disc_type = disc['type']
                discovery_types[disc_type] = discovery_types.get(disc_type, 0) + 1
            
            print(f"\n{self.colors['highlight']}üìã Discovery Breakdown:{self.colors['reset']}")
            for disc_type, count in discovery_types.items():
                print(f"   {self.colors['success']}‚Ä¢ {disc_type}: {count}{self.colors['reset']}")
        
        # Show module timing breakdown
        if self.module_timings:
            print(f"\n{self.colors['highlight']}‚è±Ô∏è  Module Performance:{self.colors['reset']}")
            for module, duration in self.module_timings.items():
                print(f"   {self.colors['info']}‚Ä¢ {module}: {duration:.1f}s{self.colors['reset']}")
        
        print(f"\n{self.colors['info']}üìÅ Results have been saved to the output directory{self.colors['reset']}\n")
    
    def estimate_remaining_time(self):
        """Estimate remaining scan time based on completed modules"""
        if self.completed_modules == 0:
            return "Unknown"
        
        elapsed = time.time() - self.start_time
        avg_time_per_module = elapsed / self.completed_modules
        remaining_modules = self.total_modules - self.completed_modules
        estimated_remaining = avg_time_per_module * remaining_modules
        
        if estimated_remaining < 60:
            return f"{estimated_remaining:.0f}s"
        else:
            return f"{estimated_remaining/60:.1f}m"
    
    def cleanup(self):
        """Clean up progress bars and resources"""
        for pbar in self.progress_bars.values():
            pbar.close()
        self.progress_bars.clear()


# ============================== ERROR HANDLER ==============================
class ErrorHandler:
    """Enhanced error handling with user-friendly messages and suggestions"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.use_colors = HAS_PROGRESS and self.config.get('ui', 'colors', True)
        
        # Color scheme
        if self.use_colors:
            self.colors = {
                'error': Fore.RED,
                'warning': Fore.YELLOW,
                'info': Fore.CYAN,
                'success': Fore.GREEN,
                'reset': Style.RESET_ALL,
                'bold': Style.BRIGHT
            }
        else:
            self.colors = {key: '' for key in ['error', 'warning', 'info', 'success', 'reset', 'bold']}
    
    def handle_tool_missing(self, tool_name, module_name=""):
        """Handle missing external tools with helpful suggestions"""
        module_info = f" in {module_name}" if module_name else ""
        
        suggestions = {
            'nmap': "Install with: sudo apt-get install nmap (Ubuntu/Debian) or brew install nmap (macOS)",
            'masscan': "Install with: sudo apt-get install masscan or compile from source",
            'gobuster': "Install with: sudo apt-get install gobuster or go install github.com/OJ/gobuster/v3@latest",
            'nikto': "Install with: sudo apt-get install nikto",
            'sublist3r': "Install with: pip install sublist3r",
            'amass': "Download from: https://github.com/OWASP/Amass/releases",
            'ffuf': "Install with: go install github.com/ffuf/ffuf@latest",
            'feroxbuster': "Download from: https://github.com/epi052/feroxbuster/releases",
            'whatweb': "Install with: sudo apt-get install whatweb",
            'wafw00f': "Install with: pip install wafw00f",
            'sqlmap': "Install with: sudo apt-get install sqlmap or pip install sqlmap",
            'chromium': "Install with: sudo apt-get install chromium-browser",
            'chrome': "Download from: https://www.google.com/chrome/",
            'firefox': "Install with: sudo apt-get install firefox"
        }
        
        suggestion = suggestions.get(tool_name.lower(), f"Please install {tool_name} and ensure it's in your PATH")
        
        print(f"{self.colors['warning']}‚ö†Ô∏è  Tool '{tool_name}' not found{module_info}{self.colors['reset']}")
        print(f"{self.colors['info']}üí° {suggestion}{self.colors['reset']}")
        print(f"{self.colors['info']}üîÑ Continuing with available tools...{self.colors['reset']}\n")
        
        self.logger.warning(f"Tool {tool_name} not available{module_info}")
    
    def handle_network_error(self, target, error, module_name=""):
        """Handle network-related errors with helpful suggestions"""
        module_info = f" during {module_name}" if module_name else ""
        
        print(f"{self.colors['error']}‚ùå Network error for {target}{module_info}{self.colors['reset']}")
        print(f"{self.colors['info']}üîç Error details: {str(error)}{self.colors['reset']}")
        
        # Provide specific suggestions based on error type
        error_str = str(error).lower()
        if 'timeout' in error_str:
            print(f"{self.colors['info']}üí° Target may be slow to respond. Try increasing timeout values.{self.colors['reset']}")
        elif 'connection refused' in error_str:
            print(f"{self.colors['info']}üí° Target may be blocking connections or service is down.{self.colors['reset']}")
        elif 'name resolution' in error_str or 'name or service not known' in error_str:
            print(f"{self.colors['info']}üí° DNS resolution failed. Check if domain exists or try --offline mode.{self.colors['reset']}")
        elif 'permission denied' in error_str:
            print(f"{self.colors['info']}üí° Permission denied. Try running with sudo for raw socket operations.{self.colors['reset']}")
        else:
            print(f"{self.colors['info']}üí° Check network connectivity and target availability.{self.colors['reset']}")
        
        print(f"{self.colors['info']}üîÑ Continuing with next operation...{self.colors['reset']}\n")
        
        self.logger.error(f"Network error for {target}{module_info}: {error}")
    
    def handle_permission_error(self, operation, suggestion=""):
        """Handle permission-related errors"""
        print(f"{self.colors['error']}‚ùå Permission denied for: {operation}{self.colors['reset']}")
        
        if not suggestion:
            suggestion = "Try running with elevated privileges (sudo) or check file permissions"
        
        print(f"{self.colors['info']}üí° {suggestion}{self.colors['reset']}")
        print(f"{self.colors['info']}üîÑ Continuing with available operations...{self.colors['reset']}\n")
        
        self.logger.error(f"Permission error: {operation}")
    
    def handle_api_error(self, api_name, error, suggestion=""):
        """Handle API-related errors"""
        print(f"{self.colors['warning']}‚ö†Ô∏è  API error for {api_name}: {str(error)}{self.colors['reset']}")
        
        if not suggestion:
            if 'rate limit' in str(error).lower() or '429' in str(error):
                suggestion = "Rate limit exceeded. Wait before retrying or get premium API access."
            elif 'unauthorized' in str(error).lower() or '401' in str(error):
                suggestion = "Check API key configuration and permissions."
            elif 'forbidden' in str(error).lower() or '403' in str(error):
                suggestion = "API access forbidden. Verify API key has required permissions."
            else:
                suggestion = "Check API configuration and network connectivity."
        
        print(f"{self.colors['info']}üí° {suggestion}{self.colors['reset']}")
        print(f"{self.colors['info']}üîÑ Continuing without {api_name} data...{self.colors['reset']}\n")
        
        self.logger.warning(f"API error for {api_name}: {error}")
    
    def handle_file_error(self, operation, filepath, error):
        """Handle file operation errors"""
        print(f"{self.colors['error']}‚ùå File error during {operation}: {filepath}{self.colors['reset']}")
        print(f"{self.colors['info']}üîç Error: {str(error)}{self.colors['reset']}")
        
        # Provide specific suggestions
        if 'permission denied' in str(error).lower():
            print(f"{self.colors['info']}üí° Check file/directory permissions or run with appropriate privileges.{self.colors['reset']}")
        elif 'no space left' in str(error).lower():
            print(f"{self.colors['info']}üí° Insufficient disk space. Free up space or change output directory.{self.colors['reset']}")
        elif 'file not found' in str(error).lower():
            print(f"{self.colors['info']}üí° File or directory doesn't exist. Check path and create if necessary.{self.colors['reset']}")
        else:
            print(f"{self.colors['info']}üí° Check file path and permissions.{self.colors['reset']}")
        
        print(f"{self.colors['info']}üîÑ Continuing with available operations...{self.colors['reset']}\n")
        
        self.logger.error(f"File error during {operation} ({filepath}): {error}")
    
    def handle_module_failure(self, module_name, error, is_critical=False):
        """Handle module execution failures"""
        level = "critical" if is_critical else "non-critical"
        icon = "üí•" if is_critical else "‚ö†Ô∏è"
        color = self.colors['error'] if is_critical else self.colors['warning']
        
        print(f"{color}{icon} {level.title()} failure in {module_name}{self.colors['reset']}")
        print(f"{self.colors['info']}üîç Error: {str(error)}{self.colors['reset']}")
        
        if is_critical:
            print(f"{self.colors['error']}üí° This module is critical for the scan. Consider fixing the issue and rerunning.{self.colors['reset']}")
        else:
            print(f"{self.colors['info']}üí° This module is optional. Scan will continue with remaining modules.{self.colors['reset']}")
        
        print(f"{self.colors['info']}üîÑ Continuing with scan...{self.colors['reset']}\n")
        
        log_level = self.logger.error if is_critical else self.logger.warning
        log_level(f"Module failure in {module_name}: {error}")
    
    def handle_dependency_missing(self, dependency, feature, install_command=""):
        """Handle missing Python dependencies"""
        print(f"{self.colors['warning']}‚ö†Ô∏è  Missing dependency: {dependency}{self.colors['reset']}")
        print(f"{self.colors['info']}üö´ Feature disabled: {feature}{self.colors['reset']}")
        
        if install_command:
            print(f"{self.colors['info']}üí° Install with: {install_command}{self.colors['reset']}")
        else:
            print(f"{self.colors['info']}üí° Install with: pip install {dependency}{self.colors['reset']}")
        
        print(f"{self.colors['info']}üîÑ Continuing with available features...{self.colors['reset']}\n")
        
        self.logger.warning(f"Missing dependency {dependency} - {feature} disabled")
    
    def graceful_degradation(self, feature, alternative, reason=""):
        """Handle graceful feature degradation"""
        reason_text = f" ({reason})" if reason else ""
        
        print(f"{self.colors['warning']}‚¨áÔ∏è  Degrading feature: {feature}{reason_text}{self.colors['reset']}")
        print(f"{self.colors['info']}üîÑ Using alternative: {alternative}{self.colors['reset']}")
        print(f"{self.colors['info']}üí° For full functionality, address the underlying issue.{self.colors['reset']}\n")
        
        self.logger.info(f"Graceful degradation: {feature} -> {alternative}{reason_text}")
    
    def suggest_fixes(self, issue_type, context=""):
        """Provide general troubleshooting suggestions"""
        suggestions = {
            'slow_response': [
                "Increase timeout values in configuration",
                "Check network connectivity to target",
                "Consider using light scan mode for faster results",
                "Run during off-peak hours for better performance"
            ],
            'high_memory': [
                "Enable light mode to reduce memory usage",
                "Increase system swap space",
                "Close other applications to free memory",
                "Process targets one at a time instead of batch mode"
            ],
            'permission_issues': [
                "Run with appropriate privileges (sudo for raw sockets)",
                "Check file/directory permissions",
                "Ensure output directory is writable",
                "Verify tool installation permissions"
            ],
            'network_issues': [
                "Check internet connectivity",
                "Verify target is accessible",
                "Check firewall settings",
                "Try using VPN if geographically restricted"
            ]
        }
        
        if issue_type in suggestions:
            print(f"{self.colors['info']}üîß Troubleshooting suggestions for {issue_type}:{self.colors['reset']}")
            for i, suggestion in enumerate(suggestions[issue_type], 1):
                print(f"{self.colors['info']}   {i}. {suggestion}{self.colors['reset']}")
            print()


# ============================== CONFIG MANAGER ==============================
class ConfigManager:
    """Manages configuration settings for the recon wrapper"""
    
    def __init__(self, config_file=None):
        self.config = self.get_default_config()
        self.logger = logging.getLogger(__name__)
        
        if config_file:
            self.load_config(config_file)
        else:
            # Try to load default config file
            default_config = Path(__file__).parent / "config.json"
            if default_config.exists():
                self.load_config(str(default_config))
    
    def get_default_config(self):
        """Return default configuration settings"""
        return {
            "nmap": {
                "basic_flags": "-sV -sC --version-intensity 1",
                "aggressive_flags": "-A -T4 -O",
                "timeout": 300,
                "top_ports": 1000
            },
            "subdomains": {
                "tools": ["sublist3r", "assetfinder", "amass", "subfinder"],
                "wordlist": "/usr/share/wordlists/SecLists/Discovery/DNS/subdomains-top1million-110000.txt",
                "timeout": 600,
                "threads": 50
            },
            "web": {
                "nikto_flags": "-h",
                "whatweb_flags": "-a 3",
                "user_agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36",
                "timeout": 180,
                "follow_redirects": True
            },
            "wordpress": {
                "wpscan_flags": "--enumerate ap,at,u,dbe",
                "api_token": "",
                "timeout": 300
            },
            "ssl": {
                "testssl_flags": "--fast --parallel",
                "timeout": 120
            },
            "security": {
                "enabled": True,
                "ssl_analysis": True,
                "cert_transparency": True,
                "check_vulnerabilities": True,
                "security_headers": True,
                "cipher_analysis": True,
                "protocol_analysis": True,
                "max_subdomains": 5,
                "ports": [443, 8443, 9443, 8080, 8008, 8888],
                "timeout": 30
            },
            "osint": {
                "theharvester_sources": "baidu,bing,google,yahoo,duckduckgo",
                "shodan_api_key": "YOUR_SHODAN_API_KEY_HERE",
                "virustotal_api_key": "",
                "timeout": 240
            },
            "screenshots": {
                "tool": "gowitness", # or "aquatone"
                "resolution": "1440,900",
                "timeout": 30,
                "threads": 10
            },
            "general": {
                "threads": 10,
                "timeout": 300,
                "user_agent": "ReconWrapper/1.0",
                "delay": 1,
                "retries": 3,
                "offline_mode": False,
                "dns_server": "",
                "cidr_range": "",
                "dir_wordlist": ""
            },
            "mode": {
                "offline": False,
                "skip_online_modules": ["whois", "shodan", "crtsh", "sublist3r", "assetfinder", "subfinder", "theharvester"]
            },
            "dns": {
                "servers": []
            },
            "bruteforce": {
                "dir_wordlist": "/usr/share/wordlists/SecLists/Discovery/Web-Content/raft-medium-directories.txt",
                "dns_wordlist": "/usr/share/wordlists/SecLists/Discovery/DNS/subdomains-top1million-110000.txt",
                "rate_limit": 0,
                "threads": 10,
                "max_words": 5000
            },
            "performance": {
                "max_concurrent_modules": 1,  # Number of heavy modules to run simultaneously  
                "module_cooldown": 5,         # Seconds to wait between heavy modules
                "memory_limit_mb": 1024,      # Memory usage limit in MB (for future use)
                "cpu_limit_percent": 80,      # CPU usage limit percentage (for future use)
                "enable_staggering": True,    # Enable module staggering
                "light_mode": False,          # Reduce resource usage across all modules
                "resource_monitoring": True   # Monitor system resources during scan
            },
            "output": {
                "format": ["json", "txt", "xml"],
                "compress": False,
                "cleanup_raw": False
            },
            "reporting": {
                "advanced_enabled": True,
                "generate_pdf": True,
                "generate_risk_assessment": True,
                "generate_compliance": True,
                "generate_csv": True,
                "risk_scoring": {
                    "enabled": True,
                    "weights": {
                        "critical_vulns": 30,
                        "high_vulns": 20,
                        "medium_vulns": 10,
                        "low_vulns": 5,
                        "expired_certs": 25,
                        "weak_protocols": 15,
                        "missing_headers": 10,
                        "open_ports": 8,
                        "exposed_services": 12
                    }
                },
                "compliance_frameworks": ["owasp", "nist", "pci_dss"],
                "executive_summary": True,
                "technical_details": True,
                "visualization": {
                    "charts": True,
                    "interactive": False,
                    "export_images": False
                }
            },
            "ui": {
                "colors": True,                    # Enable colored output
                "progress_bars": True,             # Show progress bars during operations
                "real_time_updates": True,         # Display real-time status updates
                "discovery_notifications": True,   # Show discoveries as they happen
                "detailed_errors": True,          # Show detailed error messages with suggestions
                "intermediate_summaries": True,   # Show progress summaries during scan
                "module_timings": True,           # Display module execution times
                "eta_estimates": True             # Show estimated time remaining
            }
        }
    
    def load_config(self, config_file):
        """Load configuration from file"""
        try:
            with open(config_file, 'r') as f:
                if config_file.endswith('.json'):
                    user_config = json.load(f)
                elif config_file.endswith('.yaml') or config_file.endswith('.yml'):
                    if HAS_YAML:
                        user_config = yaml.safe_load(f)
                    else:
                        raise ValueError("YAML support not available")
                else:
                    raise ValueError("Unsupported config file format")
                
                # Merge with default config
                self.merge_config(user_config)
                self.logger.info(f"Loaded configuration from {config_file}")
                
        except FileNotFoundError:
            self.logger.warning(f"Config file not found: {config_file}")
        except Exception as e:
            self.logger.error(f"Error loading config: {str(e)}")
    
    def merge_config(self, user_config):
        """Merge user configuration with default configuration"""
        def merge_dict(default, user):
            for key, value in user.items():
                if key in default and isinstance(default[key], dict) and isinstance(value, dict):
                    merge_dict(default[key], value)
                else:
                    default[key] = value
        
        merge_dict(self.config, user_config)
    
    def get(self, section, key=None, default=None):
        """Get configuration value"""
        try:
            if key is None:
                return self.config.get(section, default)
            return self.config.get(section, {}).get(key, default)
        except Exception:
            return default
    
    def set(self, section, key, value):
        """Set configuration value"""
        if section not in self.config:
            self.config[section] = {}
        self.config[section][key] = value
    
    def save_config(self, config_file):
        """Save current configuration to file"""
        try:
            with open(config_file, 'w') as f:
                json.dump(self.config, f, indent=4)
            self.logger.info(f"Configuration saved to {config_file}")
        except Exception as e:
            self.logger.error(f"Error saving config: {str(e)}")
    
    def validate_dependencies(self):
        """Validate that required tools are installed"""
        tools = {
            'nmap': 'nmap --version',
            'nikto': 'nikto -Version',
            'whatweb': 'whatweb --version',
            'wpscan': 'wpscan --version',
            'testssl.sh': 'testssl.sh --version',
            'theharvester': 'theHarvester --version',
            'sublist3r': 'sublist3r --help',
            'assetfinder': 'assetfinder --help',
            'amass': 'amass --version',
            'subfinder': 'subfinder --version',
            'httprobe': 'httprobe --help',
            'httpx': 'httpx --version',
            'gowitness': 'gowitness --version',
            'aquatone': 'aquatone --version'
        }
        
        available_tools = {}
        missing_tools = []
        
        for tool, check_cmd in tools.items():
            try:
                result = os.system(f"{check_cmd} >/dev/null 2>&1")
                if result == 0:
                    available_tools[tool] = True
                else:
                    available_tools[tool] = False
                    missing_tools.append(tool)
            except Exception:
                available_tools[tool] = False
                missing_tools.append(tool)
        
        if missing_tools:
            self.logger.warning(f"Missing tools: {', '.join(missing_tools)}")
            self.logger.info("Install missing tools for full functionality")
        
        return available_tools, missing_tools


# ============================== SECURITY SCANNER ==============================
class SecurityScanner:
    """SSL/TLS Security Analysis and Certificate Transparency Scanner"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.results = {}
        
    def analyze_ssl_tls(self, target, port=443):
        """Comprehensive SSL/TLS analysis"""
        self.logger.info(f"Analyzing SSL/TLS for {target}:{port}")
        
        ssl_info = {
            'target': target,
            'port': port,
            'certificate': None,
            'cipher_suites': [],
            'protocols': [],
            'vulnerabilities': [],
            'security_headers': {},
            'certificate_chain': [],
            'transparency_logs': []
        }
        
        try:
            # Get SSL certificate information
            ssl_info['certificate'] = self._get_certificate_info(target, port)
            
            # Test supported SSL/TLS protocols
            ssl_info['protocols'] = self._test_ssl_protocols(target, port)
            
            # Get cipher suites
            ssl_info['cipher_suites'] = self._get_cipher_suites(target, port)
            
            # Check for common vulnerabilities
            ssl_info['vulnerabilities'] = self._check_ssl_vulnerabilities(target, port)
            
            # Get security headers
            ssl_info['security_headers'] = self._check_security_headers(target, port)
            
            # Get certificate chain
            ssl_info['certificate_chain'] = self._get_certificate_chain(target, port)
            
            # Query Certificate Transparency logs
            if ssl_info['certificate']:
                ssl_info['transparency_logs'] = self._query_certificate_transparency(ssl_info['certificate'])
            
            # Save results
            self._save_ssl_results(target, ssl_info)
            self.results[f"{target}:{port}"] = ssl_info
            
        except Exception as e:
            self.logger.error(f"SSL/TLS analysis failed for {target}:{port}: {str(e)}")
            ssl_info['error'] = str(e)
            
        return ssl_info
        
    def _get_certificate_info(self, target, port):
        """Extract detailed certificate information"""
        try:
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            with socket.create_connection((target, port), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=target) as ssock:
                    # Get basic certificate info that's always available
                    basic_cert = ssock.getpeercert()
                    
                    cert_info = {
                        'subject': dict(x[0] for x in basic_cert.get('subject', [])),
                        'issuer': dict(x[0] for x in basic_cert.get('issuer', [])),
                        'serial_number': basic_cert.get('serialNumber'),
                        'not_before': basic_cert.get('notBefore'),
                        'not_after': basic_cert.get('notAfter'),
                        'signature_algorithm': None,
                        'public_key_algorithm': None,
                        'public_key_size': None,
                        'san': [name[1] for name in basic_cert.get('subjectAltName', [])],
                        'sha256_fingerprint': None,
                        'sha1_fingerprint': None,
                        'pem': None
                    }
                    
                    # Try to get detailed info with cryptography if available
                    if HAS_CRYPTO:
                        try:
                            cert_der = ssock.getpeercert_chain()[0].public_bytes(serialization.Encoding.DER)
                            cert_pem = ssock.getpeercert_chain()[0].public_bytes(serialization.Encoding.PEM)
                            cert = x509.load_der_x509_certificate(cert_der, default_backend())
                            
                            # Extract detailed information
                            cert_info['subject'] = {attr.oid._name: attr.value for attr in cert.subject}
                            cert_info['issuer'] = {attr.oid._name: attr.value for attr in cert.issuer}
                            cert_info['serial_number'] = str(cert.serial_number)
                            cert_info['not_before'] = cert.not_valid_before.isoformat()
                            cert_info['not_after'] = cert.not_valid_after.isoformat()
                            cert_info['signature_algorithm'] = cert.signature_algorithm_oid._name
                            cert_info['public_key_size'] = cert.public_key().key_size
                            cert_info['pem'] = cert_pem.decode() if isinstance(cert_pem, bytes) else cert_pem
                            
                            # Get Subject Alternative Names
                            try:
                                san_ext = cert.extensions.get_extension_for_oid(x509.NameOID.SUBJECT_ALTERNATIVE_NAME)
                                cert_info['san'] = [name.value for name in san_ext.value]
                            except x509.ExtensionNotFound:
                                pass
                                
                            # Calculate fingerprints
                            cert_info['sha256_fingerprint'] = cert.fingerprint(hashes.SHA256()).hex()
                            cert_info['sha1_fingerprint'] = cert.fingerprint(hashes.SHA1()).hex()
                            
                        except Exception as e:
                            self.logger.warning(f"Detailed certificate parsing failed: {e}")
                    
                    # Calculate basic fingerprint without cryptography
                    if not cert_info['sha256_fingerprint']:
                        try:
                            cert_der = ssock.getpeercert(binary_form=True)
                            cert_info['sha256_fingerprint'] = hashlib.sha256(cert_der).hexdigest()
                            cert_info['sha1_fingerprint'] = hashlib.sha1(cert_der).hexdigest()
                        except Exception:
                            pass
                        
                    return cert_info
                    
        except Exception as e:
            self.logger.error(f"Failed to get certificate info: {str(e)}")
            return None
            
    def _test_ssl_protocols(self, target, port):
        """Test supported SSL/TLS protocol versions"""
        protocols = []
        protocol_versions = [
            ('SSLv2', ssl.PROTOCOL_SSLv2 if hasattr(ssl, 'PROTOCOL_SSLv2') else None),
            ('SSLv3', ssl.PROTOCOL_SSLv3 if hasattr(ssl, 'PROTOCOL_SSLv3') else None),
            ('TLSv1.0', ssl.PROTOCOL_TLSv1 if hasattr(ssl, 'PROTOCOL_TLSv1') else None),
            ('TLSv1.1', ssl.PROTOCOL_TLSv1_1 if hasattr(ssl, 'PROTOCOL_TLSv1_1') else None),
            ('TLSv1.2', ssl.PROTOCOL_TLSv1_2 if hasattr(ssl, 'PROTOCOL_TLSv1_2') else None),
            ('TLSv1.3', ssl.PROTOCOL_TLS if hasattr(ssl, 'PROTOCOL_TLS') else None)
        ]
        
        for name, protocol in protocol_versions:
            if protocol is None:
                continue
                
            try:
                context = ssl.SSLContext(protocol)
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
                
                with socket.create_connection((target, port), timeout=5) as sock:
                    with context.wrap_socket(sock, server_hostname=target) as ssock:
                        protocols.append({
                            'name': name,
                            'supported': True,
                            'cipher': ssock.cipher()
                        })
            except Exception:
                protocols.append({
                    'name': name,
                    'supported': False,
                    'cipher': None
                })
                
        return protocols
        
    def _get_cipher_suites(self, target, port):
        """Get supported cipher suites"""
        cipher_suites = []
        
        try:
            # Test with different SSL contexts to get cipher information
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            with socket.create_connection((target, port), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=target) as ssock:
                    cipher_info = ssock.cipher()
                    if cipher_info:
                        cipher_suites.append({
                            'name': cipher_info[0],
                            'protocol': cipher_info[1],
                            'key_length': cipher_info[2]
                        })
                        
        except Exception as e:
            self.logger.error(f"Failed to get cipher suites: {str(e)}")
            
        return cipher_suites
        
    def _check_ssl_vulnerabilities(self, target, port):
        """Check for common SSL/TLS vulnerabilities"""
        vulnerabilities = []
        
        # Check for weak protocols
        protocols = self._test_ssl_protocols(target, port)
        for proto in protocols:
            if proto['supported']:
                if proto['name'] in ['SSLv2', 'SSLv3', 'TLSv1.0']:
                    vulnerabilities.append({
                        'type': 'weak_protocol',
                        'name': f"Weak Protocol: {proto['name']}",
                        'severity': 'high' if proto['name'] in ['SSLv2', 'SSLv3'] else 'medium',
                        'description': f"Server supports deprecated protocol {proto['name']}"
                    })
                    
        # Check certificate validity
        cert_info = self._get_certificate_info(target, port)
        if cert_info:
            try:
                from datetime import datetime
                if cert_info.get('not_after'):
                    expiry = datetime.fromisoformat(cert_info['not_after'].replace('Z', '+00:00'))
                    if expiry < datetime.now():
                        vulnerabilities.append({
                            'type': 'expired_certificate',
                            'name': 'Expired Certificate',
                            'severity': 'high',
                            'description': f"Certificate expired on {cert_info['not_after']}"
                        })
                    elif (expiry - datetime.now()).days < 30:
                        vulnerabilities.append({
                            'type': 'expiring_certificate',
                            'name': 'Certificate Expiring Soon',
                            'severity': 'medium',
                            'description': f"Certificate expires on {cert_info['not_after']}"
                        })
            except Exception:
                pass
                
        return vulnerabilities
        
    def _check_security_headers(self, target, port):
        """Check HTTP security headers"""
        headers = {}
        
        try:
            # Try HTTPS first
            url = f"https://{target}:{port}" if port != 443 else f"https://{target}"
            response = requests.get(url, timeout=10, verify=False, allow_redirects=False)
            
            security_headers = [
                'Strict-Transport-Security',
                'Content-Security-Policy',
                'X-Frame-Options',
                'X-Content-Type-Options',
                'X-XSS-Protection',
                'Referrer-Policy',
                'Permissions-Policy',
                'Expect-CT'
            ]
            
            for header in security_headers:
                value = response.headers.get(header)
                headers[header] = {
                    'present': value is not None,
                    'value': value
                }
                
        except Exception as e:
            self.logger.error(f"Failed to check security headers: {str(e)}")
            
        return headers
        
    def _get_certificate_chain(self, target, port):
        """Get complete certificate chain"""
        chain = []
        
        try:
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            with socket.create_connection((target, port), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=target) as ssock:
                    # Try to get certificate chain
                    if HAS_CRYPTO:
                        try:
                            chain_certs = ssock.getpeercert_chain()
                            
                            for cert in chain_certs:
                                cert_der = cert.public_bytes(serialization.Encoding.DER)
                                cert_obj = x509.load_der_x509_certificate(cert_der, default_backend())
                                
                                chain.append({
                                    'subject': {attr.oid._name: attr.value for attr in cert_obj.subject},
                                    'issuer': {attr.oid._name: attr.value for attr in cert_obj.issuer},
                                    'serial_number': str(cert_obj.serial_number),
                                    'fingerprint': cert_obj.fingerprint(hashes.SHA256()).hex()
                                })
                        except Exception as e:
                            self.logger.warning(f"Detailed chain parsing failed: {e}")
                    
                    # Fallback to basic certificate info
                    if not chain:
                        try:
                            basic_cert = ssock.getpeercert()
                            chain.append({
                                'subject': dict(x[0] for x in basic_cert.get('subject', [])),
                                'issuer': dict(x[0] for x in basic_cert.get('issuer', [])),
                                'serial_number': basic_cert.get('serialNumber'),
                                'fingerprint': 'unavailable'
                            })
                        except Exception:
                            chain.append({
                                'subject': 'Certificate info unavailable',
                                'issuer': 'Certificate info unavailable'
                            })
                            
        except Exception as e:
            self.logger.error(f"Failed to get certificate chain: {str(e)}")
            
        return chain
        
    def _query_certificate_transparency(self, cert_info):
        """Query Certificate Transparency logs"""
        ct_logs = []
        
        # Check if Certificate Transparency is enabled
        if not self.config.get('security', 'cert_transparency', True):
            self.logger.info("Certificate Transparency queries disabled")
            return ct_logs
        
        if not cert_info or not cert_info.get('sha256_fingerprint'):
            return ct_logs
            
        try:
            # Query crt.sh for certificate transparency logs
            fingerprint = cert_info['sha256_fingerprint']
            url = f"https://crt.sh/?q={fingerprint}&output=json"
            
            response = requests.get(url, timeout=15)
            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list):
                    for entry in data[:10]:  # Limit to first 10 entries
                        ct_logs.append({
                            'id': entry.get('id'),
                            'logged_at': entry.get('entry_timestamp'),
                            'not_before': entry.get('not_before'),
                            'not_after': entry.get('not_after'),
                            'common_name': entry.get('common_name'),
                            'issuer_name': entry.get('issuer_name')
                        })
                        
        except Exception as e:
            self.logger.error(f"Failed to query Certificate Transparency logs: {str(e)}")
            
        return ct_logs
        
    def _save_ssl_results(self, target, ssl_info):
        """Save SSL/TLS analysis results"""
        try:
            output_file = self.output_dir / f"ssl_analysis_{target.replace('.', '_')}.json"
            with open(output_file, 'w') as f:
                json.dump(ssl_info, f, indent=2, default=str)
            self.logger.info(f"SSL analysis results saved to {output_file}")
        except Exception as e:
            self.logger.error(f"Failed to save SSL results: {str(e)}")
            
    def scan_target(self, target):
        """Run complete security scan on target"""
        self.logger.info(f"Running security scan on {target}")
        
        results = {
            'target': target,
            'timestamp': datetime.now().isoformat(),
            'ssl_analysis': {},
            'open_ports': []
        }
        
        # Get SSL/TLS ports from configuration
        ssl_ports = self.config.get('security', 'ports', [443, 8443, 9443, 8080, 8008, 8888])
        timeout = self.config.get('security', 'timeout', 30)
        
        for port in ssl_ports:
            if self._port_is_open(target, port, timeout=timeout):
                results['open_ports'].append(port)
                ssl_result = self.analyze_ssl_tls(target, port)
                results['ssl_analysis'][f"port_{port}"] = ssl_result
                
        return results
        
    def _port_is_open(self, target, port, timeout=3):
        """Check if a port is open"""
        try:
            with socket.create_connection((target, port), timeout=timeout):
                return True
        except (socket.timeout, socket.error):
            return False
    
    def vulnerability_scan(self, target):
        """Enhanced vulnerability scanning with multiple tools"""
        try:
            print(f"\nüîç Starting vulnerability scan for: {target}")
            
            results = {
                'target': target,
                'timestamp': datetime.now().isoformat(),
                'nmap_vulners': {},
                'ssl_vulnerabilities': {},
                'web_vulnerabilities': {},
                'service_vulnerabilities': {},
                'cve_analysis': {}
            }
            
            # Nmap vulnerability scripts
            nmap_vuln_results = self._run_nmap_vulners(target)
            if nmap_vuln_results:
                results['nmap_vulners'] = nmap_vuln_results
            
            # SSL/TLS vulnerability analysis
            ssl_vulns = self._analyze_ssl_vulnerabilities(target)
            if ssl_vulns:
                results['ssl_vulnerabilities'] = ssl_vulns
            
            # Web application vulnerability checks
            web_vulns = self._check_web_vulnerabilities(target)
            if web_vulns:
                results['web_vulnerabilities'] = web_vulns
            
            # Service-specific vulnerability checks
            service_vulns = self._check_service_vulnerabilities(target)
            if service_vulns:
                results['service_vulnerabilities'] = service_vulns
            
            print(f"‚úÖ Vulnerability scan completed for {target}")
            return results
            
        except Exception as e:
            self.logger.error(f"Vulnerability scan error: {str(e)}")
            return {}
    
    def _run_nmap_vulners(self, target):
        """Run Nmap with vulnerability detection scripts"""
        try:
            vuln_scripts = [
                '--script=vuln',
                '--script=vulners',
                '--script=vulscan',
                '--script=exploit'
            ]
            
            results = {}
            
            for script in vuln_scripts:
                try:
                    cmd = f"nmap -sV {script} --script-args vulners.shodan-api-key='' {target}"
                    result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=300)
                    
                    if result.stdout:
                        script_name = script.split('=')[1] if '=' in script else script
                        results[script_name] = self._parse_nmap_vuln_output(result.stdout)
                        
                except subprocess.TimeoutExpired:
                    self.logger.warning(f"Nmap vulnerability script {script} timed out")
                except Exception as e:
                    self.logger.debug(f"Script {script} failed: {str(e)}")
                    
            return results
            
        except Exception as e:
            self.logger.error(f"Nmap vulnerability scan error: {str(e)}")
            return {}
    
    def _parse_nmap_vuln_output(self, output):
        """Parse Nmap vulnerability scan output"""
        vulnerabilities = []
        
        # Look for CVE patterns
        cve_pattern = r'CVE-\d{4}-\d{4,7}'
        cves = re.findall(cve_pattern, output)
        
        # Look for vulnerability descriptions
        vuln_lines = []
        for line in output.split('\n'):
            if any(keyword in line.lower() for keyword in ['vulnerable', 'exploit', 'cve-', 'risk']):
                vuln_lines.append(line.strip())
        
        return {
            'cves': list(set(cves)),
            'vulnerability_details': vuln_lines[:20]  # Limit output
        }
    
    def _analyze_ssl_vulnerabilities(self, target):
        """Advanced SSL/TLS vulnerability analysis"""
        try:
            ssl_ports = [443, 8443, 9443, 8080, 8008]
            results = {}
            
            for port in ssl_ports:
                if self._port_is_open(target, port):
                    port_results = {}
                    
                    # Check for common SSL vulnerabilities
                    vuln_checks = {
                        'heartbleed': self._check_heartbleed(target, port),
                        'poodle': self._check_poodle(target, port),
                        'beast': self._check_beast(target, port),
                        'drown': self._check_drown(target, port),
                        'weak_ciphers': self._check_weak_ciphers(target, port),
                        'certificate_issues': self._check_certificate_issues(target, port)
                    }
                    
                    # Filter out empty results
                    port_results = {k: v for k, v in vuln_checks.items() if v}
                    
                    if port_results:
                        results[f'port_{port}'] = port_results
                        
            return results
            
        except Exception as e:
            self.logger.error(f"SSL vulnerability analysis error: {str(e)}")
            return {}
    
    def _check_heartbleed(self, target, port):
        """Check for Heartbleed vulnerability using Nmap"""
        try:
            cmd = f"nmap -p {port} --script ssl-heartbleed {target}"
            result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
            
            if 'VULNERABLE' in result.stdout:
                return {
                    'vulnerable': True,
                    'cve': 'CVE-2014-0160',
                    'severity': 'HIGH',
                    'description': 'Heartbleed vulnerability detected'
                }
        except Exception:
            pass
        return None
    
    def _check_poodle(self, target, port):
        """Check for POODLE vulnerability"""
        try:
            cmd = f"nmap -p {port} --script ssl-poodle {target}"
            result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
            
            if 'VULNERABLE' in result.stdout:
                return {
                    'vulnerable': True,
                    'cve': 'CVE-2014-3566',
                    'severity': 'MEDIUM',
                    'description': 'POODLE vulnerability detected'
                }
        except Exception:
            pass
        return None
    
    def _check_beast(self, target, port):
        """Check for BEAST vulnerability"""
        try:
            cmd = f"nmap -p {port} --script ssl-enum-ciphers {target}"
            result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
            
            # Look for CBC ciphers with TLS 1.0
            if 'TLSv1.0' in result.stdout and 'CBC' in result.stdout:
                return {
                    'vulnerable': True,
                    'cve': 'CVE-2011-3389',
                    'severity': 'MEDIUM',
                    'description': 'BEAST vulnerability - CBC cipher with TLS 1.0'
                }
        except Exception:
            pass
        return None
    
    def _check_drown(self, target, port):
        """Check for DROWN vulnerability"""
        try:
            cmd = f"nmap -p {port} --script ssl-dh-params {target}"
            result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
            
            if 'SSLv2' in result.stdout:
                return {
                    'vulnerable': True,
                    'cve': 'CVE-2016-0800',
                    'severity': 'HIGH',
                    'description': 'DROWN vulnerability - SSLv2 enabled'
                }
        except Exception:
            pass
        return None
    
    def _check_weak_ciphers(self, target, port):
        """Check for weak SSL/TLS ciphers"""
        try:
            cmd = f"nmap -p {port} --script ssl-enum-ciphers {target}"
            result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
            
            weak_ciphers = []
            weak_keywords = ['NULL', 'EXPORT', 'RC4', 'DES', 'MD5', 'weak']
            
            for line in result.stdout.split('\n'):
                for keyword in weak_keywords:
                    if keyword in line.upper():
                        weak_ciphers.append(line.strip())
                        
            if weak_ciphers:
                return {
                    'weak_ciphers_found': True,
                    'severity': 'MEDIUM',
                    'ciphers': weak_ciphers[:10],  # Limit output
                    'description': 'Weak or insecure ciphers detected'
                }
        except Exception:
            pass
        return None
    
    def _check_certificate_issues(self, target, port):
        """Check for SSL certificate issues"""
        try:
            import ssl
            import socket
            
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            with socket.create_connection((target, port), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=target) as ssock:
                    cert = ssock.getpeercert()
                    
                    issues = []
                    
                    # Check expiration
                    import datetime
                    not_after = datetime.datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
                    days_until_expiry = (not_after - datetime.datetime.now()).days
                    
                    if days_until_expiry < 30:
                        issues.append(f"Certificate expires in {days_until_expiry} days")
                    
                    # Check for self-signed
                    if cert.get('issuer') == cert.get('subject'):
                        issues.append("Self-signed certificate")
                    
                    # Check for weak signature algorithm
                    if 'sha1' in cert.get('signatureAlgorithm', '').lower():
                        issues.append("Weak signature algorithm (SHA-1)")
                    
                    if issues:
                        return {
                            'certificate_issues': True,
                            'issues': issues,
                            'severity': 'MEDIUM',
                            'certificate_info': {
                                'subject': cert.get('subject'),
                                'issuer': cert.get('issuer'),
                                'expiry': cert.get('notAfter')
                            }
                        }
                        
        except Exception as e:
            self.logger.debug(f"Certificate check error: {str(e)}")
        return None
    
    def _check_web_vulnerabilities(self, target):
        """Check for common web application vulnerabilities"""
        try:
            results = {}
            
            # Check if target responds to HTTP/HTTPS
            protocols = []
            if self._port_is_open(target, 80):
                protocols.append('http')
            if self._port_is_open(target, 443):
                protocols.append('https')
                
            for protocol in protocols:
                base_url = f"{protocol}://{target}"
                
                # SQL Injection basic check
                sqli_check = self._basic_sqli_check(base_url)
                if sqli_check:
                    results['sql_injection'] = sqli_check
                
                # XSS basic check
                xss_check = self._basic_xss_check(base_url)
                if xss_check:
                    results['xss'] = xss_check
                
                # Directory traversal check
                lfi_check = self._basic_lfi_check(base_url)
                if lfi_check:
                    results['directory_traversal'] = lfi_check
                
                # Command injection check
                cmd_check = self._basic_command_injection_check(base_url)
                if cmd_check:
                    results['command_injection'] = cmd_check
                    
            return results
            
        except Exception as e:
            self.logger.error(f"Web vulnerability check error: {str(e)}")
            return {}
    
    def _basic_sqli_check(self, base_url):
        """Basic SQL injection detection"""
        try:
            payloads = ["'", "1'OR'1'='1", "admin'--", "' UNION SELECT NULL--"]
            
            for payload in payloads:
                test_urls = [
                    f"{base_url}/?id={payload}",
                    f"{base_url}/login?username={payload}&password=test",
                    f"{base_url}/search?q={payload}"
                ]
                
                for url in test_urls:
                    try:
                        resp = requests.get(url, timeout=5)
                        
                        # Look for SQL error messages
                        error_patterns = [
                            r'mysql_fetch_array',
                            r'ORA-\d{5}',
                            r'Microsoft.*ODBC.*SQL',
                            r'PostgreSQL.*ERROR',
                            r'Warning.*mysql_.*',
                            r'SQL syntax.*MySQL',
                            r'sqlite3\.OperationalError'
                        ]
                        
                        for pattern in error_patterns:
                            if re.search(pattern, resp.text, re.IGNORECASE):
                                return {
                                    'potential_sqli': True,
                                    'url': url,
                                    'payload': payload,
                                    'pattern_matched': pattern,
                                    'severity': 'HIGH'
                                }
                                
                    except Exception:
                        continue
                        
        except Exception:
            pass
        return None
    
    def _basic_xss_check(self, base_url):
        """Basic XSS detection"""
        try:
            payloads = [
                "<script>alert('XSS')</script>",
                "javascript:alert('XSS')",
                "<img src=x onerror=alert('XSS')>"
            ]
            
            for payload in payloads:
                test_urls = [
                    f"{base_url}/?search={payload}",
                    f"{base_url}/?q={payload}",
                    f"{base_url}/?name={payload}"
                ]
                
                for url in test_urls:
                    try:
                        resp = requests.get(url, timeout=5)
                        
                        if payload in resp.text:
                            return {
                                'potential_xss': True,
                                'url': url,
                                'payload': payload,
                                'reflected': True,
                                'severity': 'MEDIUM'
                            }
                            
                    except Exception:
                        continue
                        
        except Exception:
            pass
        return None
    
    def _basic_lfi_check(self, base_url):
        """Basic Local File Inclusion detection"""
        try:
            payloads = [
                "../../../etc/passwd",
                "..\\..\\..\\windows\\system32\\drivers\\etc\\hosts",
                "....//....//....//etc/passwd"
            ]
            
            for payload in payloads:
                test_urls = [
                    f"{base_url}/?file={payload}",
                    f"{base_url}/?page={payload}",
                    f"{base_url}/?include={payload}"
                ]
                
                for url in test_urls:
                    try:
                        resp = requests.get(url, timeout=5)
                        
                        # Look for signs of file inclusion
                        if any(pattern in resp.text for pattern in ['root:x:', 'daemon:', 'bin:', '127.0.0.1']):
                            return {
                                'potential_lfi': True,
                                'url': url,
                                'payload': payload,
                                'severity': 'HIGH'
                            }
                            
                    except Exception:
                        continue
                        
        except Exception:
            pass
        return None
    
    def _basic_command_injection_check(self, base_url):
        """Basic command injection detection"""
        try:
            payloads = [
                "; ls",
                "| whoami",
                "&& dir",
                "`id`"
            ]
            
            for payload in payloads:
                test_urls = [
                    f"{base_url}/?cmd={payload}",
                    f"{base_url}/?exec={payload}",
                    f"{base_url}/?system={payload}"
                ]
                
                for url in test_urls:
                    try:
                        resp = requests.get(url, timeout=5)
                        
                        # Look for command output patterns
                        cmd_patterns = [
                            r'uid=\d+.*gid=\d+',  # id command output
                            r'total \d+',         # ls command output
                            r'Volume.*Serial',    # dir command output
                            r'root.*bin.*sbin'    # whoami/ls output
                        ]
                        
                        for pattern in cmd_patterns:
                            if re.search(pattern, resp.text):
                                return {
                                    'potential_command_injection': True,
                                    'url': url,
                                    'payload': payload,
                                    'pattern_matched': pattern,
                                    'severity': 'HIGH'
                                }
                                
                    except Exception:
                        continue
                        
        except Exception:
            pass
        return None
    
    def _check_service_vulnerabilities(self, target):
        """Check for service-specific vulnerabilities"""
        try:
            results = {}
            
            # Check common vulnerable services
            vulnerable_services = {
                21: 'FTP',
                22: 'SSH', 
                23: 'Telnet',
                25: 'SMTP',
                53: 'DNS',
                80: 'HTTP',
                110: 'POP3',
                143: 'IMAP',
                443: 'HTTPS',
                993: 'IMAPS',
                995: 'POP3S',
                1433: 'MSSQL',
                3306: 'MySQL',
                5432: 'PostgreSQL',
                6379: 'Redis'
            }
            
            for port, service in vulnerable_services.items():
                if self._port_is_open(target, port):
                    service_vulns = self._check_specific_service(target, port, service)
                    if service_vulns:
                        results[f'{service}_port_{port}'] = service_vulns
                        
            return results
            
        except Exception as e:
            self.logger.error(f"Service vulnerability check error: {str(e)}")
            return {}
    
    def _check_specific_service(self, target, port, service):
        """Check vulnerabilities for specific services"""
        try:
            vulnerabilities = []
            
            if service == 'SSH':
                # Check for weak SSH configuration
                ssh_issues = self._check_ssh_vulnerabilities(target, port)
                if ssh_issues:
                    vulnerabilities.extend(ssh_issues)
                    
            elif service == 'FTP':
                # Check for anonymous FTP
                ftp_issues = self._check_ftp_vulnerabilities(target, port)
                if ftp_issues:
                    vulnerabilities.extend(ftp_issues)
                    
            elif service in ['MySQL', 'MSSQL', 'PostgreSQL']:
                # Check for database vulnerabilities
                db_issues = self._check_database_vulnerabilities(target, port, service)
                if db_issues:
                    vulnerabilities.extend(db_issues)
                    
            return vulnerabilities if vulnerabilities else None
            
        except Exception:
            return None
    
    def _check_ssh_vulnerabilities(self, target, port):
        """Check SSH-specific vulnerabilities"""
        try:
            issues = []
            
            # Use Nmap SSH scripts
            ssh_scripts = [
                '--script=ssh2-enum-algos',
                '--script=ssh-hostkey',
                '--script=ssh-auth-methods'
            ]
            
            for script in ssh_scripts:
                try:
                    cmd = f"nmap -p {port} {script} {target}"
                    result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
                    
                    # Look for weak algorithms
                    if 'weak' in result.stdout.lower() or 'deprecated' in result.stdout.lower():
                        issues.append({
                            'issue': 'Weak SSH algorithms detected',
                            'severity': 'MEDIUM',
                            'details': result.stdout[:200]
                        })
                        
                except Exception:
                    continue
                    
            return issues
            
        except Exception:
            return []
    
    def _check_ftp_vulnerabilities(self, target, port):
        """Check FTP-specific vulnerabilities"""
        try:
            issues = []
            
            # Check for anonymous FTP
            try:
                import ftplib
                ftp = ftplib.FTP()
                ftp.connect(target, port, timeout=10)
                
                try:
                    ftp.login('anonymous', 'test@test.com')
                    issues.append({
                        'issue': 'Anonymous FTP access enabled',
                        'severity': 'MEDIUM',
                        'details': 'Anonymous login successful'
                    })
                    ftp.quit()
                except:
                    pass
                    
            except Exception:
                pass
                
            return issues
            
        except Exception:
            return []
    
    def _check_database_vulnerabilities(self, target, port, service):
        """Check database-specific vulnerabilities"""
        try:
            issues = []
            
            # Use Nmap database scripts
            if service == 'MySQL':
                cmd = f"nmap -p {port} --script=mysql-info,mysql-empty-password {target}"
            elif service == 'MSSQL':
                cmd = f"nmap -p {port} --script=ms-sql-info,ms-sql-empty-password {target}"
            elif service == 'PostgreSQL':
                cmd = f"nmap -p {port} --script=pgsql-brute {target}"
            else:
                return []
                
            try:
                result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=30)
                
                # Look for security issues
                if 'empty password' in result.stdout.lower():
                    issues.append({
                        'issue': 'Empty/default password detected',
                        'severity': 'HIGH',
                        'service': service
                    })
                    
                if 'root' in result.stdout.lower() and 'access' in result.stdout.lower():
                    issues.append({
                        'issue': 'Root access detected',
                        'severity': 'HIGH',
                        'service': service
                    })
                    
            except Exception:
                pass
                
            return issues
            
        except Exception:
            return []


# ============================== PORT SCANNER ==============================
class PortScanner:
    """Nmap port scanner wrapper"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def basic_scan(self, target):
        """Run basic port scan"""
        self.logger.info(f"Running basic port scan on {target}")
        
        flags = self.config.get('nmap', 'basic_flags', '-sV -sC')
        timeout = self.config.get('nmap', 'timeout', 300)
        
        output_file = self.output_dir / 'nmap' / f'{target}_basic'
        
        cmd = [
            'nmap', 
            *flags.split(),
            '-oA', str(output_file),
            '--open',
            target
        ]
        
        return self._run_nmap_command(cmd, target, 'basic')
    
    def aggressive_scan(self, target):
        """Run aggressive port scan with light mode support"""
        self.logger.info(f"Running aggressive port scan on {target}")
        
        flags = self.config.get('nmap', 'aggressive_flags', '-A -T4')
        
        # Adjust for light mode
        if self.config.get('performance', 'light_mode', False):
            # Use lighter timing and reduce aggressive features
            flags = flags.replace('-T4', '-T3')  # Slower timing
            flags = flags.replace('-A', '-sV -sC')  # Remove OS detection and traceroute
            self.logger.info("Light mode: Using reduced Nmap flags for lower resource usage")
        
        timeout = self.config.get('nmap', 'timeout', 600)
        
        output_file = self.output_dir / 'nmap' / f'{target}_aggressive'
        
        cmd = [
            'nmap',
            *flags.split(),
            '-oA', str(output_file),
            '--open',
            target
        ]
        
        return self._run_nmap_command(cmd, target, 'aggressive')
    
    def _run_nmap_command(self, cmd, target, scan_type):
        """Execute nmap command and parse results"""
        try:
            self.logger.info(f"Executing: {' '.join(cmd)}")
            
            # Run the command
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config.get('nmap', 'timeout', 300)
            )
            
            if result.returncode != 0:
                self.logger.error(f"Nmap scan failed: {result.stderr}")
                return {}
            
            # Parse XML output
            xml_file = f"{cmd[cmd.index('-oA') + 1]}.xml"
            
            if os.path.exists(xml_file):
                return self._parse_nmap_xml(xml_file, target, scan_type)
            else:
                self.logger.warning(f"XML output file not found: {xml_file}")
                return {}
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"Nmap scan timed out for {target}")
            return {}
        except Exception as e:
            self.logger.error(f"Error running nmap scan: {str(e)}")
            return {}
    
    def _parse_nmap_xml(self, xml_file, target, scan_type):
        """Parse Nmap XML output"""
        try:
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            results = {
                'target': target,
                'scan_type': scan_type,
                'timestamp': root.get('startstr'),
                'hosts': [],
                'summary': {
                    'total_hosts': 0,
                    'hosts_up': 0,
                    'total_ports': 0,
                    'open_ports': 0,
                    'filtered_ports': 0,
                    'closed_ports': 0
                }
            }
            
            for host in root.findall('host'):
                host_info = self._parse_host(host)
                if host_info:
                    results['hosts'].append(host_info)
                    results['summary']['total_hosts'] += 1
                    
                    if host_info['status'] == 'up':
                        results['summary']['hosts_up'] += 1
                        
                    for port in host_info.get('ports', []):
                        results['summary']['total_ports'] += 1
                        state = port.get('state', 'unknown')
                        if state == 'open':
                            results['summary']['open_ports'] += 1
                        elif state == 'filtered':
                            results['summary']['filtered_ports'] += 1
                        elif state == 'closed':
                            results['summary']['closed_ports'] += 1
            
            # Save parsed results
            json_file = self.output_dir / 'nmap' / f'{target}_{scan_type}_parsed.json'
            with open(json_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            self.logger.info(f"Parsed nmap results saved to {json_file}")
            return results
            
        except Exception as e:
            self.logger.error(f"Error parsing XML file {xml_file}: {str(e)}")
            return {}
    
    def _parse_host(self, host_element):
        """Parse individual host from XML"""
        try:
            # Get host address
            address_elem = host_element.find('address')
            if address_elem is None:
                return None
                
            host_info = {
                'address': address_elem.get('addr'),
                'address_type': address_elem.get('addrtype'),
                'status': host_element.find('status').get('state'),
                'hostnames': [],
                'ports': [],
                'os': {},
                'scripts': []
            }
            
            # Get hostnames
            hostnames = host_element.find('hostnames')
            if hostnames is not None:
                for hostname in hostnames.findall('hostname'):
                    host_info['hostnames'].append({
                        'name': hostname.get('name'),
                        'type': hostname.get('type')
                    })
            
            # Get ports
            ports = host_element.find('ports')
            if ports is not None:
                for port in ports.findall('port'):
                    port_info = {
                        'port': port.get('portid'),
                        'protocol': port.get('protocol'),
                        'state': port.find('state').get('state'),
                        'reason': port.find('state').get('reason'),
                        'service': {}
                    }
                    
                    # Get service info
                    service = port.find('service')
                    if service is not None:
                        port_info['service'] = {
                            'name': service.get('name', ''),
                            'product': service.get('product', ''),
                            'version': service.get('version', ''),
                            'extrainfo': service.get('extrainfo', '')
                        }
                    
                    host_info['ports'].append(port_info)
            
            return host_info
            
        except Exception as e:
            self.logger.error(f"Error parsing host: {str(e)}")
            return None

    def masscan_scan(self, target, port_range="1-65535"):
        """Run masscan for ultra-fast port discovery"""
        try:
            # Check if masscan is available
            subprocess.run(['masscan', '--help'], capture_output=True, check=True)
            
            self.logger.info(f"Running masscan on {target} (ports {port_range})")
            
            output_file = self.output_dir / 'nmap' / f'{target}_masscan.json'
            
            # Masscan command with rate limiting for safety
            cmd = [
                'masscan',
                target,
                '-p', port_range,
                '--rate', '1000',  # Conservative rate
                '--output-format', 'json',
                '--output-filename', str(output_file),
                '--open-only'
            ]
            
            # Run masscan with timeout
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                # Parse masscan JSON output
                masscan_results = self._parse_masscan_json(output_file, target)
                self.logger.info(f"Masscan discovered {len(masscan_results.get('ports', []))} open ports")
                return masscan_results
            else:
                self.logger.error(f"Masscan failed: {result.stderr}")
                return None
                
        except subprocess.CalledProcessError:
            self.logger.warning("Masscan not available, falling back to nmap")
            return None
        except subprocess.TimeoutExpired:
            self.logger.warning("Masscan timed out")
            return None
        except Exception as e:
            self.logger.error(f"Error running masscan: {str(e)}")
            return None

    def _parse_masscan_json(self, json_file, target):
        """Parse masscan JSON output"""
        try:
            results = {
                'target': target,
                'scan_type': 'masscan',
                'ports': [],
                'total_ports': 0
            }
            
            if not json_file.exists():
                return results
            
            with open(json_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and line.startswith('{'):
                        try:
                            port_data = json.loads(line)
                            if 'ports' in port_data:
                                for port_info in port_data['ports']:
                                    results['ports'].append({
                                        'port': port_info.get('port'),
                                        'protocol': port_info.get('proto', 'tcp'),
                                        'state': 'open',
                                        'service': {'name': 'unknown'},
                                        'discovered_by': 'masscan'
                                    })
                        except json.JSONDecodeError:
                            continue
            
            results['total_ports'] = len(results['ports'])
            return results
            
        except Exception as e:
            self.logger.error(f"Error parsing masscan output: {str(e)}")
            return {'target': target, 'scan_type': 'masscan', 'ports': [], 'total_ports': 0}

    def hybrid_scan(self, target):
        """Hybrid scan: masscan for discovery + nmap for service detection"""
        self.logger.info(f"Running hybrid scan on {target}")
        
        # Step 1: Fast port discovery with masscan
        masscan_results = self.masscan_scan(target)
        
        if masscan_results and masscan_results['total_ports'] > 0:
            # Step 2: Extract discovered ports
            open_ports = [str(port['port']) for port in masscan_results['ports']]
            port_list = ','.join(open_ports[:100])  # Limit to first 100 ports
            
            self.logger.info(f"Masscan found {len(open_ports)} ports, running nmap service detection")
            
            # Step 3: Service detection with nmap on discovered ports
            output_file = self.output_dir / 'nmap' / f'{target}_hybrid'
            
            cmd = [
                'nmap',
                '-sV', '-sC',  # Service detection and default scripts
                '-p', port_list,
                '-oA', str(output_file),
                '--open',
                target
            ]
            
            nmap_results = self._run_nmap_command(cmd, target, 'hybrid')
            
            # Merge results
            if nmap_results:
                # Update masscan results with nmap service info
                nmap_ports = {p['port']: p for host in nmap_results.get('hosts', []) for p in host.get('ports', [])}
                
                for port in masscan_results['ports']:
                    port_num = str(port['port'])
                    if port_num in nmap_ports:
                        port.update(nmap_ports[port_num])
                
                masscan_results['scan_type'] = 'hybrid'
                masscan_results['service_detection'] = True
                
            return masscan_results
        else:
            # Fallback to basic nmap scan
            self.logger.info("Masscan found no ports, falling back to nmap basic scan")
            return self.basic_scan(target)


# ============================== SUBDOMAIN ENUMERATOR ==============================
class SubdomainEnumerator:
    """Subdomain enumeration using multiple tools"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.subdomains = set()
        
    def enumerate(self, domain):
        """Run comprehensive subdomain enumeration"""
        self.logger.info(f"Starting subdomain enumeration for {domain}")
        
        # Create results structure
        results = {
            'domain': domain,
            'subdomains': [],
            'live_subdomains': [],
            'tools_used': [],
            'total_found': 0,
            'total_live': 0
        }
        
        # Check if we're in offline mode
        offline_mode = self.config.get('mode', 'offline', False) or self.config.get('general', 'offline_mode', False)
        
        if offline_mode:
            # Run offline enumeration methods
            self.logger.info("Running in offline mode - using internal enumeration methods")
            self._dns_bruteforce(domain, results)
            self._zone_transfer(domain, results)
            self._san_from_cert(domain, results)
        else:
            # Run online enumeration methods
            self._run_sublist3r(domain, results)
            self._run_assetfinder(domain, results)
            self._run_subfinder(domain, results)
            self._run_crtsh(domain, results)
        
        # Deduplicate and validate subdomains
        unique_subdomains = list(self.subdomains)
        results['subdomains'] = unique_subdomains
        results['total_found'] = len(unique_subdomains)
        
        # Check which subdomains are live
        live_subdomains = self._validate_subdomains(unique_subdomains[:50])  # Limit for performance
        results['live_subdomains'] = live_subdomains
        results['total_live'] = len(live_subdomains)
        
        # Save results
        self._save_results(domain, results)
        
        self.logger.info(f"Found {results['total_found']} subdomains, {results['total_live']} live")
        return [sub['subdomain'] for sub in live_subdomains]
    
    def _run_sublist3r(self, domain, results):
        """Run Sublist3r for subdomain enumeration"""
        try:
            self.logger.info("Running Sublist3r...")
            output_file = self.output_dir / 'subdomains' / f'{domain}_sublist3r.txt'
            
            cmd = [
                'sublist3r',
                '-d', domain,
                '-o', str(output_file)
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config.get('subdomains', 'timeout', 300)
            )
            
            if result.returncode == 0 and output_file.exists():
                with open(output_file, 'r') as f:
                    subdomains = [line.strip() for line in f if line.strip()]
                    self.subdomains.update(subdomains)
                    results['tools_used'].append('sublist3r')
                    self.logger.info(f"Sublist3r found {len(subdomains)} subdomains")
            
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            self.logger.warning(f"Sublist3r error: {str(e)}")
    
    def _run_assetfinder(self, domain, results):
        """Run Assetfinder for subdomain enumeration"""
        try:
            self.logger.info("Running Assetfinder...")
            
            cmd = ['assetfinder', domain]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config.get('subdomains', 'timeout', 300)
            )
            
            if result.returncode == 0:
                subdomains = [line.strip() for line in result.stdout.split('\n') if line.strip()]
                self.subdomains.update(subdomains)
                results['tools_used'].append('assetfinder')
                
                # Save output
                output_file = self.output_dir / 'subdomains' / f'{domain}_assetfinder.txt'
                with open(output_file, 'w') as f:
                    f.write(result.stdout)
                
                self.logger.info(f"Assetfinder found {len(subdomains)} subdomains")
            
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            self.logger.warning(f"Assetfinder error: {str(e)}")
    
    def _run_subfinder(self, domain, results):
        """Run Subfinder for subdomain enumeration"""
        try:
            self.logger.info("Running Subfinder...")
            output_file = self.output_dir / 'subdomains' / f'{domain}_subfinder.txt'
            
            cmd = [
                'subfinder',
                '-d', domain,
                '-o', str(output_file),
                '-silent'
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config.get('subdomains', 'timeout', 300)
            )
            
            if result.returncode == 0 and output_file.exists():
                with open(output_file, 'r') as f:
                    subdomains = [line.strip() for line in f if line.strip()]
                    self.subdomains.update(subdomains)
                    results['tools_used'].append('subfinder')
                    self.logger.info(f"Subfinder found {len(subdomains)} subdomains")
            
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            self.logger.warning(f"Subfinder error: {str(e)}")
    
    def _run_crtsh(self, domain, results):
        """Query crt.sh for certificate transparency logs"""
        try:
            self.logger.info("Querying crt.sh...")
            
            url = f"https://crt.sh/?q=%.{domain}&output=json"
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                subdomains = set()
                
                for entry in data[:100]:  # Limit results
                    name_value = entry.get('name_value', '')
                    if name_value:
                        # Handle multiple names in one entry
                        names = name_value.split('\n')
                        for name in names:
                            name = name.strip()
                            if name and domain in name:
                                subdomains.add(name)
                
                self.subdomains.update(subdomains)
                results['tools_used'].append('crt.sh')
                
                self.logger.info(f"crt.sh found {len(subdomains)} subdomains")
            
        except Exception as e:
            self.logger.warning(f"Error querying crt.sh: {str(e)}")
    
    def _dns_bruteforce(self, domain, results):
        """DNS bruteforce using local/internal resolver"""
        try:
            self.logger.info("Running DNS bruteforce...")
            
            # Load DNS wordlist with comprehensive error handling
            wordlist_path = self.config.get('bruteforce', 'dns_wordlist', '/usr/share/wordlists/subdomains.txt')
            
            # Create a basic fallback wordlist
            basic_words = [
                'www', 'mail', 'admin', 'ftp', 'blog', 'test', 'dev', 'staging', 'api',
                'portal', 'intranet', 'vpn', 'secure', 'app', 'web', 'server', 'host',
                'database', 'db', 'sql', 'backup', 'store', 'shop', 'cdn', 'static',
                'img', 'images', 'media', 'assets', 'files', 'docs', 'help', 'support'
            ]
            
            # Attempt to load custom wordlist with proper error handling
            if not wordlist_path or not os.path.exists(wordlist_path):
                if wordlist_path:
                    self.logger.warning(f"DNS wordlist not found: {wordlist_path}, using built-in wordlist")
                else:
                    self.logger.info("No DNS wordlist specified, using built-in wordlist")
                self.logger.info(f"Using built-in DNS wordlist ({len(basic_words)} words)")
                wordlist = basic_words
            else:
                try:
                    with open(wordlist_path, 'r', encoding='utf-8', errors='ignore') as f:
                        wordlist = [line.strip() for line in f if line.strip() and not line.startswith('#')][:1000]  # Limit for performance
                        if wordlist:
                            self.logger.info(f"Loaded DNS wordlist from {wordlist_path} ({len(wordlist)} words)")
                        else:
                            self.logger.warning(f"DNS wordlist is empty: {wordlist_path}, using built-in wordlist")
                            wordlist = basic_words
                except (IOError, OSError, PermissionError) as e:
                    self.logger.error(f"Cannot read DNS wordlist '{wordlist_path}': {str(e)}, using built-in wordlist")
                    wordlist = basic_words
                except Exception as e:
                    self.logger.error(f"Unexpected error loading DNS wordlist '{wordlist_path}': {str(e)}, using built-in wordlist")
                    wordlist = basic_words
            
            # Configure DNS resolver
            resolver = dns.resolver.Resolver()
            dns_servers = self.config.get('dns', 'servers', [])
            if dns_servers:
                resolver.nameservers = dns_servers
                self.logger.info(f"Using DNS servers: {dns_servers}")
            
            # Detect wildcard DNS by testing multiple random labels
            wildcard_ips = set()
            try:
                import random
                import string
                
                # Test multiple random labels to catch round-robin wildcards
                for i in range(3):
                    # Generate a truly random label
                    random_string = ''.join(random.choices(string.ascii_lowercase + string.digits, k=12))
                    random_label = f"nonexistent-{random_string}-{i}.{domain}"
                    
                    try:
                        answer = resolver.resolve(random_label, 'A')
                        # Collect all IPs from the response (in case of multiple A records)
                        for record in answer:
                            wildcard_ips.add(str(record))
                        self.logger.debug(f"Wildcard test {i+1}: {random_label} -> {[str(r) for r in answer]}")
                    except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer):
                        # This is good - means no wildcard for this test
                        pass
                    except Exception as e:
                        self.logger.debug(f"Wildcard test {i+1} error: {str(e)}")
                
                if wildcard_ips:
                    self.logger.info(f"Wildcard DNS detected! IPs: {sorted(wildcard_ips)}")
                else:
                    self.logger.info("No wildcard DNS detected")
                    
            except Exception as e:
                self.logger.warning(f"Wildcard detection error: {str(e)}")
                wildcard_ips = set()  # Continue without wildcard detection
            
            # Bruteforce subdomains
            found_subdomains = []
            for word in wordlist[:500]:  # Limit for performance
                subdomain = f"{word}.{domain}"
                try:
                    answer = resolver.resolve(subdomain, 'A')
                    
                    # Check all A records returned
                    subdomain_ips = set(str(record) for record in answer)
                    
                    # Skip if all IPs match wildcard IPs
                    if wildcard_ips and subdomain_ips.issubset(wildcard_ips):
                        self.logger.debug(f"Skipping {subdomain} - matches wildcard IP(s)")
                        continue
                    
                    # Also skip if ANY IP matches wildcard (more conservative approach)
                    if wildcard_ips and subdomain_ips.intersection(wildcard_ips):
                        self.logger.debug(f"Skipping {subdomain} - contains wildcard IP")
                        continue
                    
                    found_subdomains.append(subdomain)
                    self.subdomains.add(subdomain)
                    
                except dns.resolver.NXDOMAIN:
                    pass  # Domain doesn't exist
                except Exception as e:
                    self.logger.debug(f"DNS error for {subdomain}: {str(e)}")
            
            results['tools_used'].append('dns_bruteforce')
            
            # Save bruteforce results
            output_file = self.output_dir / 'subdomains' / f'{domain}_dns_bruteforce.txt'
            with open(output_file, 'w') as f:
                for subdomain in found_subdomains:
                    f.write(f"{subdomain}\n")
            
            self.logger.info(f"DNS bruteforce found {len(found_subdomains)} subdomains")
            
        except Exception as e:
            self.logger.warning(f"DNS bruteforce error: {str(e)}")
    
    def _zone_transfer(self, domain, results):
        """Attempt zone transfer (AXFR)"""
        try:
            self.logger.info("Attempting zone transfer (AXFR)...")
            
            # Get NS records using dig
            ns_records = []
            try:
                cmd = ['dig', '+short', domain, 'NS']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    ns_records = [line.strip().rstrip('.') for line in result.stdout.strip().split('\n') if line.strip()]
            except Exception as e:
                self.logger.debug(f"Error getting NS records with dig: {str(e)}")
            
            # Fallback to dns.resolver for NS records
            if not ns_records:
                try:
                    resolver = dns.resolver.Resolver()
                    dns_servers = self.config.get('dns', 'servers', [])
                    if dns_servers:
                        resolver.nameservers = dns_servers
                    
                    answer = resolver.resolve(domain, 'NS')
                    ns_records = [str(rdata).rstrip('.') for rdata in answer]
                except Exception as e:
                    self.logger.debug(f"Error getting NS records with resolver: {str(e)}")
            
            if not ns_records:
                self.logger.info("No NS records found for zone transfer")
                return
            
            self.logger.info(f"Found {len(ns_records)} NS records: {ns_records}")
            
            # Try zone transfer on each NS
            transfer_results = []
            for ns in ns_records[:3]:  # Limit NS servers
                try:
                    self.logger.info(f"Trying zone transfer from {ns}")
                    
                    # Use dns.query.xfr for zone transfer if available
                    if HAS_DNS_QUERY:
                        try:
                            self.logger.debug(f"Attempting AXFR from {ns}...")
                            xfr = dns.query.xfr(ns, domain, timeout=30)
                            zone = dns.zone.from_xfr(xfr)
                            
                            # Extract subdomains from zone
                            for name, node in zone.nodes.items():
                                if name != dns.name.empty:
                                    subdomain = f"{name}.{domain}".rstrip('.')
                                    if subdomain != domain:  # Exclude apex domain
                                        transfer_results.append(subdomain)
                                        self.subdomains.add(subdomain)
                            
                            self.logger.info(f"Zone transfer successful from {ns}: {len(transfer_results)} records")
                            break  # Success, no need to try other NS
                            
                        except dns.exception.DNSException as e:
                            # Specific DNS exceptions (refused, timeout, etc.)
                            if "refused" in str(e).lower() or "REFUSED" in str(e):
                                self.logger.info(f"AXFR refused by {ns} (expected security measure)")
                            elif "timeout" in str(e).lower() or "TIMEOUT" in str(e):
                                self.logger.info(f"AXFR timeout from {ns}")
                            elif "NOTAUTH" in str(e):
                                self.logger.info(f"AXFR not authorized by {ns}")
                            else:
                                self.logger.info(f"AXFR failed from {ns}: {str(e)}")
                        except Exception as e:
                            # Other non-DNS exceptions
                            self.logger.debug(f"Zone transfer error from {ns}: {str(e)}")
                    else:
                        self.logger.info("dns.query not available - skipping zone transfer")
                        break
                        
                except Exception as e:
                    self.logger.debug(f"Error with NS {ns}: {str(e)}")
            
            if transfer_results:
                results['tools_used'].append('zone_transfer')
                
                # Save zone transfer results
                output_file = self.output_dir / 'subdomains' / f'{domain}_zone_transfer.txt'
                with open(output_file, 'w') as f:
                    for subdomain in transfer_results:
                        f.write(f"{subdomain}\n")
                
                self.logger.info(f"Zone transfer found {len(transfer_results)} subdomains")
            else:
                self.logger.info("Zone transfer not allowed or failed")
                
        except Exception as e:
            self.logger.warning(f"Zone transfer error: {str(e)}")
    
    def _san_from_cert(self, domain, results):
        """Extract subdomains from certificate Subject Alternative Names (SAN)"""
        try:
            self.logger.info("Extracting subdomains from SSL certificates...")
            
            # Get target IPs
            target_ips = []
            try:
                # Try to resolve domain to IP
                import socket
                ip = socket.gethostbyname(domain)
                target_ips.append(ip)
            except:
                # If resolution fails, try the domain itself if it looks like an IP
                try:
                    ipaddress.ip_address(domain)
                    target_ips.append(domain)
                except:
                    self.logger.info(f"Could not resolve {domain} to IP for certificate analysis")
                    return
            
            # Common SSL ports to check
            ssl_ports = [443, 8443, 8080, 8000, 9443]
            found_subdomains = []
            
            for ip in target_ips:
                for port in ssl_ports:
                    try:
                        self.logger.debug(f"Checking SSL certificate on {ip}:{port}")
                        
                        # Create SSL context
                        context = ssl.create_default_context()
                        context.check_hostname = False
                        context.verify_mode = ssl.CERT_NONE
                        
                        # Connect and get certificate
                        with socket.create_connection((ip, port), timeout=10) as sock:
                            with context.wrap_socket(sock, server_hostname=domain) as ssock:
                                cert_der = ssock.getpeercert_chain()[0]
                                
                                # Parse certificate with cryptography
                                if HAS_CRYPTO:
                                    cert = x509.load_der_x509_certificate(cert_der.public_bytes(ssl.ENCODING_DER), default_backend())
                                    
                                    # Extract SAN extension
                                    try:
                                        san_ext = cert.extensions.get_extension_for_oid(x509.oid.ExtensionOID.SUBJECT_ALTERNATIVE_NAME)
                                        san_names = san_ext.value
                                        
                                        for name in san_names:
                                            if isinstance(name, x509.DNSName):
                                                dns_name = str(name.value)
                                                # Check if it's a subdomain of our target domain
                                                if dns_name.endswith(f'.{domain}') or dns_name == domain:
                                                    found_subdomains.append(dns_name)
                                                    self.subdomains.add(dns_name)
                                                    
                                        self.logger.info(f"Found {len(san_names)} SAN entries on {ip}:{port}")
                                        
                                    except x509.ExtensionNotFound:
                                        self.logger.debug(f"No SAN extension found on {ip}:{port}")
                                        
                                else:
                                    # Fallback to basic certificate parsing
                                    cert_info = ssock.getpeercert()
                                    san_list = cert_info.get('subjectAltName', [])
                                    
                                    for san_type, san_value in san_list:
                                        if san_type == 'DNS':
                                            if san_value.endswith(f'.{domain}') or san_value == domain:
                                                found_subdomains.append(san_value)
                                                self.subdomains.add(san_value)
                                    
                                    self.logger.info(f"Found {len(san_list)} SAN entries on {ip}:{port} (basic parsing)")
                        
                        # If we found a working SSL port, we can stop checking other ports for this IP
                        if found_subdomains:
                            break
                            
                    except (ConnectionRefusedError, ssl.SSLError, socket.timeout):
                        # Port not open or SSL not available
                        continue
                    except Exception as e:
                        self.logger.debug(f"SSL error on {ip}:{port}: {str(e)}")
                        continue
            
            if found_subdomains:
                results['tools_used'].append('cert_san')
                
                # Remove duplicates
                unique_sans = list(set(found_subdomains))
                
                # Save SAN results
                output_file = self.output_dir / 'subdomains' / f'{domain}_cert_san.txt'
                with open(output_file, 'w') as f:
                    for subdomain in unique_sans:
                        f.write(f"{subdomain}\n")
                
                self.logger.info(f"Certificate SAN analysis found {len(unique_sans)} subdomains")
            else:
                self.logger.info("No subdomains found in certificate SANs")
                
        except Exception as e:
            self.logger.warning(f"Certificate SAN analysis error: {str(e)}")
    
    def _validate_subdomains(self, subdomains):
        """Validate which subdomains are live using HTTP probes"""
        self.logger.info("Validating live subdomains...")
        
        live_subdomains = []
        
        def check_http(subdomain):
            for scheme in ['https', 'http']:
                try:
                    url = f"{scheme}://{subdomain}"
                    response = requests.head(url, timeout=5, allow_redirects=True)
                    if response.status_code < 400:
                        return {
                            'subdomain': subdomain,
                            'url': url,
                            'status_code': response.status_code
                        }
                except:
                    continue
            return None
        
        threads = min(self.config.get('subdomains', 'threads', 20), 20)  # Limit threads
        
        with ThreadPoolExecutor(max_workers=threads) as executor:
            futures = [executor.submit(check_http, sub) for sub in subdomains]
            
            for future in futures:
                try:
                    result = future.result(timeout=10)
                    if result:
                        live_subdomains.append(result)
                except:
                    continue
        
        return live_subdomains
    
    def _save_results(self, domain, results):
        """Save enumeration results"""
        # Save JSON results
        json_file = self.output_dir / 'subdomains' / f'{domain}_results.json'
        with open(json_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        # Save all subdomains to text file
        all_subs_file = self.output_dir / 'subdomains' / f'{domain}_all_subdomains.txt'
        with open(all_subs_file, 'w') as f:
            for subdomain in sorted(results['subdomains']):
                f.write(f"{subdomain}\n")
        
        self.logger.info(f"Subdomain results saved to {json_file}")


# ============================== WEB SCANNER ==============================
class WebScanner:
    """Web application scanner wrapper"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def scan_target(self, target):
        """Run comprehensive web application scan"""
        self.logger.info(f"Starting web application scan for {target}")
        
        results = {
            'target': target,
            'nikto': {},
            'technology_stack': {},
            'security_headers': {},
            'directories': []
        }
        
        # Determine if target is HTTP/HTTPS accessible
        urls = self._get_web_urls(target)
        
        for url in urls[:2]:  # Limit to 2 URLs
            self.logger.info(f"Scanning {url}")
            
            # Run Nikto scan
            nikto_results = self._run_nikto(url)
            results['nikto'][url] = nikto_results
            
            # Technology stack detection
            tech_stack = self._detect_technology_stack(url)
            results['technology_stack'][url] = tech_stack
            
            # Security headers analysis
            headers = self._analyze_security_headers(url)
            results['security_headers'][url] = headers
            
            # Directory brute force
            directories = self._brute_force_dirs(url)
            results['directories'].extend(directories)
            
            # Enhanced directory discovery with modern tools
            enhanced_dirs = self._enhanced_directory_discovery(url)
            results['directories'].extend(enhanced_dirs)
        
        # Save results
        self._save_web_results(target, results)
        
        return results
    
    def _get_web_urls(self, target):
        """Get HTTP/HTTPS URLs for target"""
        urls = []
        
        # If target is already a URL, use it
        if target.startswith('http'):
            urls.append(target)
        else:
            # Try both HTTP and HTTPS
            for scheme in ['https', 'http']:
                url = f"{scheme}://{target}"
                try:
                    response = requests.head(url, timeout=10, allow_redirects=True)
                    if response.status_code < 400:
                        urls.append(url)
                except:
                    continue
        
        return urls if urls else [f"http://{target}"]  # Fallback
    
    def _run_nikto(self, url):
        """Run Nikto web vulnerability scanner"""
        try:
            self.logger.info(f"Running Nikto on {url}")
            
            output_file = self.output_dir / 'web' / f'nikto_{self._sanitize_url(url)}.txt'
            
            cmd = [
                'nikto',
                '-h', url,
                '-output', str(output_file),
                '-Format', 'txt'
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config.get('web', 'timeout', 300)
            )
            
            nikto_results = {
                'return_code': result.returncode,
                'findings': []
            }
            
            if output_file.exists():
                with open(output_file, 'r') as f:
                    content = f.read()
                    # Simple parsing of Nikto output
                    lines = content.split('\n')
                    for line in lines:
                        if line.startswith('+'):
                            nikto_results['findings'].append(line.strip())
            
            return nikto_results
            
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            self.logger.warning(f"Nikto error: {str(e)}")
            return {'error': str(e)}
    
    def _detect_technology_stack(self, url):
        """Enhanced technology stack detection with Wappalyzer-style analysis"""
        try:
            response = requests.get(url, timeout=10, allow_redirects=True)
            
            tech_stack = {
                'server': response.headers.get('Server', ''),
                'powered_by': response.headers.get('X-Powered-By', ''),
                'framework': [],
                'cms': [],
                'programming_language': [],
                'web_servers': [],
                'databases': [],
                'javascript_libraries': [],
                'cdn': [],
                'analytics': [],
                'confidence_score': 0
            }
            
            # Analyze headers, content, and scripts
            content = response.text.lower()
            headers = response.headers
            
            # Enhanced detection patterns
            detection_patterns = {
                'cms': [
                    ('WordPress', r'wp-content|wp-includes|wordpress|wp-json', 'meta[name="generator"][content*="wordpress"]'),
                    ('Drupal', r'drupal|sites/default|misc/drupal\.js', 'meta[name="generator"][content*="drupal"]'),
                    ('Joomla', r'joomla|com_content|media/jui', 'meta[name="generator"][content*="joomla"]'),
                    ('Magento', r'magento|mage/|skin/frontend', 'var BLANK_URL'),
                    ('Shopify', r'shopify|cdn\.shopify\.com', 'shopify'),
                    ('PrestaShop', r'prestashop|ps_', 'prestashop'),
                ],
                'frameworks': [
                    ('React', r'react|__react|data-reactroot', '_react'),
                    ('Angular', r'angular|ng-|angularjs', 'angular'),
                    ('Vue.js', r'vue\.js|__vue__|v-if|v-for', 'vue'),
                    ('Laravel', r'laravel_session|laravel_token', 'laravel'),
                    ('Django', r'django|csrfmiddlewaretoken', 'django'),
                    ('Ruby on Rails', r'rails|csrf-token|authenticity_token', 'rails'),
                    ('Express.js', r'express|x-powered-by.*express', 'express'),
                    ('Spring', r'spring|jsessionid|java_session', 'spring'),
                ],
                'languages': [
                    ('PHP', r'\.php|php|x-powered-by.*php', 'phpsessid'),
                    ('ASP.NET', r'\.aspx|asp\.net|x-aspnet-version', 'asp.net_sessionid'),
                    ('Java', r'\.jsp|\.jsf|jsessionid', 'java'),
                    ('Python', r'\.py|django|flask|wsgi', 'python'),
                    ('Node.js', r'node\.js|express|x-powered-by.*express', 'nodejs'),
                    ('Ruby', r'\.rb|rails|ruby', 'ruby'),
                ],
                'servers': [
                    ('Apache', r'apache|httpd', 'server.*apache'),
                    ('Nginx', r'nginx', 'server.*nginx'),
                    ('IIS', r'iis|microsoft-iis', 'server.*iis'),
                    ('LiteSpeed', r'litespeed|lsws', 'server.*litespeed'),
                    ('Cloudflare', r'cloudflare|cf-ray', 'cf-ray'),
                ],
                'js_libraries': [
                    ('jQuery', r'jquery|jquery\.min\.js', 'jquery'),
                    ('Bootstrap', r'bootstrap|bootstrap\.min\.css', 'bootstrap'),
                    ('Modernizr', r'modernizr', 'modernizr'),
                    ('Underscore.js', r'underscore\.js|_\.', 'underscore'),
                    ('Moment.js', r'moment\.js', 'moment'),
                ],
                'analytics': [
                    ('Google Analytics', r'google-analytics|ga\.js|gtag', 'ua-'),
                    ('Google Tag Manager', r'googletagmanager', 'gtm'),
                    ('Adobe Analytics', r'omniture|adobe.*analytics', 'omniture'),
                    ('Hotjar', r'hotjar', 'hotjar'),
                ],
                'cdn': [
                    ('Cloudflare', r'cloudflare|cf-ray', 'cf-ray'),
                    ('AWS CloudFront', r'cloudfront', 'cloudfront'),
                    ('Fastly', r'fastly', 'fastly'),
                    ('MaxCDN', r'maxcdn', 'maxcdn'),
                ]
            }
            
            confidence = 0
            
            # Check each category
            for category, patterns in detection_patterns.items():
                for tech_name, content_pattern, header_pattern in patterns:
                    score = 0
                    
                    # Check content patterns
                    if re.search(content_pattern, content):
                        score += 1
                        
                    # Check header patterns
                    for header_name, header_value in headers.items():
                        if re.search(header_pattern, f"{header_name}: {header_value}".lower()):
                            score += 2  # Headers are more reliable
                            
                    if score > 0:
                        category_key = category.rstrip('s')  # Remove 's' for dict key
                        if category_key not in tech_stack:
                            tech_stack[category_key] = []
                        tech_stack[category_key].append({
                            'name': tech_name,
                            'confidence': min(score * 33, 100)  # Cap at 100%
                        })
                        confidence += score
            
            # Special detection for specific technologies
            self._detect_cms_specific(url, tech_stack, content, headers)
            self._detect_api_technologies(url, tech_stack)
            
            tech_stack['confidence_score'] = min(confidence * 10, 100)
            return tech_stack
            
        except Exception as e:
            self.logger.error(f"Error detecting technology stack: {str(e)}")
            return {}
    
    def _detect_cms_specific(self, url, tech_stack, content, headers):
        """Specific CMS detection with version discovery"""
        try:
            # WordPress specific
            if any('wordpress' in item['name'].lower() for item in tech_stack.get('cms', [])):
                wp_version = self._get_wordpress_version(url, content)
                if wp_version:
                    for item in tech_stack['cms']:
                        if 'wordpress' in item['name'].lower():
                            item['version'] = wp_version
                            
            # Check for admin panels
            admin_paths = [
                '/wp-admin/', '/admin/', '/administrator/', '/admin.php',
                '/wp-login.php', '/login/', '/dashboard/'
            ]
            
            accessible_admin = []
            for path in admin_paths:
                try:
                    admin_url = urljoin(url, path)
                    resp = requests.get(admin_url, timeout=5, allow_redirects=True)
                    if resp.status_code == 200:
                        accessible_admin.append(path)
                except:
                    continue
                    
            if accessible_admin:
                tech_stack['admin_panels'] = accessible_admin
                
        except Exception as e:
            self.logger.debug(f"CMS specific detection error: {str(e)}")
    
    def _get_wordpress_version(self, url, content):
        """Get WordPress version"""
        try:
            # Check generator meta tag
            version_match = re.search(r'wordpress\s+([\d\.]+)', content)
            if version_match:
                return version_match.group(1)
                
            # Check readme.html
            readme_url = urljoin(url, '/readme.html')
            resp = requests.get(readme_url, timeout=5)
            if resp.status_code == 200:
                version_match = re.search(r'version\s+([\d\.]+)', resp.text.lower())
                if version_match:
                    return version_match.group(1)
                    
        except Exception:
            pass
        return None
    
    def _detect_api_technologies(self, url, tech_stack):
        """Detect API-related technologies"""
        try:
            api_endpoints = [
                '/api/', '/api/v1/', '/api/v2/', '/rest/', '/graphql',
                '/swagger/', '/openapi.json', '/api-docs'
            ]
            
            api_info = []
            for endpoint in api_endpoints:
                try:
                    api_url = urljoin(url, endpoint)
                    resp = requests.get(api_url, timeout=5)
                    if resp.status_code in [200, 401, 403]:  # API exists but may need auth
                        api_info.append({
                            'endpoint': endpoint,
                            'status': resp.status_code,
                            'content_type': resp.headers.get('Content-Type', '')
                        })
                except:
                    continue
                    
            if api_info:
                tech_stack['api_endpoints'] = api_info
                
        except Exception as e:
            self.logger.debug(f"API detection error: {str(e)}")
    
    def api_fuzzing(self, base_url, endpoints=None):
        """Enhanced API fuzzing and enumeration"""
        try:
            print(f"\nüîç Starting API fuzzing for: {base_url}")
            
            results = {
                'discovered_endpoints': [],
                'parameter_fuzzing': {},
                'authentication_tests': {},
                'rate_limiting': {},
                'security_headers': {}
            }
            
            if not endpoints:
                endpoints = self._discover_api_endpoints(base_url)
            
            for endpoint in endpoints:
                full_url = urljoin(base_url, endpoint)
                print(f"   üì° Testing endpoint: {endpoint}")
                
                # Test different HTTP methods
                methods = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS', 'HEAD']
                endpoint_results = {}
                
                for method in methods:
                    try:
                        resp = requests.request(method, full_url, timeout=10)
                        endpoint_results[method] = {
                            'status_code': resp.status_code,
                            'response_time': resp.elapsed.total_seconds(),
                            'content_length': len(resp.content),
                            'headers': dict(resp.headers)
                        }
                        
                        # Check for interesting responses
                        if resp.status_code in [200, 201, 202, 400, 401, 403, 422]:
                            endpoint_results[method]['interesting'] = True
                            
                    except Exception as e:
                        endpoint_results[method] = {'error': str(e)}
                
                results['discovered_endpoints'].append({
                    'endpoint': endpoint,
                    'methods': endpoint_results
                })
                
                # Parameter fuzzing for GET endpoints
                if endpoint_results.get('GET', {}).get('status_code') == 200:
                    param_results = self._fuzz_parameters(full_url)
                    if param_results:
                        results['parameter_fuzzing'][endpoint] = param_results
                
                # Rate limiting test
                rate_limit = self._test_rate_limiting(full_url)
                if rate_limit:
                    results['rate_limiting'][endpoint] = rate_limit
            
            # Authentication bypass tests
            results['authentication_tests'] = self._test_auth_bypass(base_url)
            
            print(f"‚úÖ API fuzzing completed. Found {len(results['discovered_endpoints'])} endpoints")
            return results
            
        except Exception as e:
            self.logger.error(f"API fuzzing error: {str(e)}")
            return {}
    
    def _discover_api_endpoints(self, base_url):
        """Discover API endpoints through various methods"""
        endpoints = set()
        
        # Common API paths
        common_paths = [
            '/api/', '/api/v1/', '/api/v2/', '/api/v3/',
            '/rest/', '/graphql', '/swagger/', '/openapi.json',
            '/api-docs', '/docs/', '/documentation/',
            '/users/', '/user/', '/admin/', '/auth/',
            '/login/', '/register/', '/profile/', '/settings/',
            '/products/', '/orders/', '/payments/', '/search/'
        ]
        
        print("   üîç Discovering API endpoints...")
        for path in common_paths:
            try:
                url = urljoin(base_url, path)
                resp = requests.get(url, timeout=5)
                if resp.status_code not in [404, 502, 503]:
                    endpoints.add(path)
            except:
                continue
        
        # Try to find endpoints from JavaScript files
        try:
            resp = requests.get(base_url, timeout=10)
            js_urls = re.findall(r'src=["\']([^"\']*\.js[^"\']*)["\']', resp.text)
            
            for js_url in js_urls[:5]:  # Limit to first 5 JS files
                full_js_url = urljoin(base_url, js_url)
                try:
                    js_resp = requests.get(full_js_url, timeout=5)
                    # Look for API endpoints in JS
                    api_patterns = re.findall(r'["\'](/api/[^"\']*)["\']', js_resp.text)
                    endpoints.update(api_patterns)
                except:
                    continue
        except:
            pass
            
        return list(endpoints)
    
    def _fuzz_parameters(self, url):
        """Fuzz common parameters"""
        common_params = [
            'id', 'user_id', 'username', 'email', 'token', 'key',
            'page', 'limit', 'offset', 'search', 'query', 'filter',
            'sort', 'order', 'category', 'type', 'format', 'callback'
        ]
        
        interesting_responses = []
        
        for param in common_params:
            test_values = ['1', 'admin', 'test', '../', 'null', '0', '-1']
            
            for value in test_values:
                try:
                    resp = requests.get(url, params={param: value}, timeout=5)
                    
                    # Check for interesting status codes or content changes
                    if resp.status_code in [200, 400, 422, 500] and len(resp.content) > 100:
                        interesting_responses.append({
                            'parameter': param,
                            'value': value,
                            'status_code': resp.status_code,
                            'content_length': len(resp.content)
                        })
                        break  # Found interesting response, move to next param
                except:
                    continue
                    
        return interesting_responses
    
    def _test_rate_limiting(self, url):
        """Test for rate limiting"""
        try:
            response_times = []
            status_codes = []
            
            for i in range(10):  # Make 10 rapid requests
                start_time = time.time()
                resp = requests.get(url, timeout=5)
                response_time = time.time() - start_time
                
                response_times.append(response_time)
                status_codes.append(resp.status_code)
                
                # Check for rate limiting status codes
                if resp.status_code in [429, 503]:
                    return {
                        'rate_limited': True,
                        'status_code': resp.status_code,
                        'request_number': i + 1,
                        'retry_after': resp.headers.get('Retry-After')
                    }
                    
            # Check if response times increased significantly
            if len(response_times) > 5:
                avg_first_half = sum(response_times[:5]) / 5
                avg_second_half = sum(response_times[5:]) / len(response_times[5:])
                
                if avg_second_half > avg_first_half * 2:  # 2x slower
                    return {
                        'potential_rate_limiting': True,
                        'avg_response_time_increase': avg_second_half / avg_first_half
                    }
                    
        except Exception:
            pass
            
        return None
    
    def _test_auth_bypass(self, base_url):
        """Test common authentication bypass techniques"""
        bypass_tests = {
            'headers': [
                {'X-Forwarded-For': '127.0.0.1'},
                {'X-Real-IP': '127.0.0.1'},
                {'X-Originating-IP': '127.0.0.1'},
                {'X-Remote-IP': '127.0.0.1'},
                {'X-Client-IP': '127.0.0.1'},
                {'X-Original-URL': '/admin'},
                {'X-Rewrite-URL': '/admin'},
            ],
            'parameters': [
                {'admin': 'true'},
                {'debug': '1'},
                {'test': '1'},
                {'role': 'admin'},
                {'privilege': 'admin'}
            ]
        }
        
        results = {}
        protected_endpoints = ['/admin/', '/api/admin/', '/dashboard/', '/profile/']
        
        for endpoint in protected_endpoints:
            url = urljoin(base_url, endpoint)
            endpoint_results = []
            
            try:
                # Baseline request
                baseline = requests.get(url, timeout=5)
                baseline_status = baseline.status_code
                
                # Test header bypasses
                for headers in bypass_tests['headers']:
                    try:
                        resp = requests.get(url, headers=headers, timeout=5)
                        if resp.status_code != baseline_status and resp.status_code == 200:
                            endpoint_results.append({
                                'type': 'header_bypass',
                                'method': headers,
                                'status_code': resp.status_code
                            })
                    except:
                        continue
                
                # Test parameter bypasses
                for params in bypass_tests['parameters']:
                    try:
                        resp = requests.get(url, params=params, timeout=5)
                        if resp.status_code != baseline_status and resp.status_code == 200:
                            endpoint_results.append({
                                'type': 'parameter_bypass',
                                'method': params,
                                'status_code': resp.status_code
                            })
                    except:
                        continue
                        
                if endpoint_results:
                    results[endpoint] = endpoint_results
                    
            except:
                continue
                
        return results
    
    def _analyze_security_headers(self, url):
        """Analyze security headers"""
        try:
            response = requests.get(url, timeout=10, allow_redirects=True)
            
            security_headers = {
                'x_frame_options': response.headers.get('X-Frame-Options'),
                'x_content_type_options': response.headers.get('X-Content-Type-Options'),
                'strict_transport_security': response.headers.get('Strict-Transport-Security'),
                'content_security_policy': response.headers.get('Content-Security-Policy'),
                'missing_headers': []
            }
            
            # Check for missing security headers
            required_headers = [
                'X-Frame-Options',
                'X-Content-Type-Options', 
                'Strict-Transport-Security',
                'Content-Security-Policy'
            ]
            
            for header in required_headers:
                if header not in response.headers:
                    security_headers['missing_headers'].append(header)
            
            return security_headers
            
        except Exception as e:
            self.logger.error(f"Error analyzing security headers: {str(e)}")
            return {}
    
    def _sanitize_url(self, url):
        """Sanitize URL for filename"""
        return re.sub(r'[^\w\-_\.]', '_', url)
    
    def _brute_force_dirs(self, url):
        """Brute force directories and common files with concurrency control and rate limiting"""
        try:
            self.logger.info(f"Starting directory brute force for {url}")
            
            # Load directory wordlist with comprehensive error handling
            wordlist_path = self.config.get('bruteforce', 'dir_wordlist', '/usr/share/wordlists/dirb/common.txt')
            
            # Create a basic directory/file wordlist as fallback
            basic_dirs = [
                # Common directories
                'admin', 'administrator', 'login', 'uploads', 'images', 'img', 'css', 'js',
                'api', 'config', 'backup', 'backups', 'tmp', 'temp', 'test', 'dev',
                'phpmyadmin', 'wp-admin', 'wp-content', 'wp-includes', 'dashboard', 'panel',
                'control', 'cpanel', 'webmail', 'mail', 'ftp', 'ssh', 'logs', 'log',
                'database', 'db', 'files', 'documents', 'downloads', 'media', 'assets',
                'private', 'secret', 'hidden', 'secure', 'protected', 'include', 'inc',
                
                # Common files
                'robots.txt', 'sitemap.xml', 'favicon.ico', 'crossdomain.xml',
                '.htaccess', '.htpasswd', 'web.config', 'readme.txt', 'README.md',
                'install.php', 'setup.php', 'config.php', 'wp-config.php',
                'phpinfo.php', 'info.php', 'test.php', 'index.bak',
                'backup.sql', 'database.sql', 'dump.sql', '.env', '.git',
                
                # Admin panels and login pages
                'admin.php', 'login.php', 'signin.php', 'auth.php',
                'manager', 'administrator.php', 'moderator.php'
            ]
            
            # Attempt to load custom wordlist with proper error handling
            if not wordlist_path or not os.path.exists(wordlist_path):
                if wordlist_path:
                    self.logger.warning(f"Directory wordlist not found: {wordlist_path}, skipping directory brute force")
                    self.logger.info("To enable directory brute force, specify a valid wordlist with --dir-wordlist")
                    return []  # Skip directory brute force entirely if no wordlist
                else:
                    self.logger.info("No directory wordlist specified, using built-in wordlist")
                    self.logger.info(f"Using built-in directory wordlist ({len(basic_dirs)} entries)")
                    wordlist = basic_dirs
            else:
                try:
                    with open(wordlist_path, 'r', encoding='utf-8', errors='ignore') as f:
                        wordlist = [line.strip() for line in f if line.strip() and not line.startswith('#')]
                        if wordlist:
                            # Limit wordlist size for performance
                            max_words = self.config.get('bruteforce', 'max_words', 5000)
                            if len(wordlist) > max_words:
                                self.logger.info(f"Limiting wordlist from {len(wordlist)} to {max_words} entries")
                                wordlist = wordlist[:max_words]
                            self.logger.info(f"Loaded directory wordlist from {wordlist_path} ({len(wordlist)} entries)")
                        else:
                            self.logger.warning(f"Directory wordlist is empty: {wordlist_path}, skipping directory brute force")
                            return []  # Skip if wordlist is empty
                except (IOError, OSError, PermissionError) as e:
                    self.logger.error(f"Cannot read directory wordlist '{wordlist_path}': {str(e)}, skipping directory brute force")
                    return []  # Skip directory brute force on file errors
                except Exception as e:
                    self.logger.error(f"Unexpected error loading directory wordlist '{wordlist_path}': {str(e)}, skipping directory brute force")
                    return []  # Skip directory brute force on unexpected errors
            
            # Configuration
            timeout = min(self.config.get('web', 'timeout', 5), 10)  # Max 10 seconds
            rate_limit = self.config.get('bruteforce', 'rate_limit', 0)  # Seconds between requests
            max_threads = self.config.get('bruteforce', 'threads', 10)  # Default 10 threads
            max_threads = min(max_threads, 50)  # Cap at 50 threads
            
            # Interesting status codes to save
            interesting_codes = {
                200: 'OK',
                201: 'Created', 
                202: 'Accepted',
                204: 'No Content',
                301: 'Moved Permanently',
                302: 'Found',
                303: 'See Other',
                307: 'Temporary Redirect',
                308: 'Permanent Redirect',
                401: 'Unauthorized',
                403: 'Forbidden',
                405: 'Method Not Allowed',
                500: 'Internal Server Error',
                503: 'Service Unavailable'
            }
            
            self.logger.info(f"Using {max_threads} threads with {rate_limit}s rate limit")
            
            found_directories = []
            processed_count = 0
            
            def test_directory(path):
                """Test a single directory/file path"""
                nonlocal processed_count
                
                try:
                    # Rate limiting
                    if rate_limit > 0:
                        time.sleep(rate_limit)
                    
                    # Construct full URL
                    if not path.startswith('/'):
                        path = '/' + path
                    test_url = url.rstrip('/') + path
                    
                    # Use HEAD request for faster scanning (fallback to GET if needed)
                    try:
                        response = requests.head(
                            test_url,
                            timeout=timeout,
                            allow_redirects=False,
                            headers={
                                'User-Agent': self.config.get('general', 'user_agent', 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')
                            }
                        )
                        
                        # Some servers return 405 for HEAD but allow GET
                        if response.status_code == 405:
                            response = requests.get(
                                test_url,
                                timeout=timeout,
                                allow_redirects=False,
                                headers={
                                    'User-Agent': self.config.get('general', 'user_agent', 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')
                                }
                            )
                            
                    except requests.exceptions.RequestException:
                        # Fallback to GET request
                        response = requests.get(
                            test_url,
                            timeout=timeout,
                            allow_redirects=False,
                            headers={
                                'User-Agent': self.config.get('general', 'user_agent', 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')
                            }
                        )
                    
                    processed_count += 1
                    if processed_count % 100 == 0:
                        self.logger.info(f"Processed {processed_count}/{len(wordlist)} paths...")
                    
                    # Check for interesting status codes
                    if response.status_code in interesting_codes:
                        directory_info = {
                            'path': path,
                            'url': test_url,
                            'status_code': response.status_code,
                            'status_text': interesting_codes.get(response.status_code, 'Unknown'),
                            'size': response.headers.get('Content-Length', 'unknown'),
                            'content_type': response.headers.get('Content-Type', 'unknown'),
                            'server': response.headers.get('Server', 'unknown')
                        }
                        
                        # Add redirect information
                        if response.status_code in [301, 302, 303, 307, 308]:
                            directory_info['location'] = response.headers.get('Location', 'unknown')
                        
                        self.logger.info(f"Found: {test_url} [{response.status_code} {interesting_codes.get(response.status_code, '')}]")
                        return directory_info
                    
                    return None
                    
                except requests.exceptions.Timeout:
                    self.logger.debug(f"Timeout testing {test_url}")
                    return None
                except requests.exceptions.ConnectionError:
                    self.logger.debug(f"Connection error testing {test_url}")
                    return None
                except Exception as e:
                    self.logger.debug(f"Error testing {test_url}: {str(e)}")
                    return None
            
            # Use ThreadPoolExecutor for concurrent requests
            with ThreadPoolExecutor(max_workers=max_threads) as executor:
                futures = [executor.submit(test_directory, path) for path in wordlist]
                
                for future in futures:
                    try:
                        result = future.result(timeout=timeout + 5)  # Give extra time for completion
                        if result:
                            found_directories.append(result)
                    except Exception as e:
                        self.logger.debug(f"Thread execution error: {str(e)}")
            
            # Save directory brute force results
            if found_directories:
                output_file = self.output_dir / 'web' / f'directories_{self._sanitize_url(url)}.txt'
                with open(output_file, 'w') as f:
                    f.write(f"Directory brute force results for {url}\n")
                    f.write(f"Threads: {max_threads}, Rate limit: {rate_limit}s\n")
                    f.write("=" * 60 + "\n\n")
                    
                    for dir_info in sorted(found_directories, key=lambda x: x['status_code']):
                        f.write(f"[{dir_info['status_code']}] {dir_info['url']} ({dir_info['status_text']})\n")
                        
                        if dir_info.get('content_type') != 'unknown':
                            f.write(f"    Content-Type: {dir_info['content_type']}\n")
                        if dir_info.get('size') != 'unknown':
                            f.write(f"    Size: {dir_info['size']} bytes\n")
                        if dir_info.get('server') != 'unknown':
                            f.write(f"    Server: {dir_info['server']}\n")
                        if dir_info.get('location'):
                            f.write(f"    Location: {dir_info['location']}\n")
                        f.write("\n")
                
                self.logger.info(f"Directory brute force found {len(found_directories)} accessible paths")
                
                # Log summary by status code
                status_summary = {}
                for item in found_directories:
                    code = item['status_code']
                    status_summary[code] = status_summary.get(code, 0) + 1
                
                summary_text = ', '.join([f"{code}: {count}" for code, count in sorted(status_summary.items())])
                self.logger.info(f"Status code summary: {summary_text}")
                
            else:
                self.logger.info("No accessible directories found")
            
            return found_directories
            
        except Exception as e:
            self.logger.error(f"Error during directory brute force: {str(e)}")
            return []

    def _enhanced_directory_discovery(self, url):
        """Enhanced directory discovery using multiple tools (gobuster, ffuf, feroxbuster)"""
        self.logger.info(f"Starting enhanced directory discovery for {url}")
        
        discovered_paths = []
        
        # Try gobuster first (if available)
        gobuster_results = self._run_gobuster(url)
        discovered_paths.extend(gobuster_results)
        
        # Try ffuf as alternative (if available)
        if not gobuster_results:
            ffuf_results = self._run_ffuf(url)
            discovered_paths.extend(ffuf_results)
        
        # Try feroxbuster for recursive discovery (if available)
        ferox_results = self._run_feroxbuster(url)
        discovered_paths.extend(ferox_results)
        
        # Deduplicate results
        unique_paths = list(set(discovered_paths))
        
        self.logger.info(f"Enhanced directory discovery found {len(unique_paths)} unique paths")
        return unique_paths

    def _run_gobuster(self, url):
        """Run gobuster for directory discovery"""
        try:
            # Check if gobuster is available
            subprocess.run(['gobuster', '--help'], capture_output=True, check=True)
            
            self.logger.info(f"Running gobuster directory scan on {url}")
            
            # Get wordlist path
            wordlist_path = self.config.get('bruteforce', 'dir_wordlist', '/usr/share/wordlists/dirb/common.txt')
            
            # Fallback wordlists
            fallback_wordlists = [
                '/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt',
                '/usr/share/wordlists/dirb/common.txt',
                '/usr/share/seclists/Discovery/Web-Content/common.txt',
                '/usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt'
            ]
            
            # Find available wordlist
            if not os.path.exists(wordlist_path):
                for fallback in fallback_wordlists:
                    if os.path.exists(fallback):
                        wordlist_path = fallback
                        break
                else:
                    self.logger.warning("No wordlist found for gobuster")
                    return []
            
            output_file = self.output_dir / 'web' / f'gobuster_{self._sanitize_url(url)}.txt'
            
            cmd = [
                'gobuster', 'dir',
                '-u', url,
                '-w', wordlist_path,
                '-o', str(output_file),
                '-t', '50',  # 50 threads
                '-x', 'php,html,txt,js,css,bak,old,backup',  # Common extensions
                '--wildcard',
                '--no-error',
                '--quiet'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            # Parse results
            discovered_paths = []
            if output_file.exists():
                with open(output_file, 'r') as f:
                    for line in f:
                        if line.strip() and not line.startswith('='):
                            # Extract path from gobuster output
                            parts = line.strip().split()
                            if parts:
                                path = parts[0]
                                discovered_paths.append({
                                    'path': path,
                                    'status': parts[1] if len(parts) > 1 else 'unknown',
                                    'size': parts[2] if len(parts) > 2 else 'unknown',
                                    'tool': 'gobuster'
                                })
            
            self.logger.info(f"Gobuster found {len(discovered_paths)} directories/files")
            return discovered_paths
            
        except subprocess.CalledProcessError:
            self.logger.warning("Gobuster not available")
            return []
        except Exception as e:
            self.logger.error(f"Error running gobuster: {str(e)}")
            return []

    def _run_ffuf(self, url):
        """Run ffuf for directory discovery"""
        try:
            # Check if ffuf is available
            subprocess.run(['ffuf', '-h'], capture_output=True, check=True)
            
            self.logger.info(f"Running ffuf directory scan on {url}")
            
            # Get wordlist path
            wordlist_path = self.config.get('bruteforce', 'dir_wordlist', '/usr/share/wordlists/dirb/common.txt')
            
            if not os.path.exists(wordlist_path):
                self.logger.warning("No wordlist found for ffuf")
                return []
            
            output_file = self.output_dir / 'web' / f'ffuf_{self._sanitize_url(url)}.json'
            
            cmd = [
                'ffuf',
                '-u', f"{url}/FUZZ",
                '-w', wordlist_path,
                '-o', str(output_file),
                '-of', 'json',
                '-t', '50',  # 50 threads
                '-mc', '200,204,301,302,307,401,403',  # Match status codes
                '-fs', '0',  # Filter size 0
                '-silent'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            # Parse JSON results
            discovered_paths = []
            if output_file.exists():
                try:
                    with open(output_file, 'r') as f:
                        data = json.load(f)
                        for result in data.get('results', []):
                            discovered_paths.append({
                                'path': f"/{result['input']['FUZZ']}",
                                'status': result['status'],
                                'size': result['length'],
                                'words': result['words'],
                                'tool': 'ffuf'
                            })
                except json.JSONDecodeError:
                    self.logger.warning("Could not parse ffuf JSON output")
            
            self.logger.info(f"Ffuf found {len(discovered_paths)} directories/files")
            return discovered_paths
            
        except subprocess.CalledProcessError:
            self.logger.warning("Ffuf not available")
            return []
        except Exception as e:
            self.logger.error(f"Error running ffuf: {str(e)}")
            return []

    def _run_feroxbuster(self, url):
        """Run feroxbuster for recursive directory discovery"""
        try:
            # Check if feroxbuster is available
            subprocess.run(['feroxbuster', '--help'], capture_output=True, check=True)
            
            self.logger.info(f"Running feroxbuster recursive scan on {url}")
            
            # Get wordlist path
            wordlist_path = self.config.get('bruteforce', 'dir_wordlist', '/usr/share/wordlists/dirb/common.txt')
            
            if not os.path.exists(wordlist_path):
                self.logger.warning("No wordlist found for feroxbuster")
                return []
            
            output_file = self.output_dir / 'web' / f'feroxbuster_{self._sanitize_url(url)}.txt'
            
            cmd = [
                'feroxbuster',
                '-u', url,
                '-w', wordlist_path,
                '-o', str(output_file),
                '-t', '50',  # 50 threads
                '-d', '3',   # Depth of 3
                '-x', 'php,html,txt,js,css,bak,old,backup',  # Extensions
                '--silent',
                '--no-recursion'  # Control recursion manually
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            # Parse results
            discovered_paths = []
            if output_file.exists():
                with open(output_file, 'r') as f:
                    for line in f:
                        if line.strip() and 'HTTP' in line:
                            # Parse feroxbuster output format
                            parts = line.strip().split()
                            if len(parts) >= 4:
                                status = parts[0]
                                size = parts[1]
                                path = parts[-1].replace(url, '')
                                discovered_paths.append({
                                    'path': path,
                                    'status': status,
                                    'size': size,
                                    'tool': 'feroxbuster'
                                })
            
            self.logger.info(f"Feroxbuster found {len(discovered_paths)} directories/files")
            return discovered_paths
            
        except subprocess.CalledProcessError:
            self.logger.warning("Feroxbuster not available")
            return []
        except Exception as e:
            self.logger.error(f"Error running feroxbuster: {str(e)}")
            return []
    
    def _save_web_results(self, target, results):
        """Save web scanning results"""
        json_file = self.output_dir / 'web' / f'{target}_web_results.json'
        with open(json_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        self.logger.info(f"Web scan results saved to {json_file}")
    
    def is_wordpress(self, target):
        """Check if target is running WordPress"""
        try:
            urls = self._get_web_urls(target)
            
            for url in urls[:1]:  # Check only first URL
                response = requests.get(url, timeout=10)
                content = response.text.lower()
                
                # Check for WordPress indicators
                wp_indicators = ['wp-content', 'wp-includes', 'wordpress']
                
                for indicator in wp_indicators:
                    if indicator in content:
                        return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Error checking for WordPress: {str(e)}")
            return False


# ============================== SSL SCANNER ==============================
class SSLScanner:
    """SSL/TLS scanner wrapper"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def scan(self, target):
        """Run comprehensive SSL/TLS analysis"""
        self.logger.info(f"Starting SSL/TLS analysis for {target}")
        
        results = {
            'target': target,
            'certificate_info': {},
            'vulnerabilities': []
        }
        
        # Manual SSL analysis
        cert_info = self._analyze_certificate(target)
        results['certificate_info'] = cert_info
        
        # Vulnerability assessment
        vulnerabilities = self._assess_ssl_vulnerabilities(cert_info)
        results['vulnerabilities'] = vulnerabilities
        
        # Save results
        self._save_ssl_results(target, results)
        
        return results
    
    def _analyze_certificate(self, target):
        """Analyze SSL certificate"""
        try:
            self.logger.info(f"Analyzing SSL certificate for {target}")
            
            # Parse target to get hostname and port
            if ':' in target:
                hostname, port = target.split(':', 1)
                port = int(port)
            else:
                hostname = target
                port = 443
            
            # Get certificate
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            with socket.create_connection((hostname, port), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                    cert = ssock.getpeercert()
            
            cert_info = {
                'subject': dict(x[0] for x in cert['subject']),
                'issuer': dict(x[0] for x in cert['issuer']),
                'serial_number': cert['serialNumber'],
                'not_before': cert['notBefore'],
                'not_after': cert['notAfter'],
                'version': cert['version'],
                'is_expired': self._is_cert_expired(cert['notAfter'])
            }
            
            return cert_info
            
        except Exception as e:
            self.logger.error(f"Error analyzing certificate: {str(e)}")
            return {'error': str(e)}
    
    def _is_cert_expired(self, not_after):
        """Check if certificate is expired"""
        try:
            # Parse cert date format
            from datetime import datetime
            cert_date = datetime.strptime(not_after, '%b %d %H:%M:%S %Y %Z')
            return datetime.now() > cert_date
        except:
            return False
    
    def _assess_ssl_vulnerabilities(self, cert_info):
        """Assess SSL/TLS vulnerabilities"""
        vulnerabilities = []
        
        # Check certificate expiry
        if cert_info.get('is_expired'):
            vulnerabilities.append({
                'type': 'expired_certificate',
                'severity': 'critical',
                'description': 'SSL certificate has expired'
            })
        
        return vulnerabilities
    
    def _save_ssl_results(self, target, results):
        """Save SSL analysis results"""
        json_file = self.output_dir / 'ssl' / f'{target}_ssl_results.json'
        with open(json_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        self.logger.info(f"SSL analysis results saved to {json_file}")


# ============================== OSINT COLLECTOR ==============================
class OSINTCollector:
    """OSINT data collection wrapper"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def collect(self, target):
        """Run comprehensive OSINT collection"""
        self.logger.info(f"Starting OSINT collection for {target}")
        
        results = {
            'target': target,
            'whois': {},
            'dns_records': {},
            'shodan': {}
        }
        
        # Check if we're in offline mode
        offline_mode = self.config.get('mode', 'offline', False) or self.config.get('general', 'offline_mode', False)
        
        if offline_mode:
            self.logger.info("Running in offline mode - skipping internet-based OSINT sources")
            
            # Only run DNS record enumeration in offline mode
            dns_results = self._enumerate_dns_records(target)
            results['dns_records'] = dns_results
            
            # Set skipped sources with appropriate messages
            results['whois'] = {'error': 'skipped_offline_mode'}
            results['shodan'] = {'error': 'skipped_offline_mode'}
        else:
            # Online mode: run all OSINT sources
            
            # WHOIS lookup
            if HAS_WHOIS:
                whois_results = self._run_whois_lookup(target)
                results['whois'] = whois_results
            
            # DNS record enumeration
            dns_results = self._enumerate_dns_records(target)
            results['dns_records'] = dns_results
            
            # Shodan lookup (if API key available)
            shodan_results = self._query_shodan(target)
            results['shodan'] = shodan_results
        
        # Save results
        self._save_osint_results(target, results)
        
        return results
    
    def _run_whois_lookup(self, target):
        """Perform WHOIS lookup"""
        try:
            self.logger.info(f"Performing WHOIS lookup for {target}")
            
            # Remove protocol if present
            if target.startswith('http'):
                target = urlparse(target).netloc
            
            whois_info = whois.whois(target)
            
            whois_results = {
                'domain_name': str(whois_info.domain_name) if whois_info.domain_name else None,
                'registrar': whois_info.registrar,
                'creation_date': str(whois_info.creation_date) if whois_info.creation_date else None,
                'expiration_date': str(whois_info.expiration_date) if whois_info.expiration_date else None,
                'country': whois_info.country
            }
            
            return whois_results
            
        except Exception as e:
            self.logger.error(f"Error performing WHOIS lookup: {str(e)}")
            return {'error': str(e)}
    
    def _enumerate_dns_records(self, target):
        """Enumerate DNS records"""
        try:
            self.logger.info(f"Enumerating DNS records for {target}")
            
            # Remove protocol if present
            if target.startswith('http'):
                target = urlparse(target).netloc
            
            dns_results = {
                'A': [],
                'MX': [],
                'NS': [],
                'TXT': []
            }
            
            record_types = ['A', 'MX', 'NS', 'TXT']
            
            # Check for custom DNS servers
            dns_servers = self.config.get('dns', 'servers', [])
            custom_dns = self.config.get('general', 'dns_server', '')
            
            # Use custom DNS server if provided
            dns_server_arg = []
            resolver_nameservers = None
            
            if custom_dns:
                dns_server_arg = [f'@{custom_dns}']
                resolver_nameservers = [custom_dns]
                self.logger.info(f"Using custom DNS server: {custom_dns}")
            elif dns_servers:
                # Use first DNS server from config
                dns_server_arg = [f'@{dns_servers[0]}']
                resolver_nameservers = dns_servers
                self.logger.info(f"Using DNS server from config: {dns_servers[0]}")
            else:
                self.logger.debug("Using system default DNS servers")
            
            for record_type in record_types:
                try:
                    # Try dig command first
                    cmd = ['dig', '+short'] + dns_server_arg + [target, record_type]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    
                    if result.returncode == 0 and result.stdout.strip():
                        records = [line.strip() for line in result.stdout.strip().split('\n') if line.strip()]
                        dns_results[record_type] = records
                        self.logger.debug(f"Found {len(records)} {record_type} records via dig")
                    else:
                        # Fallback to dns.resolver if dig fails or returns nothing
                        self.logger.debug(f"dig failed for {record_type}, trying dns.resolver fallback...")
                        
                        try:
                            resolver = dns.resolver.Resolver()
                            if resolver_nameservers:
                                resolver.nameservers = resolver_nameservers
                                self.logger.debug(f"Resolver using nameservers: {resolver_nameservers}")
                            
                            answer = resolver.resolve(target, record_type)
                            records = [str(rdata) for rdata in answer]
                            dns_results[record_type] = records
                            self.logger.debug(f"Found {len(records)} {record_type} records via dns.resolver")
                            
                        except dns.resolver.NXDOMAIN:
                            self.logger.debug(f"No {record_type} records found (NXDOMAIN)")
                        except dns.resolver.NoAnswer:
                            self.logger.debug(f"No {record_type} records found (NODATA)")
                        except Exception as resolver_e:
                            self.logger.debug(f"dns.resolver also failed for {record_type}: {str(resolver_e)}")
                        
                except subprocess.TimeoutExpired:
                    self.logger.debug(f"dig timeout for {record_type} records")
                    # Try dns.resolver fallback for timeout
                    try:
                        resolver = dns.resolver.Resolver()
                        if resolver_nameservers:
                            resolver.nameservers = resolver_nameservers
                        resolver.timeout = 5  # Shorter timeout for fallback
                        
                        answer = resolver.resolve(target, record_type)
                        records = [str(rdata) for rdata in answer]
                        dns_results[record_type] = records
                        self.logger.debug(f"Found {len(records)} {record_type} records via dns.resolver fallback")
                        
                    except Exception as fallback_e:
                        self.logger.debug(f"Fallback resolver also failed for {record_type}: {str(fallback_e)}")
                        
                except FileNotFoundError:
                    # dig command not found, use dns.resolver
                    self.logger.debug("dig command not found, using dns.resolver")
                    try:
                        resolver = dns.resolver.Resolver()
                        if resolver_nameservers:
                            resolver.nameservers = resolver_nameservers
                        
                        answer = resolver.resolve(target, record_type)
                        records = [str(rdata) for rdata in answer]
                        dns_results[record_type] = records
                        self.logger.debug(f"Found {len(records)} {record_type} records via dns.resolver (no dig)")
                        
                    except Exception as resolver_e:
                        self.logger.debug(f"dns.resolver failed for {record_type}: {str(resolver_e)}")
                        
                except Exception as e:
                    self.logger.debug(f"Error querying {record_type} records: {str(e)}")
            
            # Summary logging
            total_records = sum(len(records) for records in dns_results.values())
            if total_records > 0:
                summary = ', '.join([f"{rtype}: {len(records)}" for rtype, records in dns_results.items() if records])
                self.logger.info(f"DNS enumeration found {total_records} total records ({summary})")
            else:
                self.logger.info("No DNS records found")
            
            return dns_results
            
        except Exception as e:
            self.logger.error(f"Error enumerating DNS records: {str(e)}")
            return {'error': str(e)}

    def enhanced_dns_enumeration(self, target):
        """Enhanced DNS enumeration with advanced techniques"""
        self.logger.info(f"Starting enhanced DNS enumeration for {target}")
        
        # Clean target
        if target.startswith('http'):
            target = urlparse(target).netloc
        
        results = {
            'target': target,
            'basic_records': {},
            'advanced_records': {},
            'dns_security': {},
            'subdomain_bruteforce': [],
            'zone_transfer': {},
            'dns_bruteforce': []
        }
        
        # Basic DNS records (existing functionality)
        results['basic_records'] = self._enumerate_dns_records(target)
        
        # Advanced DNS records
        results['advanced_records'] = self._enumerate_advanced_dns_records(target)
        
        # DNS security checks
        results['dns_security'] = self._check_dns_security(target)
        
        # DNS-based subdomain bruteforce
        results['subdomain_bruteforce'] = self._dns_subdomain_bruteforce(target)
        
        # Zone transfer attempts
        results['zone_transfer'] = self._attempt_zone_transfer(target)
        
        return results

    def _enumerate_advanced_dns_records(self, target):
        """Enumerate additional DNS record types"""
        advanced_records = {
            'AAAA': [],    # IPv6
            'CNAME': [],   # Canonical names
            'PTR': [],     # Reverse DNS
            'SOA': [],     # Start of Authority
            'SRV': [],     # Service records
            'CAA': [],     # Certificate Authority Authorization
            'DMARC': [],   # DMARC policy
            'SPF': [],     # SPF records
            'DKIM': []     # DKIM records
        }
        
        record_types = ['AAAA', 'CNAME', 'PTR', 'SOA', 'SRV', 'CAA']
        
        for record_type in record_types:
            try:
                cmd = ['dig', '+short', target, record_type]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                
                if result.returncode == 0 and result.stdout.strip():
                    records = [line.strip() for line in result.stdout.strip().split('\n') if line.strip()]
                    advanced_records[record_type] = records
                    
            except Exception as e:
                self.logger.debug(f"Error getting {record_type} records: {str(e)}")
        
        # Check for DMARC policy
        try:
            dmarc_domain = f"_dmarc.{target}"
            cmd = ['dig', '+short', dmarc_domain, 'TXT']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                advanced_records['DMARC'] = [result.stdout.strip()]
        except:
            pass
        
        # Check for SPF records in TXT
        try:
            cmd = ['dig', '+short', target, 'TXT']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                txt_records = result.stdout.strip().split('\n')
                spf_records = [record for record in txt_records if 'v=spf1' in record.lower()]
                advanced_records['SPF'] = spf_records
        except:
            pass
        
        return advanced_records

    def _check_dns_security(self, target):
        """Check DNS security configurations"""
        security_results = {
            'dnssec_enabled': False,
            'spf_configured': False,
            'dmarc_configured': False,
            'caa_configured': False,
            'security_score': 0
        }
        
        try:
            # Check DNSSEC
            cmd = ['dig', '+dnssec', '+short', target, 'A']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if 'RRSIG' in result.stdout:
                security_results['dnssec_enabled'] = True
                security_results['security_score'] += 25
        except:
            pass
        
        try:
            # Check SPF
            cmd = ['dig', '+short', target, 'TXT']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if 'v=spf1' in result.stdout.lower():
                security_results['spf_configured'] = True
                security_results['security_score'] += 25
        except:
            pass
        
        try:
            # Check DMARC
            dmarc_domain = f"_dmarc.{target}"
            cmd = ['dig', '+short', dmarc_domain, 'TXT']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if 'v=DMARC1' in result.stdout:
                security_results['dmarc_configured'] = True
                security_results['security_score'] += 25
        except:
            pass
        
        try:
            # Check CAA
            cmd = ['dig', '+short', target, 'CAA']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.stdout.strip():
                security_results['caa_configured'] = True
                security_results['security_score'] += 25
        except:
            pass
        
        return security_results

    def _dns_subdomain_bruteforce(self, target):
        """DNS-based subdomain bruteforce"""
        common_subdomains = [
            'www', 'mail', 'ftp', 'admin', 'api', 'dev', 'test', 'staging',
            'prod', 'blog', 'shop', 'store', 'portal', 'support', 'help',
            'docs', 'cdn', 'static', 'media', 'images', 'assets', 'secure',
            'vpn', 'remote', 'app', 'mobile', 'beta', 'demo', 'lab',
            'git', 'svn', 'repo', 'backup', 'db', 'database', 'mysql',
            'postgres', 'redis', 'elastic', 'kibana', 'grafana'
        ]
        
        found_subdomains = []
        
        for subdomain in common_subdomains:
            try:
                full_domain = f"{subdomain}.{target}"
                
                # Try A record
                cmd = ['dig', '+short', full_domain, 'A']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                
                if result.returncode == 0 and result.stdout.strip():
                    ip_addresses = [line.strip() for line in result.stdout.strip().split('\n') if line.strip()]
                    found_subdomains.append({
                        'subdomain': full_domain,
                        'type': 'A',
                        'values': ip_addresses
                    })
                else:
                    # Try CNAME record
                    cmd = ['dig', '+short', full_domain, 'CNAME']
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                    
                    if result.returncode == 0 and result.stdout.strip():
                        cname_values = [line.strip() for line in result.stdout.strip().split('\n') if line.strip()]
                        found_subdomains.append({
                            'subdomain': full_domain,
                            'type': 'CNAME',
                            'values': cname_values
                        })
                        
            except Exception as e:
                self.logger.debug(f"Error checking subdomain {subdomain}: {str(e)}")
                continue
        
        self.logger.info(f"DNS bruteforce found {len(found_subdomains)} subdomains")
        return found_subdomains

    def _attempt_zone_transfer(self, target):
        """Attempt DNS zone transfer"""
        zone_transfer_results = {
            'attempted': False,
            'successful': False,
            'nameservers': [],
            'transferred_records': []
        }
        
        try:
            # Get nameservers
            cmd = ['dig', '+short', target, 'NS']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                nameservers = [line.strip().rstrip('.') for line in result.stdout.strip().split('\n') if line.strip()]
                zone_transfer_results['nameservers'] = nameservers
                
                # Try zone transfer against each nameserver
                for ns in nameservers[:3]:  # Limit to first 3 NS
                    try:
                        zone_transfer_results['attempted'] = True
                        self.logger.info(f"Attempting zone transfer from {ns}")
                        
                        cmd = ['dig', f'@{ns}', target, 'AXFR']
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                        
                        if result.returncode == 0 and result.stdout.strip():
                            # Check if transfer was successful (contains multiple records)
                            lines = result.stdout.strip().split('\n')
                            if len(lines) > 5:  # More than just SOA records
                                zone_transfer_results['successful'] = True
                                zone_transfer_results['transferred_records'] = lines[:50]  # Limit output
                                self.logger.warning(f"Zone transfer successful from {ns}!")
                                break
                                
                    except Exception as e:
                        self.logger.debug(f"Zone transfer failed for {ns}: {str(e)}")
                        
        except Exception as e:
            self.logger.error(f"Error in zone transfer attempt: {str(e)}")
        
        return zone_transfer_results
    
    def _query_shodan(self, target):
        """Query Shodan API for target information"""
        try:
            api_key = self.config.get('osint', 'shodan_api_key')
            if not api_key:
                return {'error': 'no_api_key'}
            
            self.logger.info(f"Querying Shodan for {target}")
            
            # Remove protocol if present
            if target.startswith('http'):
                target = urlparse(target).netloc
            
            # Resolve target to IP if it's a domain
            try:
                ip = socket.gethostbyname(target)
            except:
                ip = target
            
            url = f"https://api.shodan.io/shodan/host/{ip}?key={api_key}"
            response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                shodan_results = {
                    'ip': data.get('ip_str'),
                    'country': data.get('country_name'),
                    'city': data.get('city'),
                    'ports': data.get('ports', [])[:10],  # Limit ports
                    'vulnerabilities': data.get('vulns', [])[:5]  # Limit vulns
                }
                
                return shodan_results
            else:
                return {'error': f'API error: {response.status_code}'}
                
        except Exception as e:
            self.logger.error(f"Error querying Shodan: {str(e)}")
            return {'error': str(e)}
    
    def _save_osint_results(self, target, results):
        """Save OSINT results"""
        json_file = self.output_dir / 'osint' / f'{target}_osint_results.json'
        with open(json_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        self.logger.info(f"OSINT results saved to {json_file}")

    def wayback_analysis(self, target):
        """Analyze target using Wayback Machine data"""
        self.logger.info(f"Analyzing Wayback Machine data for {target}")
        
        results = {
            'target': target,
            'snapshots': [],
            'interesting_files': [],
            'technologies_history': [],
            'status': 'success'
        }
        
        try:
            # Get snapshots from Wayback Machine API
            snapshots = self._get_wayback_snapshots(target)
            results['snapshots'] = snapshots
            
            # Analyze snapshots for interesting files
            interesting_files = self._find_interesting_files(snapshots)
            results['interesting_files'] = interesting_files
            
            # Technology stack evolution
            tech_history = self._analyze_technology_evolution(snapshots)
            results['technologies_history'] = tech_history
            
            self.logger.info(f"Found {len(snapshots)} snapshots and {len(interesting_files)} interesting files")
            
        except Exception as e:
            self.logger.error(f"Wayback analysis failed: {str(e)}")
            results['status'] = 'failed'
            results['error'] = str(e)
        
        return results

    def _get_wayback_snapshots(self, target):
        """Get snapshots from Wayback Machine CDX API"""
        try:
            # Clean target URL
            if target.startswith('http'):
                domain = urlparse(target).netloc
            else:
                domain = target
                
            # Query Wayback CDX API
            cdx_url = f"http://web.archive.org/cdx/search/cdx?url={domain}/*&output=json&limit=1000"
            
            response = requests.get(cdx_url, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            if not data:
                return []
            
            # Skip header row
            snapshots = []
            for row in data[1:]:
                if len(row) >= 7:
                    snapshots.append({
                        'timestamp': row[1],
                        'url': row[2],
                        'status_code': row[4],
                        'mimetype': row[3],
                        'length': row[5],
                        'wayback_url': f"http://web.archive.org/web/{row[1]}/{row[2]}"
                    })
            
            return snapshots
            
        except Exception as e:
            self.logger.error(f"Error getting Wayback snapshots: {str(e)}")
            return []

    def _find_interesting_files(self, snapshots):
        """Find interesting files from Wayback snapshots"""
        interesting_extensions = [
            '.sql', '.bak', '.backup', '.old', '.orig', '.tmp',
            '.config', '.conf', '.ini', '.env', '.log',
            '.zip', '.tar', '.gz', '.rar', '.7z',
            '.pdf', '.doc', '.docx', '.xls', '.xlsx',
            '.xml', '.json', '.csv', '.txt'
        ]
        
        interesting_paths = [
            'admin', 'config', 'backup', 'test', 'dev',
            'staging', 'api', 'private', 'internal',
            'upload', 'uploads', 'files', 'documents'
        ]
        
        interesting_files = []
        
        for snapshot in snapshots:
            url = snapshot['url'].lower()
            
            # Check for interesting file extensions
            for ext in interesting_extensions:
                if url.endswith(ext):
                    interesting_files.append({
                        'url': snapshot['url'],
                        'wayback_url': snapshot['wayback_url'],
                        'timestamp': snapshot['timestamp'],
                        'type': 'interesting_extension',
                        'reason': f'Contains {ext} extension'
                    })
                    break
            
            # Check for interesting paths
            for path in interesting_paths:
                if f'/{path}/' in url or f'/{path}.' in url:
                    interesting_files.append({
                        'url': snapshot['url'],
                        'wayback_url': snapshot['wayback_url'],
                        'timestamp': snapshot['timestamp'],
                        'type': 'interesting_path',
                        'reason': f'Contains {path} in path'
                    })
                    break
        
        # Remove duplicates
        seen_urls = set()
        unique_files = []
        for file_info in interesting_files:
            if file_info['url'] not in seen_urls:
                seen_urls.add(file_info['url'])
                unique_files.append(file_info)
        
        return unique_files[:50]  # Limit to 50 most interesting

    def _analyze_technology_evolution(self, snapshots):
        """Analyze technology stack evolution over time"""
        tech_history = []
        
        # Group snapshots by year
        yearly_snapshots = {}
        for snapshot in snapshots:
            year = snapshot['timestamp'][:4]
            if year not in yearly_snapshots:
                yearly_snapshots[year] = []
            yearly_snapshots[year].append(snapshot)
        
        # Analyze each year
        for year in sorted(yearly_snapshots.keys()):
            year_snapshots = yearly_snapshots[year]
            
            # Look for technology indicators in URLs
            technologies = set()
            
            for snapshot in year_snapshots:
                url = snapshot['url'].lower()
                
                # Common technology indicators
                if 'wp-' in url or 'wordpress' in url:
                    technologies.add('WordPress')
                if '.php' in url:
                    technologies.add('PHP')
                if '.asp' in url or '.aspx' in url:
                    technologies.add('ASP.NET')
                if '.jsp' in url:
                    technologies.add('JSP')
                if 'jquery' in url:
                    technologies.add('jQuery')
                if 'bootstrap' in url:
                    technologies.add('Bootstrap')
                if 'angular' in url:
                    technologies.add('Angular')
                if 'react' in url:
                    technologies.add('React')
                if 'vue' in url:
                    technologies.add('Vue.js')
            
            if technologies:
                tech_history.append({
                    'year': year,
                    'technologies': list(technologies),
                    'snapshots_count': len(year_snapshots)
                })
        
        return tech_history

    def github_dorking(self, target):
        """Search GitHub for potential sensitive information"""
        self.logger.info(f"Performing GitHub dorking for {target}")
        
        results = {
            'target': target,
            'potential_leaks': [],
            'repositories': [],
            'status': 'success'
        }
        
        try:
            # Clean domain name
            if target.startswith('http'):
                domain = urlparse(target).netloc
            else:
                domain = target
            
            # Remove www. prefix if present
            domain = domain.replace('www.', '')
            
            # Common search queries for sensitive information
            search_queries = [
                f'"{domain}" password',
                f'"{domain}" api_key',
                f'"{domain}" secret',
                f'"{domain}" token',
                f'"{domain}" config',
                f'"{domain}" database',
                f'"{domain}" credentials',
                f'site:{domain} filetype:env',
                f'site:{domain} filetype:config',
                f'site:{domain} filetype:sql'
            ]
            
            # Note: This is a placeholder implementation
            # Real implementation would require GitHub API token
            for query in search_queries[:3]:  # Limit to avoid rate limiting
                self.logger.info(f"Searching GitHub for: {query}")
                # Simulated search results
                results['potential_leaks'].append({
                    'query': query,
                    'note': 'GitHub API integration required for actual search',
                    'recommendation': f'Manually search GitHub for: {query}'
                })
            
            self.logger.info(f"GitHub dorking completed with {len(search_queries)} queries")
            
        except Exception as e:
            self.logger.error(f"GitHub dorking failed: {str(e)}")
            results['status'] = 'failed'
            results['error'] = str(e)
        
        return results


# ============================== SCREENSHOTTER ==============================
class Screenshotter:
    """Web service screenshot capture wrapper"""
    
    def __init__(self, output_dir, config):
        self.output_dir = Path(output_dir)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def capture_screenshots(self, targets):
        """Capture screenshots of multiple targets"""
        self.logger.info(f"Capturing screenshots for {len(targets)} targets")
        
        results = {
            'targets': targets,
            'screenshots': [],
            'tool_used': 'custom'
        }
        
        # Prepare URLs (limit to 5)
        urls = []
        for target in targets[:5]:
            if target.startswith('http'):
                urls.append(target)
            else:
                urls.append(f'https://{target}')
        
        # Capture screenshots
        screenshots = self._capture_with_requests(urls)
        results['screenshots'] = screenshots
        
        # Save results
        self._save_screenshot_results(results)
        
        return results
    
    def _capture_with_requests(self, urls):
        """Capture basic info using requests (fallback method)"""
        screenshots = []
        
        for url in urls:
            try:
                response = requests.get(url, timeout=10)
                if response.status_code < 400:
                    screenshots.append({
                        'url': url,
                        'status_code': response.status_code,
                        'title': self._extract_title(response.text),
                        'status': 'basic_info_captured'
                    })
            except:
                screenshots.append({
                    'url': url,
                    'status': 'failed'
                })
        
        return screenshots
    
    def _extract_title(self, html):
        """Extract title from HTML"""
        try:
            if '<title>' in html and '</title>' in html:
                title = html.split('<title>')[1].split('</title>')[0]
                return title.strip()[:100]
        except:
            pass
        return ""
    
    def _save_screenshot_results(self, results):
        """Save screenshot results"""
        json_file = self.output_dir / 'screenshots' / 'screenshot_results.json'
        with open(json_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        self.logger.info(f"Screenshot results saved to {json_file}")


# ============================== RISK SCORER ==============================
class RiskScorer:
    """Advanced risk scoring and assessment engine"""
    
    def __init__(self, config=None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # Risk scoring weights (configurable)
        self.weights = {
            'critical_vulns': 30,
            'high_vulns': 20,
            'medium_vulns': 10,
            'low_vulns': 5,
            'expired_certs': 25,
            'weak_protocols': 15,
            'missing_headers': 10,
            'open_ports': 8,
            'exposed_services': 12
        }
        
    def calculate_risk_score(self, results):
        """Calculate comprehensive risk score (0-100)"""
        try:
            score = 0
            max_score = 100
            
            # Analyze vulnerabilities
            vuln_score = self._score_vulnerabilities(results)
            
            # Analyze SSL/TLS security
            ssl_score = self._score_ssl_security(results)
            
            # Analyze network exposure
            network_score = self._score_network_exposure(results)
            
            # Analyze security configuration
            config_score = self._score_security_configuration(results)
            
            # Calculate weighted total
            total_score = (vuln_score * 0.4 + ssl_score * 0.3 + 
                          network_score * 0.2 + config_score * 0.1)
            
            risk_details = {
                'total_score': min(total_score, 100),
                'risk_level': self._get_risk_level(total_score),
                'component_scores': {
                    'vulnerabilities': vuln_score,
                    'ssl_tls': ssl_score,
                    'network_exposure': network_score,
                    'security_config': config_score
                },
                'recommendations': self._generate_recommendations(results, total_score)
            }
            
            return risk_details
            
        except Exception as e:
            self.logger.error(f"Risk scoring failed: {str(e)}")
            return {'total_score': 0, 'risk_level': 'unknown', 'error': str(e)}
            
    def _score_vulnerabilities(self, results):
        """Score based on identified vulnerabilities"""
        score = 0
        
        # Web analysis vulnerabilities (new data structure)
        web_analysis = results.get('web_analysis', {})
        
        # Check if vulnerabilities are directly in web_analysis
        vulnerabilities = web_analysis.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'low').lower()
            if severity == 'critical':
                score += 25
            elif severity == 'high':
                score += 15
            elif severity == 'medium':
                score += 8
            elif severity == 'low':
                score += 3
        
        # Check if vulnerabilities are in applications array
        applications = web_analysis.get('applications', [])
        for app in applications:
            app_vulns = app.get('vulnerabilities', [])
            for vuln in app_vulns:
                severity = vuln.get('severity', 'low').lower()
                if severity == 'critical':
                    score += 25
                elif severity == 'high':
                    score += 15
                elif severity == 'medium':
                    score += 8
                elif severity == 'low':
                    score += 3
        
        # SSL scan vulnerabilities (new data structure)
        ssl_scan = results.get('ssl_scan', {})
        for domain_data in ssl_scan.values():
            if isinstance(domain_data, dict) and 'vulnerabilities' in domain_data:
                ssl_vulns = domain_data.get('vulnerabilities', [])
                for vuln in ssl_vulns:
                    severity = vuln.get('severity', 'low').lower()
                    if severity == 'critical':
                        score += 20
                    elif severity == 'high':
                        score += 12
                    elif severity == 'medium':
                        score += 6
                    elif severity == 'low':
                        score += 2
                
        # Legacy security analysis vulnerabilities (fallback)
        security_results = results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            vulnerabilities = port_data.get('vulnerabilities', [])
            for vuln in vulnerabilities:
                severity = vuln.get('severity', 'low').lower()
                if severity == 'critical':
                    score += 25
                elif severity == 'high':
                    score += 15
                elif severity == 'medium':
                    score += 8
                elif severity == 'low':
                    score += 3
                    
        return min(score, 40)  # Cap at 40 points
        
    def _score_ssl_security(self, results):
        """Score SSL/TLS security configuration"""
        score = 0
        
        # SSL scan results (new data structure)
        ssl_scan = results.get('ssl_scan', {})
        for domain_data in ssl_scan.values():
            if isinstance(domain_data, dict):
                # Check for weak protocols
                protocols = domain_data.get('protocols', [])
                for proto in protocols:
                    if isinstance(proto, dict):
                        if proto.get('supported') and proto.get('name') in ['SSLv2', 'SSLv3']:
                            score += 15
                        elif proto.get('supported') and proto.get('name') == 'TLSv1.0':
                            score += 8
                    elif isinstance(proto, str) and proto in ['SSLv2', 'SSLv3', 'TLSv1.0']:
                        score += 10
                        
                # Check certificate issues
                cert_info = domain_data.get('certificate')
                if cert_info:
                    try:
                        from datetime import datetime
                        if cert_info.get('not_after'):
                            expiry_str = cert_info['not_after']
                            # Handle different date formats
                            if 'Z' in expiry_str:
                                expiry = datetime.fromisoformat(expiry_str.replace('Z', '+00:00'))
                            else:
                                expiry = datetime.fromisoformat(expiry_str)
                            if expiry < datetime.now():
                                score += 20  # Expired certificate
                            elif (expiry - datetime.now()).days < 30:
                                score += 10  # Expiring soon
                    except Exception:
                        pass
                        
                # Check for SSL vulnerabilities
                vulnerabilities = domain_data.get('vulnerabilities', [])
                for vuln in vulnerabilities:
                    severity = vuln.get('severity', 'low').lower()
                    if severity in ['critical', 'high']:
                        score += 10
                    elif severity == 'medium':
                        score += 5
                        
                # Check security headers
                headers = domain_data.get('security_headers', {})
                missing_critical = ['Strict-Transport-Security', 'Content-Security-Policy']
                for header in missing_critical:
                    if not headers.get(header, {}).get('present', False):
                        score += 5
        
        # Legacy security analysis (fallback)
        security_results = results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            # Check for weak protocols
            protocols = port_data.get('protocols', [])
            for proto in protocols:
                if proto.get('supported') and proto.get('name') in ['SSLv2', 'SSLv3']:
                    score += 15
                elif proto.get('supported') and proto.get('name') == 'TLSv1.0':
                    score += 8
                    
            # Check certificate issues
            cert_info = port_data.get('certificate')
            if cert_info:
                try:
                    from datetime import datetime
                    if cert_info.get('not_after'):
                        expiry = datetime.fromisoformat(cert_info['not_after'].replace('Z', '+00:00'))
                        if expiry < datetime.now():
                            score += 20  # Expired certificate
                        elif (expiry - datetime.now()).days < 30:
                            score += 10  # Expiring soon
                except Exception:
                    pass
                    
            # Check security headers
            headers = port_data.get('security_headers', {})
            missing_critical = ['Strict-Transport-Security', 'Content-Security-Policy']
            for header in missing_critical:
                if not headers.get(header, {}).get('present'):
                    score += 5
                    
        return min(score, 30)  # Cap at 30 points
        
    def _score_network_exposure(self, results):
        """Score network exposure and open ports"""
        score = 0
        
        # Count open ports from network scan (new data structure)
        network_scan = results.get('network_scan', {})
        total_open_ports = 0
        
        # Handle both old and new network scan data structures
        hosts = network_scan.get('hosts', [])
        if not hosts:
            # Try alternative structure
            hosts = network_scan.get('results', {}).get('hosts', [])
        
        for host in hosts:
            ports = host.get('ports', [])
            open_ports = [p for p in ports if p.get('state') == 'open']
            total_open_ports += len(open_ports)
            
            # High-risk ports
            high_risk_ports = [21, 23, 53, 135, 139, 445, 1433, 3389]
            for port in open_ports:
                if port.get('port') in high_risk_ports:
                    score += 5
        
        # Legacy nmap results (fallback)
        nmap_results = results.get('nmap', {})
        legacy_hosts = nmap_results.get('hosts', [])
        
        for host in legacy_hosts:
            ports = host.get('ports', [])
            open_ports = [p for p in ports if p.get('state') == 'open']
            total_open_ports += len(open_ports)
            
            # High-risk ports
            high_risk_ports = [21, 23, 53, 135, 139, 445, 1433, 3389]
            for port in open_ports:
                if port.get('port') in high_risk_ports:
                    score += 5
                    
        # General port exposure
        if total_open_ports > 20:
            score += 10
        elif total_open_ports > 10:
            score += 5
            
        # Subdomain exposure
        subdomains = results.get('subdomains', [])
        if len(subdomains) > 50:
            score += 8
        elif len(subdomains) > 20:
            score += 4
            
        return min(score, 20)  # Cap at 20 points
        
    def _score_security_configuration(self, results):
        """Score security configuration issues"""
        score = 0
        
        # Web analysis vulnerabilities (new data structure)
        web_analysis = results.get('web_analysis', {})
        vulnerabilities = web_analysis.get('vulnerabilities', [])
        if vulnerabilities:
            score += len(vulnerabilities) * 2
        
        # SSL scan security issues (new data structure)
        ssl_scan = results.get('ssl_scan', {})
        for domain_data in ssl_scan.values():
            if isinstance(domain_data, dict):
                # Check for security headers
                headers = domain_data.get('security_headers', {})
                security_headers = ['X-Frame-Options', 'X-Content-Type-Options', 
                                  'X-XSS-Protection', 'Referrer-Policy']
                missing_count = sum(1 for h in security_headers 
                                  if not headers.get(h, {}).get('present', False))
                score += missing_count * 2
                
                # Check for SSL/TLS issues
                ssl_issues = domain_data.get('ssl_issues', [])
                score += len(ssl_issues) * 3
        
        # Legacy web scan (fallback)
        web_scan = results.get('web_scan', {})
        if web_scan.get('vulnerabilities'):
            score += len(web_scan['vulnerabilities']) * 2
            
        # Legacy security analysis (fallback)
        security_results = results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            headers = port_data.get('security_headers', {})
            security_headers = ['X-Frame-Options', 'X-Content-Type-Options', 
                              'X-XSS-Protection', 'Referrer-Policy']
            missing_count = sum(1 for h in security_headers 
                              if not headers.get(h, {}).get('present'))
            score += missing_count * 2
            
        return min(score, 10)  # Cap at 10 points
        
    def _get_risk_level(self, score):
        """Determine risk level based on score"""
        if score >= 70:
            return 'critical'
        elif score >= 50:
            return 'high'
        elif score >= 30:
            return 'medium'
        elif score >= 10:
            return 'low'
        else:
            return 'minimal'
            
    def _generate_recommendations(self, results, score):
        """Generate prioritized recommendations"""
        recommendations = []
        
        if score >= 50:
            recommendations.append({
                'priority': 'critical',
                'category': 'immediate_action',
                'title': 'Critical Security Issues Detected',
                'description': 'Multiple high-severity vulnerabilities require immediate attention.',
                'actions': ['Patch expired certificates', 'Disable weak protocols', 'Implement security headers']
            })
            
        # Add specific recommendations based on findings
        security_results = results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            vulnerabilities = port_data.get('vulnerabilities', [])
            for vuln in vulnerabilities:
                if vuln.get('severity') in ['critical', 'high']:
                    recommendations.append({
                        'priority': vuln.get('severity'),
                        'category': 'ssl_tls',
                        'title': vuln.get('name'),
                        'description': vuln.get('description'),
                        'actions': ['Review SSL/TLS configuration', 'Update certificates', 'Disable weak protocols']
                    })
                    
        return recommendations[:10]  # Top 10 recommendations


# ============================== ADVANCED REPORT GENERATOR ==============================
class CVSSCalculator:
    """CVSS v3.1 (Common Vulnerability Scoring System) calculator"""
    
    def __init__(self):
        # CVSS v3.1 Base Score Metrics
        self.attack_vector_scores = {
            'network': 0.85,      # AV:N
            'adjacent': 0.62,     # AV:A
            'local': 0.55,        # AV:L
            'physical': 0.2       # AV:P
        }
        
        self.attack_complexity_scores = {
            'low': 0.77,          # AC:L
            'high': 0.44          # AC:H
        }
        
        self.privileges_required_scores = {
            'none': 0.85,         # PR:N
            'low': 0.62,          # PR:L (changed scope)
            'low_unchanged': 0.62, # PR:L (unchanged scope)
            'high': 0.27,         # PR:H (changed scope)
            'high_unchanged': 0.27 # PR:H (unchanged scope)
        }
        
        self.user_interaction_scores = {
            'none': 0.85,         # UI:N
            'required': 0.62      # UI:R
        }
        
        self.impact_scores = {
            'none': 0.0,          # C:N, I:N, A:N
            'low': 0.22,          # C:L, I:L, A:L
            'high': 0.56          # C:H, I:H, A:H
        }
        
        # Vulnerability type patterns and their typical CVSS characteristics
        self.vulnerability_patterns = {
            'sql_injection': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'none',
                'confidentiality': 'high',
                'integrity': 'high',
                'availability': 'high',
                'scope_changed': True
            },
            'rce': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'none',
                'confidentiality': 'high',
                'integrity': 'high',
                'availability': 'high',
                'scope_changed': True
            },
            'command_injection': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'low',
                'user_interaction': 'none',
                'confidentiality': 'high',
                'integrity': 'high',
                'availability': 'high',
                'scope_changed': True
            },
            'xss': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'required',
                'confidentiality': 'low',
                'integrity': 'low',
                'availability': 'none',
                'scope_changed': True
            },
            'csrf': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'required',
                'confidentiality': 'none',
                'integrity': 'high',
                'availability': 'none',
                'scope_changed': False
            },
            'ssl_vulnerability': {
                'attack_vector': 'network',
                'attack_complexity': 'high',
                'privileges_required': 'none',
                'user_interaction': 'none',
                'confidentiality': 'high',
                'integrity': 'low',
                'availability': 'none',
                'scope_changed': False
            },
            'information_disclosure': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'none',
                'confidentiality': 'low',
                'integrity': 'none',
                'availability': 'none',
                'scope_changed': False
            },
            'missing_security_headers': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'required',
                'confidentiality': 'low',
                'integrity': 'low',
                'availability': 'none',
                'scope_changed': False
            },
            'weak_authentication': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'none',
                'confidentiality': 'high',
                'integrity': 'high',
                'availability': 'none',
                'scope_changed': False
            },
            'rate_limiting': {
                'attack_vector': 'network',
                'attack_complexity': 'low',
                'privileges_required': 'none',
                'user_interaction': 'none',
                'confidentiality': 'none',
                'integrity': 'none',
                'availability': 'high',
                'scope_changed': False
            }
        }
        
    def calculate_cvss(self, vulnerability):
        """Calculate CVSS v3.1 score for a vulnerability"""
        try:
            # Get vulnerability characteristics
            vuln_type = self._identify_vulnerability_type(vulnerability)
            characteristics = self._get_vulnerability_characteristics(vulnerability, vuln_type)
            
            # Calculate base score using CVSS v3.1 formula
            base_score = self._calculate_base_score(characteristics)
            
            # Ensure score is within valid range
            return round(max(0.0, min(10.0, base_score)), 1)
            
        except Exception as e:
            # Fallback to severity-based scoring
            severity = vulnerability.get('severity', 'low').lower()
            severity_map = {
                'critical': 9.5,
                'high': 7.5,
                'medium': 5.0,
                'low': 2.5,
                'info': 0.1
            }
            return severity_map.get(severity, 2.5)
    
    def _identify_vulnerability_type(self, vulnerability):
        """Identify vulnerability type from vulnerability data"""
        vuln_name = vulnerability.get('name', '').lower()
        vuln_type = vulnerability.get('type', '').lower()
        description = vulnerability.get('description', '').lower()
        
        # Combine all text for pattern matching
        full_text = f"{vuln_name} {vuln_type} {description}"
        
        # Check for SQL injection
        if any(term in full_text for term in ['sql injection', 'sqli', 'sql_injection']):
            return 'sql_injection'
        
        # Check for RCE
        if any(term in full_text for term in ['remote code execution', 'rce', 'code execution']):
            return 'rce'
        
        # Check for Command Injection
        if any(term in full_text for term in ['command injection', 'command_injection', 'cmd injection']):
            return 'command_injection'
        
        # Check for XSS
        if any(term in full_text for term in ['cross-site scripting', 'xss', 'cross site scripting']):
            return 'xss'
        
        # Check for CSRF
        if any(term in full_text for term in ['csrf', 'cross-site request forgery', 'cross site request']):
            return 'csrf'
        
        # Check for SSL/TLS vulnerabilities
        if any(term in full_text for term in ['ssl', 'tls', 'certificate', 'cipher', 'protocol']):
            return 'ssl_vulnerability'
        
        # Check for information disclosure
        if any(term in full_text for term in ['information disclosure', 'info disclosure', 'version exposed', 'server version']):
            return 'information_disclosure'
        
        # Check for missing security headers
        if any(term in full_text for term in ['security header', 'missing header', 'content security policy', 'csp']):
            return 'missing_security_headers'
        
        # Check for authentication issues
        if any(term in full_text for term in ['authentication', 'weak auth', 'login', 'password', 'account lockout']):
            return 'weak_authentication'
        
        # Check for rate limiting issues
        if any(term in full_text for term in ['rate limit', 'rate limiting', 'dos', 'denial of service']):
            return 'rate_limiting'
        
        # Default to information disclosure for unknown types
        return 'information_disclosure'
    
    def _get_vulnerability_characteristics(self, vulnerability, vuln_type):
        """Get CVSS characteristics for a vulnerability"""
        # Start with pattern defaults
        characteristics = self.vulnerability_patterns.get(vuln_type, 
            self.vulnerability_patterns['information_disclosure']).copy()
        
        # Override with explicit vulnerability data if available
        if 'cvss' in vulnerability:
            cvss_data = vulnerability['cvss']
            characteristics.update({
                'attack_vector': cvss_data.get('attack_vector', characteristics['attack_vector']),
                'attack_complexity': cvss_data.get('attack_complexity', characteristics['attack_complexity']),
                'privileges_required': cvss_data.get('privileges_required', characteristics['privileges_required']),
                'user_interaction': cvss_data.get('user_interaction', characteristics['user_interaction']),
                'confidentiality': cvss_data.get('confidentiality_impact', characteristics['confidentiality']),
                'integrity': cvss_data.get('integrity_impact', characteristics['integrity']),
                'availability': cvss_data.get('availability_impact', characteristics['availability']),
                'scope_changed': cvss_data.get('scope_changed', characteristics['scope_changed'])
            })
        
        # Adjust based on severity if provided
        severity = vulnerability.get('severity', '').lower()
        if severity == 'critical':
            characteristics['confidentiality'] = 'high'
            characteristics['integrity'] = 'high'
            characteristics['availability'] = 'high'
        elif severity == 'high':
            if characteristics['confidentiality'] == 'none':
                characteristics['confidentiality'] = 'low'
            if characteristics['integrity'] == 'none':
                characteristics['integrity'] = 'low'
        
        return characteristics
    
    def _calculate_base_score(self, characteristics):
        """Calculate CVSS v3.1 base score using the official formula"""
        # Get score components
        av = self.attack_vector_scores[characteristics['attack_vector']]
        ac = self.attack_complexity_scores[characteristics['attack_complexity']]
        
        # Handle privileges required based on scope change
        pr_key = characteristics['privileges_required']
        if characteristics['scope_changed'] and pr_key in ['low', 'high']:
            pr_key = f"{pr_key}_unchanged" if not characteristics['scope_changed'] else pr_key
        pr = self.privileges_required_scores.get(pr_key, self.privileges_required_scores['none'])
        
        ui = self.user_interaction_scores[characteristics['user_interaction']]
        c = self.impact_scores[characteristics['confidentiality']]
        i = self.impact_scores[characteristics['integrity']]
        a = self.impact_scores[characteristics['availability']]
        
        # Calculate ISS (Impact Sub Score)
        iss = 1 - ((1 - c) * (1 - i) * (1 - a))
        
        # Calculate impact score
        if characteristics['scope_changed']:
            impact = 7.52 * (iss - 0.029) - 3.25 * pow((iss - 0.02), 15)
        else:
            impact = 6.42 * iss
        
        # Calculate exploitability score
        exploitability = 8.22 * av * ac * pr * ui
        
        # Calculate base score
        if impact <= 0:
            base_score = 0
        elif characteristics['scope_changed']:
            base_score = min(1.08 * (impact + exploitability), 10)
        else:
            base_score = min(impact + exploitability, 10)
        
        return base_score
    
    def get_cvss_vector(self, vulnerability):
        """Generate CVSS v3.1 vector string"""
        vuln_type = self._identify_vulnerability_type(vulnerability)
        characteristics = self._get_vulnerability_characteristics(vulnerability, vuln_type)
        
        # Map to CVSS vector notation
        vector_map = {
            'attack_vector': {'network': 'N', 'adjacent': 'A', 'local': 'L', 'physical': 'P'},
            'attack_complexity': {'low': 'L', 'high': 'H'},
            'privileges_required': {'none': 'N', 'low': 'L', 'high': 'H'},
            'user_interaction': {'none': 'N', 'required': 'R'},
            'confidentiality': {'none': 'N', 'low': 'L', 'high': 'H'},
            'integrity': {'none': 'N', 'low': 'L', 'high': 'H'},
            'availability': {'none': 'N', 'low': 'L', 'high': 'H'}
        }
        
        av = vector_map['attack_vector'][characteristics['attack_vector']]
        ac = vector_map['attack_complexity'][characteristics['attack_complexity']]
        pr = vector_map['privileges_required'][characteristics['privileges_required'].split('_')[0]]
        ui = vector_map['user_interaction'][characteristics['user_interaction']]
        s = 'C' if characteristics['scope_changed'] else 'U'
        c = vector_map['confidentiality'][characteristics['confidentiality']]
        i = vector_map['integrity'][characteristics['integrity']]
        a = vector_map['availability'][characteristics['availability']]
        
        return f"CVSS:3.1/AV:{av}/AC:{ac}/PR:{pr}/UI:{ui}/S:{s}/C:{c}/I:{i}/A:{a}"

class ComplianceMapper:
    """Maps findings to compliance frameworks"""
    
    def __init__(self):
        self.frameworks = {
            'owasp_top10': self._map_owasp_top10,
            'nist_framework': self._map_nist_framework,
            'pci_dss': self._map_pci_dss,
            'iso27001': self._map_iso27001
        }
        
    def assess_compliance(self, results):
        """Assess compliance across all frameworks"""
        compliance_status = {}
        
        for framework_name, mapper_func in self.frameworks.items():
            try:
                status = mapper_func(results)
                compliance_status[framework_name] = status
            except Exception as e:
                logging.error(f"Failed to assess {framework_name}: {e}")
                compliance_status[framework_name] = {'status': 'error', 'message': str(e)}
                
        return compliance_status
        
    def _map_owasp_top10(self, results):
        """Map findings to OWASP Top 10"""
        owasp_status = {
            'A01_broken_access_control': {'status': 'unknown', 'findings': []},
            'A02_cryptographic_failures': {'status': 'pass', 'findings': []},
            'A03_injection': {'status': 'pass', 'findings': []},
            'A04_insecure_design': {'status': 'unknown', 'findings': []},
            'A05_security_misconfiguration': {'status': 'pass', 'findings': []},
            'A06_vulnerable_components': {'status': 'pass', 'findings': []},
            'A07_identification_failures': {'status': 'unknown', 'findings': []},
            'A08_software_integrity_failures': {'status': 'unknown', 'findings': []},
            'A09_logging_failures': {'status': 'unknown', 'findings': []},
            'A10_ssrf': {'status': 'unknown', 'findings': []}
        }
        
        # Check for cryptographic failures
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                vulnerabilities = port_data.get('vulnerabilities', [])
                for vuln in vulnerabilities:
                    if any(term in vuln.get('type', '').lower() for term in ['ssl', 'tls', 'crypto', 'cipher']):
                        owasp_status['A02_cryptographic_failures']['status'] = 'fail'
                        owasp_status['A02_cryptographic_failures']['findings'].append(vuln.get('name', 'Unknown SSL/TLS issue'))
                        
        # Check for injection vulnerabilities
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            for vuln in results['web_scan']['vulnerabilities']:
                vuln_type = vuln.get('type', '').lower()
                if any(term in vuln_type for term in ['injection', 'sql', 'xss', 'command']):
                    owasp_status['A03_injection']['status'] = 'fail'
                    owasp_status['A03_injection']['findings'].append(vuln.get('description', 'Injection vulnerability'))
                    
        # Check for security misconfigurations
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                headers = port_data.get('security_headers', {})
                for header, data in headers.items():
                    if not data.get('present', True):
                        owasp_status['A05_security_misconfiguration']['status'] = 'fail'
                        owasp_status['A05_security_misconfiguration']['findings'].append(f'Missing {header} header')
                        
        return owasp_status
        
    def _map_nist_framework(self, results):
        """Map findings to NIST Cybersecurity Framework"""
        return {
            'identify': {'score': 75, 'status': 'partial'},
            'protect': {'score': 60, 'status': 'partial'},
            'detect': {'score': 30, 'status': 'minimal'},
            'respond': {'score': 0, 'status': 'unknown'},
            'recover': {'score': 0, 'status': 'unknown'}
        }
        
    def _map_pci_dss(self, results):
        """Map findings to PCI DSS requirements"""
        return {
            'requirement_1': {'status': 'partial', 'description': 'Firewall configuration'},
            'requirement_2': {'status': 'fail', 'description': 'Default passwords'},
            'requirement_4': {'status': 'partial', 'description': 'Encryption in transit'},
            'requirement_6': {'status': 'fail', 'description': 'Secure development'},
            'requirement_11': {'status': 'pass', 'description': 'Security testing'}
        }
        
    def _map_iso27001(self, results):
        """Map findings to ISO 27001 controls"""
        return {
            'A.12.6.1': {'status': 'partial', 'description': 'Management of technical vulnerabilities'},
            'A.13.1.1': {'status': 'fail', 'description': 'Network controls'},
            'A.14.1.3': {'status': 'unknown', 'description': 'Protecting application services transactions'}
        }

class EvidenceCollector:
    """Collects and manages evidence (screenshots, packets, logs)"""
    
    def __init__(self):
        self.evidence_types = ['screenshots', 'http_samples', 'certificates', 'logs']
        
    def collect_evidence(self, results, output_dir):
        """Collect all available evidence"""
        evidence_dir = Path(output_dir) / "evidence"
        evidence_dir.mkdir(exist_ok=True)
        
        collected = []
        
        # Collect SSL certificates
        if 'security_analysis' in results:
            cert_evidence = self._collect_certificates(results['security_analysis'], evidence_dir)
            collected.extend(cert_evidence)
            
        # Collect HTTP samples
        if 'web_scan' in results:
            http_evidence = self._collect_http_samples(results['web_scan'], evidence_dir)
            collected.extend(http_evidence)
            
        return collected
        
    def _collect_certificates(self, security_analysis, evidence_dir):
        """Extract and save SSL certificates"""
        certificates = []
        ssl_analysis = security_analysis.get('ssl_analysis', {})
        
        for port, port_data in ssl_analysis.items():
            cert_info = port_data.get('certificate', {})
            if cert_info:
                cert_file = evidence_dir / f"certificate_{port}.json"
                with open(cert_file, 'w') as f:
                    json.dump(cert_info, f, indent=2)
                certificates.append(str(cert_file))
                
        return certificates
        
    def _collect_http_samples(self, web_scan, evidence_dir):
        """Collect HTTP request/response samples"""
        samples = []
        # Implementation would collect actual HTTP samples
        return samples

class BaselineTracker:
    """Tracks historical baselines and comparisons"""
    
    def __init__(self):
        self.baseline_file = "security_baseline.json"
        
    def update_baseline(self, results, target):
        """Update baseline with current scan results"""
        try:
            baseline_data = self._load_baseline()
            
            current_scan = {
                'timestamp': datetime.now().isoformat(),
                'target': target,
                'risk_score': self._extract_risk_score(results),
                'vulnerability_count': self._count_vulnerabilities(results),
                'open_ports': self._extract_open_ports(results)
            }
            
            if target not in baseline_data:
                baseline_data[target] = []
                
            baseline_data[target].append(current_scan)
            
            # Keep only last 10 scans
            baseline_data[target] = baseline_data[target][-10:]
            
            self._save_baseline(baseline_data)
            return True
            
        except Exception as e:
            logging.error(f"Failed to update baseline: {e}")
            return False
            
    def get_historical_comparison(self, target):
        """Get historical comparison data"""
        try:
            baseline_data = self._load_baseline()
            return baseline_data.get(target, [])
        except Exception:
            return []
            
    def _load_baseline(self):
        """Load baseline data from file"""
        try:
            if os.path.exists(self.baseline_file):
                with open(self.baseline_file, 'r') as f:
                    return json.load(f)
        except Exception:
            pass
        return {}
        
    def _save_baseline(self, data):
        """Save baseline data to file"""
        with open(self.baseline_file, 'w') as f:
            json.dump(data, f, indent=2)
            
    def _extract_risk_score(self, results):
        """Extract risk score from results"""
        # Implementation would extract actual risk score
        return 0
        
    def _count_vulnerabilities(self, results):
        """Count total vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            count += len(results['web_scan']['vulnerabilities'])
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                count += len(port_data.get('vulnerabilities', []))
        return count
        
    def _extract_open_ports(self, results):
        """Extract open ports list"""
        ports = []
        if 'nmap' in results and 'hosts' in results['nmap']:
            for host in results['nmap']['hosts']:
                for port_info in host.get('ports', []):
                    if port_info.get('state') == 'open':
                        ports.append(port_info.get('port'))
        return ports

class CSVExporter:
    """Export data to CSV format"""
    
    def export_vulnerabilities(self, results, output_dir):
        """Export vulnerabilities to CSV"""
        csv_file = Path(output_dir) / "vulnerabilities_detailed.csv"
        
        with open(csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Source', 'Port', 'Severity', 'Type', 'Name', 'Description', 'CVSS_Score'])
            
            # Web vulnerabilities
            if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
                for vuln in results['web_scan']['vulnerabilities']:
                    cvss_calc = CVSSCalculator()
                    cvss_score = cvss_calc.calculate_cvss(vuln)
                    writer.writerow([
                        'Web Scan',
                        vuln.get('port', 'N/A'),
                        vuln.get('severity', 'Unknown'),
                        vuln.get('type', 'Unknown'),
                        vuln.get('name', 'Unknown'),
                        vuln.get('description', 'No description'),
                        cvss_score
                    ])
                    
            # SSL/TLS vulnerabilities
            if 'security_analysis' in results:
                ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
                for port, port_data in ssl_analysis.items():
                    for vuln in port_data.get('vulnerabilities', []):
                        cvss_calc = CVSSCalculator()
                        cvss_score = cvss_calc.calculate_cvss(vuln)
                        writer.writerow([
                            'SSL/TLS Analysis',
                            port.replace('port_', ''),
                            vuln.get('severity', 'Unknown'),
                            vuln.get('type', 'Unknown'),
                            vuln.get('name', 'Unknown'),
                            vuln.get('description', 'No description'),
                            cvss_score
                        ])
                        
        return str(csv_file)
        
    def export_network_data(self, results, output_dir):
        """Export network/port data to CSV"""
        csv_file = Path(output_dir) / "network_analysis.csv"
        
        with open(csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Host', 'Port', 'Protocol', 'State', 'Service', 'Version', 'Risk_Level'])
            
            if 'nmap' in results and 'hosts' in results['nmap']:
                for host in results['nmap']['hosts']:
                    host_addr = host.get('address', 'Unknown')
                    for port_info in host.get('ports', []):
                        risk_level = self._assess_port_risk(port_info)
                        service_info = port_info.get('service', {})
                        writer.writerow([
                            host_addr,
                            port_info.get('port', 'Unknown'),
                            port_info.get('protocol', 'Unknown'),
                            port_info.get('state', 'Unknown'),
                            service_info.get('name', 'Unknown'),
                            service_info.get('version', 'Unknown'),
                            risk_level
                        ])
                        
        return str(csv_file)
        
    def _assess_port_risk(self, port_info):
        """Assess risk level for a port"""
        dangerous_ports = [21, 22, 23, 25, 53, 135, 139, 445, 1433, 3306, 3389, 5432]
        port = int(port_info.get('port', 0))
        
        if port in dangerous_ports:
            return 'High'
        elif port < 1024:
            return 'Medium'
        else:
            return 'Low'

class ExcelExporter:
    """Export data to Excel format (requires openpyxl)"""
    
    def __init__(self):
        self.available = self._check_dependencies()
        
    def _check_dependencies(self):
        """Check if Excel dependencies are available"""
        try:
            import openpyxl
            return True
        except ImportError:
            return False
            
    def export(self, results, output_dir):
        """Export comprehensive Excel workbook"""
        if not self.available:
            return None
            
        try:
            import openpyxl
            from openpyxl.styles import Font, PatternFill
            
            wb = openpyxl.Workbook()
            
            # Executive Summary sheet
            self._create_executive_sheet(wb, results)
            
            # Vulnerabilities sheet
            self._create_vulnerabilities_sheet(wb, results)
            
            # Network Analysis sheet
            self._create_network_sheet(wb, results)
            
            # Compliance sheet
            self._create_compliance_sheet(wb, results)
            
            excel_file = Path(output_dir) / "security_assessment.xlsx"
            wb.save(excel_file)
            
            return str(excel_file)
            
        except Exception as e:
            logging.error(f"Excel export failed: {e}")
            return None
            
    def _create_executive_sheet(self, workbook, results):
        """Create executive summary sheet"""
        try:
            from openpyxl.styles import Font, PatternFill
        except ImportError:
            Font = None
            PatternFill = None
            
        ws = workbook.active
        ws.title = "Executive Summary"
        
        # Headers
        ws['A1'] = "Security Assessment Executive Summary"
        if Font:
            ws['A1'].font = Font(size=16, bold=True)
        
        # Summary metrics
        ws['A3'] = "Metric"
        ws['B3'] = "Value"
        ws['A4'] = "Total Vulnerabilities"
        ws['A5'] = "Critical Vulnerabilities"
        ws['A6'] = "High Vulnerabilities"
        ws['A7'] = "Open Ports"
        ws['A8'] = "Risk Score"
        
        # Calculate values
        vuln_count = self._count_vulnerabilities(results)
        critical_count = self._count_critical_vulnerabilities(results)
        high_count = self._count_high_vulnerabilities(results)
        open_ports = self._count_open_ports(results)
        
        ws['B4'] = vuln_count
        ws['B5'] = critical_count
        ws['B6'] = high_count
        ws['B7'] = open_ports
        ws['B8'] = "Medium"  # Placeholder
        
    def _create_vulnerabilities_sheet(self, workbook, results):
        """Create detailed vulnerabilities sheet"""
        ws = workbook.create_sheet("Vulnerabilities")
        
        headers = ['Source', 'Severity', 'Type', 'Name', 'Description', 'CVSS Score']
        for col, header in enumerate(headers, 1):
            ws.cell(row=1, column=col, value=header)
            
        # Add vulnerability data
        row = 2
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            for vuln in results['web_scan']['vulnerabilities']:
                ws.cell(row=row, column=1, value='Web Scan')
                ws.cell(row=row, column=2, value=vuln.get('severity', 'Unknown'))
                ws.cell(row=row, column=3, value=vuln.get('type', 'Unknown'))
                ws.cell(row=row, column=4, value=vuln.get('name', 'Unknown'))
                ws.cell(row=row, column=5, value=vuln.get('description', 'No description'))
                
                cvss_calc = CVSSCalculator()
                cvss_score = cvss_calc.calculate_cvss(vuln)
                ws.cell(row=row, column=6, value=cvss_score)
                row += 1
                
    def _create_network_sheet(self, workbook, results):
        """Create network analysis sheet"""
        ws = workbook.create_sheet("Network Analysis")
        
        headers = ['Host', 'Port', 'Protocol', 'State', 'Service', 'Version']
        for col, header in enumerate(headers, 1):
            ws.cell(row=1, column=col, value=header)
            
        # Add network data
        row = 2
        if 'nmap' in results and 'hosts' in results['nmap']:
            for host in results['nmap']['hosts']:
                host_addr = host.get('address', 'Unknown')
                for port_info in host.get('ports', []):
                    ws.cell(row=row, column=1, value=host_addr)
                    ws.cell(row=row, column=2, value=port_info.get('port', 'Unknown'))
                    ws.cell(row=row, column=3, value=port_info.get('protocol', 'Unknown'))
                    ws.cell(row=row, column=4, value=port_info.get('state', 'Unknown'))
                    
                    service_info = port_info.get('service', {})
                    ws.cell(row=row, column=5, value=service_info.get('name', 'Unknown'))
                    ws.cell(row=row, column=6, value=service_info.get('version', 'Unknown'))
                    row += 1
                    
    def _create_compliance_sheet(self, workbook, results):
        """Create compliance mapping sheet"""
        try:
            from openpyxl.styles import Font, PatternFill
        except ImportError:
            Font = None
            PatternFill = None
            
        ws = workbook.create_sheet("Compliance")
        
        ws['A1'] = "Compliance Framework Mapping"
        if Font:
            ws['A1'].font = Font(size=14, bold=True)
        
        ws['A3'] = "Framework"
        ws['B3'] = "Control"
        ws['C3'] = "Status"
        ws['D3'] = "Findings"
        
        # Add compliance data
        compliance_mapper = ComplianceMapper()
        compliance_status = compliance_mapper.assess_compliance(results)
        
        row = 4
        for framework, controls in compliance_status.items():
            if isinstance(controls, dict):
                for control, data in controls.items():
                    ws.cell(row=row, column=1, value=framework.upper())
                    ws.cell(row=row, column=2, value=control)
                    ws.cell(row=row, column=3, value=data.get('status', 'Unknown'))
                    
                    findings = data.get('findings', [])
                    findings_text = '; '.join(findings) if findings else 'None'
                    ws.cell(row=row, column=4, value=findings_text)
                    row += 1
                    
    def _count_vulnerabilities(self, results):
        """Count total vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            count += len(results['web_scan']['vulnerabilities'])
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                count += len(port_data.get('vulnerabilities', []))
        return count
        
    def _count_critical_vulnerabilities(self, results):
        """Count critical vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            for vuln in results['web_scan']['vulnerabilities']:
                if vuln.get('severity', '').lower() == 'critical':
                    count += 1
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                for vuln in port_data.get('vulnerabilities', []):
                    if vuln.get('severity', '').lower() == 'critical':
                        count += 1
        return count
        
    def _count_high_vulnerabilities(self, results):
        """Count high severity vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            for vuln in results['web_scan']['vulnerabilities']:
                if vuln.get('severity', '').lower() == 'high':
                    count += 1
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                for vuln in port_data.get('vulnerabilities', []):
                    if vuln.get('severity', '').lower() == 'high':
                        count += 1
        return count
        
    def _count_open_ports(self, results):
        """Count open ports"""
        count = 0
        if 'nmap' in results and 'hosts' in results['nmap']:
            for host in results['nmap']['hosts']:
                for port_info in host.get('ports', []):
                    if port_info.get('state') == 'open':
                        count += 1
        return count

class WordExporter:
    """Export data to Word document format (requires python-docx)"""
    
    def __init__(self):
        self.available = self._check_dependencies()
        
    def _check_dependencies(self):
        """Check if Word dependencies are available"""
        try:
            import docx
            return True
        except ImportError:
            return False
            
    def export(self, results, output_dir):
        """Export comprehensive Word document"""
        if not self.available:
            return None
            
        try:
            import docx
            from docx.shared import Inches
            
            doc = docx.Document()
            
            # Title
            title = doc.add_heading('Security Assessment Report', 0)
            
            # Executive Summary
            doc.add_heading('Executive Summary', 1)
            summary_para = doc.add_paragraph()
            summary_para.add_run('This report presents the findings of a comprehensive security assessment conducted on the target system.')
            
            # Vulnerability Summary
            doc.add_heading('Vulnerability Summary', 2)
            vuln_count = self._count_vulnerabilities(results)
            doc.add_paragraph(f'Total vulnerabilities identified: {vuln_count}')
            
            # Detailed Findings
            doc.add_heading('Detailed Findings', 1)
            
            if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
                doc.add_heading('Web Application Vulnerabilities', 2)
                for vuln in results['web_scan']['vulnerabilities']:
                    doc.add_heading(vuln.get('name', 'Unknown Vulnerability'), 3)
                    doc.add_paragraph(f"Severity: {vuln.get('severity', 'Unknown')}")
                    doc.add_paragraph(f"Description: {vuln.get('description', 'No description available')}")
                    
            # Network Analysis
            if 'nmap' in results:
                doc.add_heading('Network Analysis', 2)
                doc.add_paragraph('The following network services were identified:')
                
                if 'hosts' in results['nmap']:
                    for host in results['nmap']['hosts']:
                        doc.add_paragraph(f"Host: {host.get('address', 'Unknown')}")
                        for port_info in host.get('ports', []):
                            if port_info.get('state') == 'open':
                                service_info = port_info.get('service', {})
                                doc.add_paragraph(f"  Port {port_info.get('port')}: {service_info.get('name', 'Unknown')} ({service_info.get('version', 'Unknown version')})")
                                
            # Recommendations
            doc.add_heading('Recommendations', 1)
            doc.add_paragraph('Based on the findings, the following remediation actions are recommended:')
            doc.add_paragraph('1. Address all critical and high severity vulnerabilities immediately')
            doc.add_paragraph('2. Implement proper SSL/TLS configuration')
            doc.add_paragraph('3. Review and harden network service configurations')
            doc.add_paragraph('4. Establish a regular vulnerability assessment schedule')
            
            word_file = Path(output_dir) / "security_assessment_report.docx"
            doc.save(word_file)
            
            return str(word_file)
            
        except Exception as e:
            logging.error(f"Word export failed: {e}")
            return None
            
    def _count_vulnerabilities(self, results):
        """Count total vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            count += len(results['web_scan']['vulnerabilities'])
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                count += len(port_data.get('vulnerabilities', []))
        return count

class PowerPointExporter:
    """Export data to PowerPoint presentation format (requires python-pptx)"""
    
    def __init__(self):
        self.available = self._check_dependencies()
        
    def _check_dependencies(self):
        """Check if PowerPoint dependencies are available"""
        try:
            import pptx
            return True
        except ImportError:
            return False
            
    def export(self, results, output_dir):
        """Export executive PowerPoint presentation"""
        if not self.available:
            return None
            
        try:
            import pptx
            from pptx.util import Inches
            
            prs = pptx.Presentation()
            
            # Title slide
            title_slide_layout = prs.slide_layouts[0]
            slide = prs.slides.add_slide(title_slide_layout)
            title = slide.shapes.title
            subtitle = slide.placeholders[1]
            
            title.text = "Security Assessment"
            subtitle.text = f"Executive Summary\nTarget: {results.get('target', 'Unknown')}"
            
            # Executive Summary slide
            bullet_slide_layout = prs.slide_layouts[1]
            slide = prs.slides.add_slide(bullet_slide_layout)
            shapes = slide.shapes
            
            title_shape = shapes.title
            body_shape = shapes.placeholders[1]
            
            title_shape.text = 'Executive Summary'
            
            tf = body_shape.text_frame
            tf.text = 'Key Findings:'
            
            p = tf.add_paragraph()
            vuln_count = self._count_vulnerabilities(results)
            p.text = f'Total vulnerabilities: {vuln_count}'
            p.level = 1
            
            p = tf.add_paragraph()
            p.text = f'Critical vulnerabilities: {self._count_critical_vulnerabilities(results)}'
            p.level = 1
            
            p = tf.add_paragraph()
            p.text = f'High vulnerabilities: {self._count_high_vulnerabilities(results)}'
            p.level = 1
            
            # Recommendations slide
            slide = prs.slides.add_slide(bullet_slide_layout)
            shapes = slide.shapes
            
            title_shape = shapes.title
            body_shape = shapes.placeholders[1]
            
            title_shape.text = 'Recommendations'
            
            tf = body_shape.text_frame
            tf.text = 'Immediate Actions Required:'
            
            recommendations = [
                'Address all critical vulnerabilities immediately',
                'Implement proper SSL/TLS configuration',
                'Review network service configurations',
                'Establish regular security assessments'
            ]
            
            for rec in recommendations:
                p = tf.add_paragraph()
                p.text = rec
                p.level = 1
                
            pptx_file = Path(output_dir) / "security_assessment_executive.pptx"
            prs.save(pptx_file)
            
            return str(pptx_file)
            
        except Exception as e:
            logging.error(f"PowerPoint export failed: {e}")
            return None
            
    def _count_vulnerabilities(self, results):
        """Count total vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            count += len(results['web_scan']['vulnerabilities'])
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                count += len(port_data.get('vulnerabilities', []))
        return count
        
    def _count_critical_vulnerabilities(self, results):
        """Count critical vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            for vuln in results['web_scan']['vulnerabilities']:
                if vuln.get('severity', '').lower() == 'critical':
                    count += 1
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                for vuln in port_data.get('vulnerabilities', []):
                    if vuln.get('severity', '').lower() == 'critical':
                        count += 1
        return count
        
    def _count_high_vulnerabilities(self, results):
        """Count high severity vulnerabilities"""
        count = 0
        if 'web_scan' in results and 'vulnerabilities' in results['web_scan']:
            for vuln in results['web_scan']['vulnerabilities']:
                if vuln.get('severity', '').lower() == 'high':
                    count += 1
        if 'security_analysis' in results:
            ssl_analysis = results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                for vuln in port_data.get('vulnerabilities', []):
                    if vuln.get('severity', '').lower() == 'high':
                        count += 1
        return count


class AdvancedReportGenerator:
    """Advanced reporting with visualizations, risk scoring, and multiple formats"""
    
    def __init__(self, output_dir, results, target, config=None):
        self.output_dir = Path(output_dir)
        self.results = results
        self.target = target
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.risk_scorer = RiskScorer(config)
        
        # Enhanced components
        self.cvss_calculator = CVSSCalculator()
        self.compliance_mapper = ComplianceMapper()
        self.evidence_collector = EvidenceCollector()
        self.baseline_tracker = BaselineTracker()
        
        # Multi-format exporters
        self.exporters = {
            'csv': CSVExporter(),
            'excel': ExcelExporter() if self._check_excel_support() else None,
            'word': WordExporter() if self._check_word_support() else None,
            'powerpoint': PowerPointExporter() if self._check_pptx_support() else None
        }
        
    def _check_excel_support(self):
        """Check if Excel export is supported"""
        try:
            import openpyxl
            return True
        except ImportError:
            return False
            
    def _check_word_support(self):
        """Check if Word export is supported"""
        try:
            import docx
            return True
        except ImportError:
            return False
            
    def _check_pptx_support(self):
        """Check if PowerPoint export is supported"""
        try:
            import pptx
            return True
        except ImportError:
            return False
        
    def generate_all_reports(self):
        """Generate all available report formats with enhanced features"""
        try:
            self.logger.info("Generating enhanced advanced reports...")
            
            # Calculate comprehensive risk assessment with CVSS scoring
            risk_assessment = self.risk_scorer.calculate_risk_score(self.results)
            
            # Assess compliance frameworks
            compliance_status = self.compliance_mapper.assess_compliance(self.results)
            
            # Generate reports
            reports_generated = []
            
            # 1. Executive Summary PDF
            if self._generate_executive_pdf(risk_assessment):
                reports_generated.append('Executive PDF')
                
            # 2. Technical Report PDF
            if self._generate_technical_pdf(risk_assessment):
                reports_generated.append('Technical PDF')
                
            # 3. Risk Assessment with CVSS scores
            if self._generate_enhanced_risk_json(risk_assessment):
                reports_generated.append('Enhanced Risk Assessment JSON')
                
            # 4. Compliance Framework Reports
            if self._generate_enhanced_compliance_report(compliance_status):
                reports_generated.append('Compliance Framework Report')
                
            # 5. Multi-format Data Exports
            export_results = self._generate_multiformat_exports()
            if export_results:
                reports_generated.extend(export_results)
                
            # 7. Evidence Collection
            if self._collect_and_organize_evidence():
                reports_generated.append('Evidence Collection')
                
            # 8. Historical Baseline Update
            if self._update_security_baseline():
                reports_generated.append('Baseline Tracking')
                
            self.logger.info(f"Generated enhanced reports: {', '.join(reports_generated)}")
            return reports_generated
            
        except Exception as e:
            self.logger.error(f"Enhanced report generation failed: {str(e)}")
            import traceback
            self.logger.error(f"Traceback: {traceback.format_exc()}")
            return []
            
    def _generate_risk_json(self, risk_assessment):
        """Generate detailed risk assessment JSON"""
        try:
            risk_file = self.output_dir / 'risk_assessment.json'
            
            # Enhanced risk data
            enhanced_risk = {
                'target': self.target,
                'scan_timestamp': datetime.now().isoformat(),
                'risk_assessment': risk_assessment,
                'detailed_findings': self._compile_detailed_findings(),
                'compliance_status': self._assess_compliance(),
                'executive_summary': self._generate_executive_summary(risk_assessment)
            }
            
            with open(risk_file, 'w') as f:
                json.dump(enhanced_risk, f, indent=2, default=str)
                
            self.logger.info(f"Risk assessment JSON saved to {risk_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"Risk JSON generation failed: {str(e)}")
            return False
            
    def _compile_detailed_findings(self):
        """Compile detailed security findings"""
        findings = {
            'vulnerabilities': [],
            'misconfigurations': [],
            'exposures': [],
            'certificates': []
        }
        
        # Security analysis findings
        security_results = self.results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_key, port_data in ssl_analysis.items():
            port = port_key.replace('port_', '')
            
            # Vulnerabilities
            for vuln in port_data.get('vulnerabilities', []):
                findings['vulnerabilities'].append({
                    'port': port,
                    'severity': vuln.get('severity'),
                    'type': vuln.get('type'),
                    'name': vuln.get('name'),
                    'description': vuln.get('description')
                })
                
            # Certificate issues
            cert_info = port_data.get('certificate')
            if cert_info:
                findings['certificates'].append({
                    'port': port,
                    'subject': cert_info.get('subject', {}),
                    'issuer': cert_info.get('issuer', {}),
                    'expiry': cert_info.get('not_after'),
                    'fingerprint': cert_info.get('sha256_fingerprint')
                })
                
        return findings
        
    def _assess_compliance(self):
        """Assess compliance with common frameworks"""
        compliance = {
            'owasp_top_10': self._check_owasp_compliance(),
            'nist_framework': self._check_nist_compliance(),
            'pci_dss': self._check_pci_compliance()
        }
        return compliance
        
    def _check_owasp_compliance(self):
        """Check OWASP Top 10 compliance"""
        owasp_checks = {
            'A02_cryptographic_failures': self._check_crypto_failures(),
            'A05_security_misconfiguration': self._check_security_misconfig(),
            'A06_vulnerable_components': self._check_vulnerable_components(),
            'A07_identification_failures': self._check_auth_failures()
        }
        return owasp_checks
        
    def _check_crypto_failures(self):
        """Check for cryptographic failures"""
        issues = []
        security_results = self.results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            protocols = port_data.get('protocols', [])
            for proto in protocols:
                if proto.get('supported') and proto.get('name') in ['SSLv2', 'SSLv3', 'TLSv1.0']:
                    issues.append(f"Weak protocol {proto.get('name')} supported")
                    
        return {'status': 'fail' if issues else 'pass', 'issues': issues}
        
    def _check_security_misconfig(self):
        """Check for security misconfigurations"""
        issues = []
        security_results = self.results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            headers = port_data.get('security_headers', {})
            required_headers = ['Strict-Transport-Security', 'Content-Security-Policy', 'X-Frame-Options']
            for header in required_headers:
                if not headers.get(header, {}).get('present'):
                    issues.append(f"Missing security header: {header}")
                    
        return {'status': 'fail' if issues else 'pass', 'issues': issues}
        
    def _check_vulnerable_components(self):
        """Check for vulnerable components"""
        issues = []
        
        # Check for expired certificates
        security_results = self.results.get('security_analysis', {})
        ssl_analysis = security_results.get('ssl_analysis', {})
        
        for port_data in ssl_analysis.values():
            cert_info = port_data.get('certificate')
            if cert_info:
                try:
                    from datetime import datetime
                    if cert_info.get('not_after'):
                        expiry = datetime.fromisoformat(cert_info['not_after'].replace('Z', '+00:00'))
                        if expiry < datetime.now():
                            issues.append("Expired SSL certificate detected")
                except Exception:
                    pass
                    
        return {'status': 'fail' if issues else 'pass', 'issues': issues}
        
    def _check_auth_failures(self):
        """Check for authentication failures"""
        # This would be enhanced with actual auth testing results
        return {'status': 'unknown', 'issues': ['Authentication testing not implemented']}
        
    def _check_nist_compliance(self):
        """Check NIST Cybersecurity Framework alignment"""
        return {
            'identify': {'status': 'partial', 'score': 75},
            'protect': {'status': 'partial', 'score': 60},
            'detect': {'status': 'minimal', 'score': 30},
            'respond': {'status': 'unknown', 'score': 0},
            'recover': {'status': 'unknown', 'score': 0}
        }
        
    def _check_pci_compliance(self):
        """Check PCI DSS compliance indicators"""
        issues = []
        
        # Check for common PCI DSS requirements
        nmap_results = self.results.get('nmap', {})
        hosts = nmap_results.get('hosts', [])
        
        for host in hosts:
            ports = host.get('ports', [])
            for port in ports:
                if port.get('state') == 'open' and port.get('port') in [21, 23, 135, 139, 445]:
                    issues.append(f"High-risk port {port.get('port')} is open")
                    
        return {'status': 'fail' if issues else 'partial', 'issues': issues}
        
    def _generate_executive_summary(self, risk_assessment):
        """Generate executive summary"""
        risk_score = risk_assessment.get('total_score', 0)
        risk_level = risk_assessment.get('risk_level', 'unknown')
        
        summary = {
            'overall_security_posture': f"Risk Level: {risk_level.title()} ({risk_score}/100)",
            'key_findings': [],
            'immediate_actions': [],
            'business_impact': self._assess_business_impact(risk_score)
        }
        
        # Key findings
        vuln_counts = self._count_vulnerabilities()
        if vuln_counts['critical_vulns'] > 0:
            summary['key_findings'].append(f"{vuln_counts['critical_vulns']} critical vulnerabilities identified")
        if vuln_counts['high_vulns'] > 0:
            summary['key_findings'].append(f"{vuln_counts['high_vulns']} high-severity vulnerabilities found")
            
        # Immediate actions from recommendations
        recommendations = risk_assessment.get('recommendations', [])
        for rec in recommendations[:3]:  # Top 3
            if rec.get('priority') in ['critical', 'high']:
                summary['immediate_actions'].append(rec.get('title'))
                
        return summary
        
    def _assess_business_impact(self, risk_score):
        """Assess business impact based on risk score"""
        if risk_score >= 70:
            return "High - Immediate security response required. Potential for significant business disruption."
        elif risk_score >= 50:
            return "Medium - Security improvements needed within 30 days. Risk of compliance violations."
        elif risk_score >= 30:
            return "Low - Address security gaps as part of regular maintenance cycle."
        else:
            return "Minimal - Continue monitoring and maintain current security posture."
            
    # Placeholder methods for other report types
    def _generate_executive_pdf(self, risk_assessment):
        """Generate executive PDF report"""
        try:
            if not HAS_REPORTLAB:
                self.logger.warning("ReportLab not available, skipping PDF generation")
                return False
                
            # PDF generation would be implemented here
            self.logger.info("Executive PDF generation not yet implemented")
            return False
        except Exception as e:
            self.logger.error(f"Executive PDF generation failed: {str(e)}")
            return False
            
    def _generate_technical_pdf(self, risk_assessment):
        """Generate technical PDF report"""
        try:
            if not HAS_REPORTLAB:
                self.logger.warning("ReportLab not available, skipping technical PDF generation")
                return False
                
            # Technical PDF generation would be implemented here
            self.logger.info("Technical PDF generation not yet implemented")
            return False
        except Exception as e:
            self.logger.error(f"Technical PDF generation failed: {str(e)}")
            return False
            
    def _generate_compliance_report(self, risk_assessment):
        """Generate compliance report"""
        try:
            compliance_file = self.output_dir / 'compliance_report.json'
            
            compliance_data = {
                'target': self.target,
                'assessment_date': datetime.now().isoformat(),
                'frameworks': self._assess_compliance(),
                'risk_assessment': risk_assessment,
                'recommendations': self._generate_compliance_recommendations()
            }
            
            with open(compliance_file, 'w') as f:
                json.dump(compliance_data, f, indent=2, default=str)
                
            self.logger.info(f"Compliance report saved to {compliance_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"Compliance report generation failed: {str(e)}")
            return False
            
    def _generate_compliance_recommendations(self):
        """Generate compliance-specific recommendations"""
        recommendations = [
            {
                'framework': 'OWASP',
                'requirement': 'A02 - Cryptographic Failures',
                'status': 'non-compliant',
                'recommendation': 'Disable weak SSL/TLS protocols (SSLv2, SSLv3, TLSv1.0)'
            },
            {
                'framework': 'NIST',
                'requirement': 'PR.DS-2 - Data-in-transit protection',
                'status': 'partial',
                'recommendation': 'Implement HSTS and strong cipher suites'
            }
        ]
        return recommendations
        
    def _generate_csv_export(self):
        """Generate CSV data export"""
        try:
            import csv
            
            # Vulnerabilities CSV
            vuln_file = self.output_dir / 'vulnerabilities.csv'
            with open(vuln_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['Port', 'Severity', 'Type', 'Name', 'Description'])
                
                security_results = self.results.get('security_analysis', {})
                ssl_analysis = security_results.get('ssl_analysis', {})
                
                for port_key, port_data in ssl_analysis.items():
                    port = port_key.replace('port_', '')
                    for vuln in port_data.get('vulnerabilities', []):
                        writer.writerow([
                            port,
                            vuln.get('severity', ''),
                            vuln.get('type', ''),
                            vuln.get('name', ''),
                            vuln.get('description', '')
                        ])
                        
            # Ports CSV
            ports_file = self.output_dir / 'open_ports.csv'
            with open(ports_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['Host', 'Port', 'Protocol', 'State', 'Service', 'Version'])
                
                nmap_results = self.results.get('nmap', {})
                hosts = nmap_results.get('hosts', [])
                
                for host in hosts:
                    host_ip = host.get('address', '')
                    for port in host.get('ports', []):
                        writer.writerow([
                            host_ip,
                            port.get('port', ''),
                            port.get('protocol', ''),
                            port.get('state', ''),
                            port.get('service', ''),
                            port.get('version', '')
                        ])
                        
            self.logger.info(f"CSV exports saved to {vuln_file} and {ports_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"CSV export generation failed: {str(e)}")
            return False
            
    def _generate_enhanced_dashboard(self, risk_assessment, compliance_status):
        """Dashboard generation removed - will be implemented later"""
        pass
            
    def _create_interactive_dashboard(self, risk_assessment, compliance_status):
        """Dashboard generation removed - will be implemented later"""
        pass
        """Create fully interactive HTML dashboard with advanced features"""
        
        # Calculate comprehensive statistics
        vuln_stats = self._calculate_vulnerability_statistics()
        network_stats = self._calculate_network_statistics()
        
        html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Security Dashboard - {self.target}</title>
    
    <!-- External Libraries for Advanced Interactive Visualizations -->
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/apexcharts"></script>
    <script src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css" rel="stylesheet">
    <link href="https://cdn.datatables.net/1.13.6/css/dataTables.bootstrap5.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.7.0.min.js"></script>
    <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js"></script>
    <script src="https://cdn.datatables.net/1.13.6/js/dataTables.bootstrap5.min.js"></script>
    
    <style>
        {self._get_interactive_dashboard_css()}
    </style>
</head>
<body>
    <div class="dashboard-container">
        <!-- Interactive Navigation & Controls -->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark sticky-top">
            <div class="container-fluid">
                <a class="navbar-brand" href="#"><i class="fas fa-shield-alt"></i> Security Dashboard</a>
                <div class="navbar-nav ms-auto">
                    <div class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="viewDropdown" role="button" data-bs-toggle="dropdown">
                            <i class="fas fa-eye"></i> Views
                        </a>
                        <ul class="dropdown-menu">
                            <li><a class="dropdown-item" href="#" onclick="switchView('executive')">Executive Summary</a></li>
                            <li><a class="dropdown-item" href="#" onclick="switchView('technical')">Technical Details</a></li>
                            <li><a class="dropdown-item" href="#" onclick="switchView('compliance')">Compliance View</a></li>
                            <li><a class="dropdown-item" href="#" onclick="switchView('timeline')">Timeline View</a></li>
                        </ul>
                    </div>
                    <div class="nav-item">
                        <button class="btn btn-outline-light btn-sm" onclick="toggleFullscreen()">
                            <i class="fas fa-expand-arrows-alt"></i> Fullscreen
                        </button>
                    </div>
                    <div class="nav-item">
                        <button class="btn btn-outline-success btn-sm ms-2" onclick="exportDashboard()">
                            <i class="fas fa-download"></i> Export
                        </button>
                    </div>
                </div>
            </div>
        </nav>
        
        <!-- Real-time Status Bar -->
        <div class="alert alert-info alert-dismissible fade show m-0" role="alert">
            <i class="fas fa-info-circle"></i> <span id="statusMessage">Dashboard loaded successfully</span>
            <div class="float-end">
                <small>Last Updated: <span id="lastUpdate">{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</span></small>
                <button class="btn btn-sm btn-outline-primary ms-2" onclick="refreshData()">
                    <i class="fas fa-sync-alt"></i> Refresh
                </button>
            </div>
            <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
        </div>
        
        <!-- Interactive Filters Panel -->
        <div class="filters-panel bg-light border-bottom">
            <div class="container-fluid py-3">
                <div class="row align-items-center">
                    <div class="col-md-3">
                        <label class="form-label">Severity Filter:</label>
                        <select class="form-select form-select-sm" id="severityFilter" onchange="applyFilters()">
                            <option value="all">All Severities</option>
                            <option value="critical">Critical Only</option>
                            <option value="high">High & Above</option>
                            <option value="medium">Medium & Above</option>
                            <option value="low">Low & Above</option>
                        </select>
                    </div>
                    <div class="col-md-3">
                        <label class="form-label">Vulnerability Type:</label>
                        <select class="form-select form-select-sm" id="typeFilter" onchange="applyFilters()">
                            <option value="all">All Types</option>
                            <option value="network">Network</option>
                            <option value="web">Web Application</option>
                            <option value="ssl">SSL/TLS</option>
                            <option value="config">Configuration</option>
                        </select>
                    </div>
                    <div class="col-md-3">
                        <label class="form-label">Date Range:</label>
                        <select class="form-select form-select-sm" id="dateFilter" onchange="applyFilters()">
                            <option value="all">All Time</option>
                            <option value="today">Today</option>
                            <option value="week">Last 7 Days</option>
                            <option value="month">Last 30 Days</option>
                        </select>
                    </div>
                    <div class="col-md-3">
                        <label class="form-label">Quick Search:</label>
                        <input type="text" class="form-control form-control-sm" id="searchFilter" 
                               placeholder="Search vulnerabilities..." onkeyup="applyFilters()">
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Main Dashboard Content -->
        <main class="dashboard-main">
            <!-- Executive Summary Section -->
            <section id="executiveView" class="dashboard-section py-4">
                <div class="container-fluid">
                    <div class="d-flex justify-content-between align-items-center mb-4">
                        <h2><i class="fas fa-tachometer-alt"></i> Executive Overview</h2>
                        <div class="btn-group" role="group">
                            <button type="button" class="btn btn-outline-primary btn-sm" onclick="zoomChart('all')">
                                <i class="fas fa-search-plus"></i> Zoom All
                            </button>
                            <button type="button" class="btn btn-outline-secondary btn-sm" onclick="resetCharts()">
                                <i class="fas fa-undo"></i> Reset
                            </button>
                        </div>
                    </div>
                    
                    <!-- Interactive KPI Cards -->
                    <div class="row mb-4">
                        {self._generate_interactive_kpi_cards(vuln_stats, network_stats, risk_assessment)}
                    </div>
                    
                    <!-- Advanced Interactive Charts Grid -->
                    <div class="row">
                        <div class="col-lg-6 mb-4">
                            <div class="card chart-card">
                                <div class="card-header d-flex justify-content-between align-items-center">
                                    <h5><i class="fas fa-chart-pie"></i> Risk Distribution</h5>
                                    <div class="chart-controls">
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleChartType('riskChart', 'pie')">
                                            <i class="fas fa-chart-pie"></i>
                                        </button>
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleChartType('riskChart', 'doughnut')">
                                            <i class="fas fa-circle-notch"></i>
                                        </button>
                                        <button class="btn btn-sm btn-outline-secondary" onclick="downloadChart('riskChart')">
                                            <i class="fas fa-download"></i>
                                        </button>
                                    </div>
                                </div>
                                <div class="card-body">
                                    <div id="riskChart" style="height: 350px;"></div>
                                    <div class="chart-summary mt-2">
                                        <small class="text-muted">Click segments for detailed breakdown</small>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="col-lg-6 mb-4">
                            <div class="card chart-card">
                                <div class="card-header d-flex justify-content-between align-items-center">
                                    <h5><i class="fas fa-chart-bar"></i> Vulnerability Trends</h5>
                                    <div class="chart-controls">
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleChartType('vulnTrendChart', 'bar')">
                                            <i class="fas fa-chart-bar"></i>
                                        </button>
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleChartType('vulnTrendChart', 'line')">
                                            <i class="fas fa-chart-line"></i>
                                        </button>
                                        <button class="btn btn-sm btn-outline-secondary" onclick="downloadChart('vulnTrendChart')">
                                            <i class="fas fa-download"></i>
                                        </button>
                                    </div>
                                </div>
                                <div class="card-body">
                                    <div id="vulnTrendChart" style="height: 350px;"></div>
                                    <div class="chart-summary mt-2">
                                        <small class="text-muted">Hover for details, drag to zoom</small>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Network Topology & Compliance Charts -->
                    <div class="row">
                        <div class="col-lg-8 mb-4">
                            <div class="card chart-card">
                                <div class="card-header d-flex justify-content-between align-items-center">
                                    <h5><i class="fas fa-project-diagram"></i> Interactive Network Topology</h5>
                                    <div class="chart-controls">
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleTopologyView('force')">
                                            <i class="fas fa-snowflake"></i> Force
                                        </button>
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleTopologyView('hierarchical')">
                                            <i class="fas fa-sitemap"></i> Hierarchy
                                        </button>
                                        <button class="btn btn-sm btn-outline-primary" onclick="toggleTopologyView('circular')">
                                            <i class="fas fa-circle"></i> Circular
                                        </button>
                                    </div>
                                </div>
                                <div class="card-body">
                                    <div id="networkTopology" style="height: 400px;"></div>
                                    <div class="topology-legend mt-2">
                                        <small class="text-muted">Drag nodes to reposition ‚Ä¢ Click for details ‚Ä¢ Scroll to zoom</small>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="col-lg-4 mb-4">
                            <div class="card chart-card">
                                <div class="card-header">
                                    <h5><i class="fas fa-shield-alt"></i> Compliance Score</h5>
                                </div>
                                <div class="card-body">
                                    <div id="complianceRadar" style="height: 400px;"></div>
                                    <div class="mt-2">
                                        <small class="text-muted">Interactive radar chart</small>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            
            <!-- Technical Details Section -->
            <section id="technicalView" class="dashboard-section py-4" style="display: none;">
                <div class="container-fluid">
                    <h2><i class="fas fa-cogs"></i> Technical Analysis</h2>
                    
                    <!-- Interactive Data Tables -->
                    <div class="row">
                        <div class="col-12 mb-4">
                            <div class="card">
                                <div class="card-header d-flex justify-content-between align-items-center">
                                    <h5><i class="fas fa-table"></i> Vulnerability Details</h5>
                                    <div>
                                        <button class="btn btn-sm btn-outline-primary" onclick="exportTable('vulnerabilitiesTable')">
                                            <i class="fas fa-file-csv"></i> Export CSV
                                        </button>
                                        <button class="btn btn-sm btn-outline-secondary" onclick="toggleTableView()">
                                            <i class="fas fa-expand"></i> Expand
                                        </button>
                                    </div>
                                </div>
                                <div class="card-body">
                                    <table id="vulnerabilitiesTable" class="table table-striped table-hover">
                                        <thead class="table-dark">
                                            <tr>
                                                <th>ID</th>
                                                <th>Type/Source</th>
                                                <th>Severity</th>
                                                <th>Description</th>
                                                <th>CVSS Score</th>
                                                <th>Vector</th>
                                                <th>CWE</th>
                                                <th>Confidence</th>
                                                <th>Actions</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            {self._generate_interactive_vulnerability_rows()}
                                        </tbody>
                                    </table>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Network Services Table -->
                    <div class="row">
                        <div class="col-12 mb-4">
                            <div class="card">
                                <div class="card-header">
                                    <h5><i class="fas fa-network-wired"></i> Network Services</h5>
                                </div>
                                <div class="card-body">
                                    <table id="servicesTable" class="table table-striped">
                                        <thead class="table-dark">
                                            <tr>
                                                <th>Host</th>
                                                <th>Port</th>
                                                <th>Service</th>
                                                <th>Version</th>
                                                <th>Risk Level</th>
                                                <th>Status</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            {self._generate_interactive_services_rows()}
                                        </tbody>
                                    </table>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            
            <!-- Compliance View Section -->
            <section id="complianceView" class="dashboard-section py-4" style="display: none;">
                <div class="container-fluid">
                    <h2><i class="fas fa-clipboard-check"></i> Compliance Framework Analysis</h2>
                    <div class="row">
                        {self._generate_interactive_compliance_cards(compliance_status)}
                    </div>
                </div>
            </section>
            
            <!-- Timeline View Section -->
            <section id="timelineView" class="dashboard-section py-4" style="display: none;">
                <div class="container-fluid">
                    <h2><i class="fas fa-clock"></i> Assessment Timeline</h2>
                    <div class="card">
                        <div class="card-body">
                            <div id="timelineChart" style="height: 500px;"></div>
                        </div>
                    </div>
                </div>
            </section>
        </main>
    </div>
    
    <!-- Modal for Detailed View -->
    <div class="modal fade" id="detailModal" tabindex="-1">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="detailModalTitle">Vulnerability Details</h5>
                    <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
                </div>
                <div class="modal-body" id="detailModalBody">
                    <!-- Dynamic content loaded here -->
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                    <button type="button" class="btn btn-primary" onclick="generateReport()">Generate Report</button>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    
    <!-- Interactive Dashboard JavaScript -->
    <script>
        // Global dashboard data
        const dashboardData = {{
            vulnerabilities: {json.dumps(vuln_stats.get('vulnerabilities', []), default=str)},
            networkServices: {json.dumps(network_stats.get('services', []), default=str)},
            riskAssessment: {json.dumps(risk_assessment, default=str)},
            complianceStatus: {json.dumps(compliance_status, default=str)},
            target: '{self.target}',
            timestamp: '{datetime.now().isoformat()}'
        }};
        
        // Initialize dashboard when DOM is ready
        document.addEventListener('DOMContentLoaded', function() {{
            initializeDashboard();
            {self._generate_advanced_interactive_js()}
        }});
    </script>
</body>
</html>
        """
        
        return html_content
        
    def _get_interactive_dashboard_css(self):
        """Dashboard CSS removed - will be implemented later"""
        pass
        
    def _generate_advanced_interactive_js(self):
        """Dashboard JavaScript removed - will be implemented later"""
        pass
        
        .kpi-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(45deg, rgba(255,255,255,0.1) 0%, transparent 100%);
            pointer-events: none;
        }
        
        .kpi-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.25);
        }
        
        .kpi-card.critical { background: linear-gradient(135deg, #ff416c, #ff4757); }
        .kpi-card.high { background: linear-gradient(135deg, #ffa726, #ff9800); }
        .kpi-card.medium { background: linear-gradient(135deg, #ffee58, #fdd835); color: #333; }
        .kpi-card.low { background: linear-gradient(135deg, #4caf50, #2e7d32); }
        
        .metric-value { 
            font-size: 3rem; 
            font-weight: bold; 
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            margin-bottom: 10px;
        }
        
        .metric-label {
            font-size: 1.1rem;
            opacity: 0.9;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .table-responsive {
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        .table th {
            background: linear-gradient(135deg, #343a40, #495057);
            color: white;
            border: none;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .table td {
            border: none;
            padding: 15px;
            vertical-align: middle;
        }
        
        .table-striped tbody tr:nth-of-type(odd) {
            background-color: rgba(0,0,0,0.02);
        }
        
        .table-hover tbody tr:hover {
            background-color: rgba(0,123,255,0.1);
            transform: scale(1.01);
            transition: all 0.2s ease;
        }
        
        .badge {
            font-size: 0.8rem;
            padding: 6px 12px;
            border-radius: 20px;
            font-weight: 600;
        }
        
        .btn-action {
            padding: 4px 8px;
            margin: 2px;
            border-radius: 15px;
            font-size: 0.8rem;
        }
        
        .dashboard-section {
            transition: all 0.3s ease;
        }
        
        .navbar-brand {
            font-weight: bold;
            font-size: 1.3rem;
        }
        
        .modal-content {
            border-radius: 15px;
            border: none;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
        }
        
        .modal-header {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border-radius: 15px 15px 0 0;
        }
        
        .alert {
            border-radius: 10px;
            border: none;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        .pulse {
            animation: pulse 2s infinite;
        }
        
        @media (max-width: 768px) {
            .filters-panel .row > div {
                margin-bottom: 15px;
            }
            
            .chart-controls {
                margin-top: 10px;
            }
            
            .metric-value {
                font-size: 2rem;
            }
        }
        """
        
    def _generate_advanced_interactive_js(self):
        """Generate advanced interactive JavaScript for dashboard functionality"""
        return """
        // Initialize Dashboard
        function initializeDashboard() {
            console.log('üöÄ Initializing Interactive Security Dashboard');
            
            // Initialize data tables with advanced features
            initializeDataTables();
            
            // Initialize interactive charts
            initializeCharts();
            
            // Setup event listeners
            setupEventListeners();
            
            // Initialize real-time features
            initializeRealTimeFeatures();
            
            console.log('‚úÖ Dashboard initialization complete');
        }
        
        // Initialize DataTables with advanced features
        function initializeDataTables() {
            // Vulnerabilities table
            $('#vulnerabilitiesTable').DataTable({
                responsive: true,
                pageLength: 25,
                order: [[4, 'desc']], // Sort by CVSS score
                dom: 'Bfrtip',
                buttons: [
                    'copy', 'csv', 'excel', 'pdf', 'print'
                ],
                columnDefs: [
                    { type: 'num', targets: [4] }, // CVSS score column
                    { orderable: false, targets: [8] } // Actions column
                ],
                language: {
                    search: "_INPUT_",
                    searchPlaceholder: "Search vulnerabilities..."
                }
            });
        }
        
        // Initialize Interactive Charts
        function initializeCharts() {
            createRiskDistributionChart();
            createVulnerabilityTrendChart();
            createNetworkTopology();
            createComplianceRadar();
        }
        
        // Risk Distribution Chart (Interactive Pie/Doughnut)
        function createRiskDistributionChart() {
            const ctx = document.getElementById('riskChart');
            if (!ctx) return;
            
            const data = {
                labels: ['Critical', 'High', 'Medium', 'Low', 'Info'],
                datasets: [{
                    data: calculateRiskDistribution(),
                    backgroundColor: [
                        '#dc3545', '#fd7e14', '#ffc107', '#28a745', '#6c757d'
                    ],
                    borderWidth: 2,
                    borderColor: '#fff',
                    hoverBorderWidth: 4
                }]
            };
            
            window.riskChart = new Chart(ctx, {
                type: 'doughnut',
                data: data,
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {
                        legend: {
                            position: 'bottom',
                            labels: {
                                padding: 20,
                                usePointStyle: true
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    const label = context.label;
                                    const value = context.parsed;
                                    const total = context.dataset.data.reduce((a, b) => a + b, 0);
                                    const percentage = ((value / total) * 100).toFixed(1);
                                    return `${label}: ${value} (${percentage}%)`;
                                }
                            }
                        }
                    },
                    onClick: function(event, elements) {
                        if (elements.length > 0) {
                            const index = elements[0].index;
                            const severity = data.labels[index];
                            drillDownBySeverity(severity);
                        }
                    },
                    animation: {
                        animateScale: true,
                        animateRotate: true
                    }
                }
            });
        }
        
        // Interactive Network Topology with D3.js
        function createNetworkTopology() {
            const container = d3.select('#networkTopology');
            container.selectAll('*').remove(); // Clear existing
            
            const width = 600;
            const height = 400;
            
            const svg = container.append('svg')
                .attr('width', '100%')
                .attr('height', height)
                .attr('viewBox', `0 0 ${width} ${height}`);
                
            // Create force simulation
            const simulation = d3.forceSimulation()
                .force('link', d3.forceLink().id(d => d.id))
                .force('charge', d3.forceManyBody().strength(-300))
                .force('center', d3.forceCenter(width / 2, height / 2));
                
            // Process network data
            const networkData = processNetworkData();
            
            // Create links
            const link = svg.append('g')
                .selectAll('line')
                .data(networkData.links)
                .enter().append('line')
                .attr('stroke', '#999')
                .attr('stroke-opacity', 0.6)
                .attr('stroke-width', d => Math.sqrt(d.value));
                
            // Create nodes
            const node = svg.append('g')
                .selectAll('circle')
                .data(networkData.nodes)
                .enter().append('circle')
                .attr('r', d => d.type === 'host' ? 20 : 10)
                .attr('fill', d => getNodeColor(d))
                .call(d3.drag()
                    .on('start', dragstarted)
                    .on('drag', dragged)
                    .on('end', dragended));
                    
            // Add labels
            const label = svg.append('g')
                .selectAll('text')
                .data(networkData.nodes)
                .enter().append('text')
                .text(d => d.label)
                .attr('font-size', '12px')
                .attr('dx', 15)
                .attr('dy', 4);
                
            // Add tooltips
            node.append('title')
                .text(d => `${d.label}\\nType: ${d.type}\\nRisk: ${d.risk || 'Unknown'}`);
                
            // Update positions
            simulation.nodes(networkData.nodes)
                .on('tick', ticked);
                
            simulation.force('link')
                .links(networkData.links);
                
            function ticked() {
                link
                    .attr('x1', d => d.source.x)
                    .attr('y1', d => d.source.y)
                    .attr('x2', d => d.target.x)
                    .attr('y2', d => d.target.y);
                    
                node
                    .attr('cx', d => d.x)
                    .attr('cy', d => d.y);
                    
                label
                    .attr('x', d => d.x)
                    .attr('y', d => d.y);
            }
            
            // Drag functions
            function dragstarted(event, d) {
                if (!event.active) simulation.alphaTarget(0.3).restart();
                d.fx = d.x;
                d.fy = d.y;
            }
            
            function dragged(event, d) {
                d.fx = event.x;
                d.fy = event.y;
            }
            
            function dragended(event, d) {
                if (!event.active) simulation.alphaTarget(0);
                d.fx = null;
                d.fy = null;
            }
        }
        
        // Compliance Radar Chart
        function createComplianceRadar() {
            const container = document.getElementById('complianceRadar');
            if (!container) return;
            
            const options = {
                series: [{
                    name: 'Compliance Score',
                    data: getComplianceScores()
                }],
                chart: {
                    height: 350,
                    type: 'radar'
                },
                colors: ['#667eea'],
                xaxis: {
                    categories: ['OWASP', 'NIST', 'PCI DSS', 'ISO 27001']
                }
            };
            
            window.complianceChart = new ApexCharts(container, options);
            window.complianceChart.render();
        }
        
        // Vulnerability Trend Chart
        function createVulnerabilityTrendChart() {
            const ctx = document.getElementById('vulnTrendChart');
            if (!ctx) return;
            
            const data = {
                labels: generateDateLabels(),
                datasets: [{
                    label: 'Critical',
                    data: generateTrendData('critical'),
                    borderColor: '#dc3545',
                    fill: false
                }, {
                    label: 'High',
                    data: generateTrendData('high'),
                    borderColor: '#fd7e14',
                    fill: false
                }]
            };
            
            window.vulnTrendChart = new Chart(ctx, {
                type: 'line',
                data: data,
                options: {
                    responsive: true,
                    maintainAspectRatio: false
                }
            });
        }
        
        // Event Listeners Setup
        function setupEventListeners() {
            // Keyboard shortcuts
            document.addEventListener('keydown', function(e) {
                if (e.ctrlKey || e.metaKey) {
                    switch(e.key) {
                        case 'f':
                            e.preventDefault();
                            toggleFullscreen();
                            break;
                        case 'r':
                            e.preventDefault();
                            refreshData();
                            break;
                    }
                }
            });
        }
        
        // Real-time Features
        function initializeRealTimeFeatures() {
            setInterval(updateLastRefreshTime, 30000);
        }
        
        // Utility Functions
        function switchView(viewName) {
            document.querySelectorAll('.dashboard-section').forEach(section => {
                section.style.display = 'none';
            });
            
            const targetSection = document.getElementById(viewName + 'View');
            if (targetSection) {
                targetSection.style.display = 'block';
            }
            
            updateStatusMessage(`Switched to ${viewName} view`);
        }
        
        function toggleFullscreen() {
            if (!document.fullscreenElement) {
                document.documentElement.requestFullscreen();
            } else {
                document.exitFullscreen();
            }
        }
        
        function exportDashboard() {
            const exportData = {
                timestamp: new Date().toISOString(),
                target: dashboardData.target,
                vulnerabilities: dashboardData.vulnerabilities
            };
            
            const blob = new Blob([JSON.stringify(exportData, null, 2)], {type: 'application/json'});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `security-dashboard-${dashboardData.target}.json`;
            a.click();
            URL.revokeObjectURL(url);
        }
        
        function refreshData() {
            updateStatusMessage('Refreshing dashboard data...');
            setTimeout(() => {
                updateLastRefreshTime();
                updateStatusMessage('Dashboard refreshed successfully');
            }, 2000);
        }
        
        function applyFilters() {
            const severity = document.getElementById('severityFilter').value;
            const type = document.getElementById('typeFilter').value;
            const search = document.getElementById('searchFilter').value.toLowerCase();
            
            const table = $('#vulnerabilitiesTable').DataTable();
            table.search('').columns().search('').draw();
            
            if (severity !== 'all' || type !== 'all' || search) {
                updateStatusMessage(`Filters applied: ${severity} severity, ${type} type`);
            }
        }
        
        function drillDown(category) {
            switch(category) {
                case 'risk':
                case 'vulnerabilities':
                case 'network':
                case 'cvss':
                    switchView('technical');
                    break;
            }
        }
        
        function showVulnDetails(index) {
            const vuln = dashboardData.vulnerabilities[index];
            if (!vuln) return;
            
            const modalTitle = document.getElementById('detailModalTitle');
            const modalBody = document.getElementById('detailModalBody');
            
            modalTitle.textContent = `Vulnerability Details - ${vuln.type || 'Unknown'}`;
            modalBody.innerHTML = `
                <p><strong>Description:</strong> ${vuln.description || 'No description'}</p>
                <p><strong>Severity:</strong> ${vuln.severity || 'Unknown'}</p>
                <p><strong>CVSS Score:</strong> ${vuln.cvss_score || 'N/A'}</p>
            `;
            
            $('#detailModal').modal('show');
        }
        
        function markResolved(index) {
            updateStatusMessage(`Marking vulnerability ${index + 1} as resolved...`);
        }
        
        function updateStatusMessage(message) {
            const statusElement = document.getElementById('statusMessage');
            if (statusElement) {
                statusElement.textContent = message;
            }
        }
        
        function updateLastRefreshTime() {
            const lastUpdateElement = document.getElementById('lastUpdate');
            if (lastUpdateElement) {
                lastUpdateElement.textContent = new Date().toLocaleString();
            }
        }
        
        // Data processing utilities
        function calculateRiskDistribution() {
            const vulnerabilities = dashboardData.vulnerabilities || [];
            const distribution = {critical: 0, high: 0, medium: 0, low: 0, info: 0};
            
            vulnerabilities.forEach(vuln => {
                const severity = (vuln.severity || 'info').toLowerCase();
                if (distribution.hasOwnProperty(severity)) {
                    distribution[severity]++;
                }
            });
            
            return [distribution.critical, distribution.high, distribution.medium, distribution.low, distribution.info];
        }
        
        function generateDateLabels() {
            const labels = [];
            for (let i = 6; i >= 0; i--) {
                const date = new Date();
                date.setDate(date.getDate() - i);
                labels.push(date.toLocaleDateString());
            }
            return labels;
        }
        
        function generateTrendData(severity) {
            return Array.from({length: 7}, () => Math.floor(Math.random() * 5));
        }
        
        function processNetworkData() {
            const services = dashboardData.networkServices || [];
            const nodes = [];
            const links = [];
            
            const hosts = [...new Set(services.map(s => s.host))];
            hosts.forEach((host, index) => {
                nodes.push({
                    id: `host-${index}`,
                    label: host,
                    type: 'host',
                    risk: 'medium'
                });
            });
            
            services.forEach((service, index) => {
                const serviceId = `service-${index}`;
                const hostIndex = hosts.indexOf(service.host);
                
                nodes.push({
                    id: serviceId,
                    label: `${service.port}`,
                    type: 'service',
                    risk: service.risk || 'low'
                });
                
                links.push({
                    source: `host-${hostIndex}`,
                    target: serviceId,
                    value: 1
                });
            });
            
            return {nodes, links};
        }
        
        function getNodeColor(node) {
            const colors = {
                'critical': '#dc3545',
                'high': '#fd7e14',
                'medium': '#ffc107',
                'low': '#28a745',
                'host': '#6f42c1'
            };
            
            if (node.type === 'host') return colors.host;
            return colors[node.risk] || colors.low;
        }
        
        function getComplianceScores() {
            const frameworks = dashboardData.complianceStatus?.frameworks || {};
            return Object.values(frameworks).map(f => f.score || 0);
        }
        
        function toggleChartType(chartId, newType) {
            updateStatusMessage(`Switching ${chartId} to ${newType} view...`);
        }
        
        function downloadChart(chartId) {
            updateStatusMessage(`Downloading ${chartId}...`);
        }
        
        function toggleTopologyView(viewType) {
            updateStatusMessage(`Switching topology to ${viewType} view...`);
        }
        
        function zoomChart(target) {
            updateStatusMessage('Zooming charts...');
        }
        
        function resetCharts() {
            updateStatusMessage('Resetting charts...');
            initializeCharts();
        }
        
        function exportTable(tableId) {
            updateStatusMessage(`Exporting ${tableId}...`);
        }
        
        function toggleTableView() {
            updateStatusMessage('Toggling table view...');
        }
        
        function showComplianceDetails(framework) {
            updateStatusMessage(`Loading ${framework} compliance details...`);
        }
        
        function generateReport() {
            updateStatusMessage('Generating detailed report...');
        }
        """
        
    def _generate_dashboard_assets(self, dashboard_dir):
        """Generate additional dashboard assets like custom CSS and JS files"""
        try:
            # Create custom CSS file
            css_content = self._get_interactive_dashboard_css()
            with open(dashboard_dir / 'dashboard.css', 'w') as f:
                f.write(css_content)
                
            # Create custom JavaScript file
            js_content = self._generate_advanced_interactive_js()
            with open(dashboard_dir / 'dashboard.js', 'w') as f:
                f.write(js_content)
                
            self.logger.info("Dashboard assets generated successfully")
            
        except Exception as e:
            self.logger.error(f"Failed to generate dashboard assets: {str(e)}")
            
    def _generate_interactive_kpi_cards(self, vuln_stats, network_stats, risk_assessment):
        """Generate interactive KPI cards with animations and drill-down"""
        total_vulns = vuln_stats.get('total', 0)
        avg_cvss = sum(vuln_stats.get('cvss_scores', [0])) / max(len(vuln_stats.get('cvss_scores', [1])), 1)
        critical_vulns = len([v for v in vuln_stats.get('vulnerabilities', []) if v.get('severity') == 'Critical'])
        high_vulns = len([v for v in vuln_stats.get('vulnerabilities', []) if v.get('severity') == 'High'])
        
        risk_level = risk_assessment.get('risk_level', 'unknown').lower()
        risk_score = risk_assessment.get('total_score', 0)
        
        return f"""
        <div class="col-md-3">
            <div class="kpi-card {risk_level}" onclick="drillDown('risk')" style="cursor: pointer;">
                <div class="d-flex justify-content-between align-items-center">
                    <div>
                        <div class="metric-value pulse">{risk_score:.1f}/100</div>
                        <div class="metric-label">Risk Score</div>
                        <small>Level: {risk_assessment.get('risk_level', 'Unknown')}</small>
                    </div>
                    <div>
                        <i class="fas fa-exclamation-triangle fa-3x" style="opacity: 0.3;"></i>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="col-md-3">
            <div class="kpi-card {'critical' if critical_vulns > 0 else 'high' if high_vulns > 0 else 'low'}" onclick="drillDown('vulnerabilities')" style="cursor: pointer;">
                <div class="d-flex justify-content-between align-items-center">
                    <div>
                        <div class="metric-value">{total_vulns}</div>
                        <div class="metric-label">Vulnerabilities</div>
                        <small>Critical: {critical_vulns} | High: {high_vulns}</small>
                    </div>
                    <div>
                        <i class="fas fa-bug fa-3x" style="opacity: 0.3;"></i>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="col-md-3">
            <div class="kpi-card low" onclick="drillDown('network')" style="cursor: pointer;">
                <div class="d-flex justify-content-between align-items-center">
                    <div>
                        <div class="metric-value">{len(network_stats.get('services', []))}</div>
                        <div class="metric-label">Network Services</div>
                        <small>Open Ports Discovered</small>
                    </div>
                    <div>
                        <i class="fas fa-network-wired fa-3x" style="opacity: 0.3;"></i>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="col-md-3">
            <div class="kpi-card {'high' if avg_cvss >= 7 else 'medium' if avg_cvss >= 4 else 'low'}" onclick="drillDown('cvss')" style="cursor: pointer;">
                <div class="d-flex justify-content-between align-items-center">
                    <div>
                        <div class="metric-value">{avg_cvss:.1f}</div>
                        <div class="metric-label">Avg CVSS Score</div>
                        <small>Average Severity Rating</small>
                    </div>
                    <div>
                        <i class="fas fa-chart-line fa-3x" style="opacity: 0.3;"></i>
                    </div>
                </div>
            </div>
        </div>
        """
        
    def _generate_interactive_vulnerability_rows(self):
        """Generate interactive vulnerability table rows with actions"""
        vuln_stats = self._calculate_vulnerability_statistics()
        vulnerabilities = vuln_stats.get('vulnerabilities', [])
        
        if not vulnerabilities:
            return '<tr><td colspan="9" class="text-center text-muted">No vulnerabilities detected</td></tr>'
        
        rows = []
        for i, vuln in enumerate(vulnerabilities[:50]):  # Limit to 50 for performance
            severity = vuln.get('severity', 'Unknown')
            cvss_score = vuln.get('cvss_score', 0)
            cvss_vector = vuln.get('cvss_vector', 'N/A')
            cwe = vuln.get('cwe', 'N/A')
            confidence = vuln.get('confidence', 'Unknown')
            
            severity_badge = {
                'Critical': 'danger',
                'High': 'warning', 
                'Medium': 'info',
                'Low': 'success'
            }.get(severity, 'secondary')
            
            row = f"""
            <tr data-severity="{severity.lower()}" data-type="{vuln.get('type', 'unknown')}" data-cvss="{cvss_score}">
                <td><strong>VULN-{i+1:03d}</strong></td>
                <td>
                    <span class="badge bg-primary">{vuln.get('type', 'Unknown')}</span><br>
                    <small class="text-muted">{vuln.get('source', 'Unknown')}</small>
                </td>
                <td>
                    <span class="badge bg-{severity_badge}">{severity}</span>
                </td>
                <td>
                    <div class="text-truncate" style="max-width: 300px;" title="{vuln.get('description', 'No description')}">
                        {vuln.get('description', 'No description')[:100]}...
                    </div>
                </td>
                <td>
                    <strong class="text-{severity_badge}">{cvss_score:.1f}</strong>
                </td>
                <td>
                    <small><code>{cvss_vector}</code></small>
                </td>
                <td>
                    <span class="badge bg-info">{cwe}</span>
                </td>
                <td>
                    <span class="badge bg-secondary">{confidence}</span>
                </td>
                <td>
                    <button class="btn btn-sm btn-outline-primary btn-action" onclick="showVulnDetails({i})">
                        <i class="fas fa-eye"></i>
                    </button>
                    <button class="btn btn-sm btn-outline-success btn-action" onclick="markResolved({i})">
                        <i class="fas fa-check"></i>
                    </button>
                </td>
            </tr>
            """
            rows.append(row)
        
        return ''.join(rows)
        
    def _generate_interactive_services_rows(self):
        """Generate interactive network services table rows"""
        network_stats = self._calculate_network_statistics()
        services = network_stats.get('services', [])
        
        if not services:
            return '<tr><td colspan="6" class="text-center text-muted">No network services detected</td></tr>'
        
        rows = []
        for service in services:
            risk_level = service.get('risk', 'Unknown')
            risk_badge = {
                'Critical': 'danger',
                'High': 'warning',
                'Medium': 'info', 
                'Low': 'success'
            }.get(risk_level, 'secondary')
            
            row = f"""
            <tr>
                <td><strong>{service.get('host', 'Unknown')}</strong></td>
                <td><span class="badge bg-dark">{service.get('port', 'N/A')}</span></td>
                <td>{service.get('service', 'Unknown')}</td>
                <td><small class="text-muted">{service.get('version', 'N/A')}</small></td>
                <td><span class="badge bg-{risk_badge}">{risk_level}</span></td>
                <td>
                    <i class="fas fa-circle text-success" title="Active"></i>
                    <small class="text-muted ms-1">Active</small>
                </td>
            </tr>
            """
            rows.append(row)
        
        return ''.join(rows)
        
    def _generate_interactive_compliance_cards(self, compliance_status):
        """Generate interactive compliance framework cards"""
        if not isinstance(compliance_status, dict):
            compliance_status = {}
            
        frameworks = compliance_status.get('frameworks', {})
        
        cards = []
        for name, data in frameworks.items():
            score = data.get('score', 0)
            total_controls = data.get('total_controls', 1)
            passed_controls = data.get('passed_controls', 0)
            
            badge_class = 'success' if score >= 80 else 'warning' if score >= 60 else 'danger'
            
            card = f"""
            <div class="col-md-4 mb-4">
                <div class="card border-{badge_class} chart-card" onclick="showComplianceDetails('{name}')" style="cursor: pointer;">
                    <div class="card-header bg-{badge_class} text-white">
                        <h6 class="mb-0">
                            <i class="fas fa-shield-alt"></i> {name.upper()}
                            <span class="float-end">{score:.0f}%</span>
                        </h6>
                    </div>
                    <div class="card-body">
                        <div class="progress mb-3" style="height: 10px;">
                            <div class="progress-bar bg-{badge_class}" style="width: {score}%"></div>
                        </div>
                        <div class="row text-center">
                            <div class="col-6">
                                <h5 class="text-{badge_class}">{passed_controls}</h5>
                                <small class="text-muted">Passed</small>
                            </div>
                            <div class="col-6">
                                <h5 class="text-danger">{total_controls - passed_controls}</h5>
                                <small class="text-muted">Failed</small>
                            </div>
                        </div>
                        <div class="mt-3">
                            <small class="text-muted">Click for detailed breakdown</small>
                        </div>
                    </div>
                </div>
            </div>
            """
            cards.append(card)
        
        return ''.join(cards)
        
        html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Executive Security Dashboard - {self.target}</title>
    
    <!-- External Libraries for Interactive Visualizations -->
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    
    <style>
        {self._get_enhanced_dashboard_css()}
    </style>
</head>
<body>
    <div class="dashboard-container">
        <!-- Header Section -->
        <header class="dashboard-header bg-dark text-white py-3">
            <div class="container-fluid">
                <div class="row align-items-center">
                    <div class="col-md-8">
                        <h1><i class="fas fa-shield-alt"></i> Executive Security Assessment Dashboard</h1>
                        <p class="mb-0">Target: <strong>{self.target}</strong> | Assessment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                    </div>
                    <div class="col-md-4 text-end">
                        <div class="risk-indicator risk-{risk_assessment.get('risk_level', 'unknown').lower()}">
                            <div class="risk-score">{risk_assessment.get('total_score', 0)}/100</div>
                            <div class="risk-label">{risk_assessment.get('risk_level', 'UNKNOWN').upper()} RISK</div>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        
        <!-- Executive Summary Cards -->
        <section class="executive-summary py-4">
            <div class="container-fluid">
                <h2>Executive Summary</h2>
                <div class="row">
                    {self._generate_enhanced_summary_cards(vuln_stats, network_stats, risk_assessment)}
                </div>
            </div>
        </section>
        
        <!-- Interactive Visualizations -->
        <section class="visualizations py-4">
            <div class="container-fluid">
                <h2>Security Analysis Visualizations</h2>
                <div class="row">
                    <div class="col-lg-6 mb-4">
                        <div class="card">
                            <div class="card-header">
                                <h5><i class="fas fa-chart-pie"></i> Risk Component Breakdown</h5>
                            </div>
                            <div class="card-body">
                                <div id="riskBreakdownChart" style="height: 400px;"></div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-6 mb-4">
                        <div class="card">
                            <div class="card-header">
                                <h5><i class="fas fa-chart-bar"></i> Vulnerability Severity Distribution</h5>
                            </div>
                            <div class="card-body">
                                <div id="vulnerabilityChart" style="height: 400px;"></div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <div class="col-lg-6 mb-4">
                        <div class="card">
                            <div class="card-header">
                                <h5><i class="fas fa-network-wired"></i> Network Topology Map</h5>
                            </div>
                            <div class="card-body">
                                <div id="networkTopology" style="height: 400px;"></div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-6 mb-4">
                        <div class="card">
                            <div class="card-header">
                                <h5><i class="fas fa-clipboard-check"></i> Compliance Framework Status</h5>
                            </div>
                            <div class="card-body">
                                <div id="complianceChart" style="height: 400px;"></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Detailed Findings Table -->
        <section class="findings py-4">
            <div class="container-fluid">
                <h2>Detailed Scan Results & Analysis</h2>
                
                <!-- Network Analysis Section -->
                <div class="card mb-4">
                    <div class="card-body">
                        {self._generate_findings_table(vuln_stats)}
                    </div>
                </div>
                
                <!-- Subdomain Analysis Section -->
                <div class="card mb-4">
                    <div class="card-header bg-info text-white">
                        <h5><i class="fas fa-sitemap"></i> Subdomain Enumeration Results</h5>
                    </div>
                    <div class="card-body">
                        {self._generate_subdomain_details()}
                    </div>
                </div>
                
                <!-- SSL/TLS Analysis Section -->
                <div class="card mb-4">
                    <div class="card-header bg-warning text-white">
                        <h5><i class="fas fa-lock"></i> SSL/TLS Security Analysis</h5>
                    </div>
                    <div class="card-body">
                        {self._generate_ssl_analysis_details()}
                    </div>
                </div>
                
                <!-- OSINT Analysis Section -->
                <div class="card mb-4">
                    <div class="card-header bg-primary text-white">
                        <h5><i class="fas fa-search"></i> OSINT Collection Results</h5>
                    </div>
                    <div class="card-body">
                        {self._generate_osint_details()}
                    </div>
                </div>
                
                <!-- Web Application Analysis Section -->
                <div class="card mb-4">
                    <div class="card-header bg-success text-white">
                        <h5><i class="fas fa-globe"></i> Web Application Security Analysis</h5>
                    </div>
                    <div class="card-body">
                        {self._generate_web_analysis_details()}
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Compliance Dashboard -->
        <section class="compliance py-4">
            <div class="container-fluid">
                <h2>Compliance Framework Analysis</h2>
                <div class="row">
                    {self._generate_compliance_cards(compliance_status)}
                </div>
            </div>
        </section>
    </div>
    
    <!-- JavaScript for Interactive Charts -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {{
            {self._generate_interactive_charts_js(risk_assessment, vuln_stats, compliance_status)}
        }});
    </script>
</body>
</html>
        """
        
        # Substitute template variables with actual values
        template_vars = {
            'target': self.target,
            'scan_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'risk_score': int(risk_assessment.get('total_score', 0)),
            'risk_level': risk_assessment.get('risk_level', 'unknown').lower(),
            'total_vulnerabilities': vuln_stats.get('total', 0),
            'critical_vulns': vuln_stats.get('critical', 0),
            'high_vulns': vuln_stats.get('high', 0),
            'medium_vulns': vuln_stats.get('medium', 0),
            'low_vulns': vuln_stats.get('low', 0),
            'open_ports': network_stats.get('total_ports', 0),
            'subdomains_count': len(self.results.get('subdomains', {}).get('subdomains', [])),
            'cvss_average': self.results.get('summary', {}).get('overall_risk_score', 0)
        }
        
        # Replace template placeholders
        for key, value in template_vars.items():
            html_content = html_content.replace(f'{{{ key }}}', str(value))
            html_content = html_content.replace(f'{{{{ {key} }}}}', str(value))
            html_content = html_content.replace(f'{{{{ {key}|title }}}}', str(value).title())
        
        return html_content
        
    def _generate_enhanced_risk_json(self, risk_assessment):
        """Generate enhanced risk assessment with CVSS scores"""
        try:
            # Enhanced risk assessment with detailed vulnerability analysis
            enhanced_risk = {
                'target': self.target,
                'assessment_timestamp': datetime.now().isoformat(),
                'risk_summary': risk_assessment,
                'cvss_analysis': self._generate_cvss_analysis(),
                'vulnerability_details': self._extract_detailed_vulnerabilities(),
                'network_exposure': self._analyze_network_exposure(),
                'compliance_gaps': self._identify_compliance_gaps(),
                'remediation_priorities': self._generate_remediation_priorities(),
                'historical_comparison': self._get_historical_risk_trends()
            }
            
            risk_file = self.output_dir / 'enhanced_risk_assessment.json'
            with open(risk_file, 'w') as f:
                json.dump(enhanced_risk, f, indent=2)
                
            self.logger.info(f"Enhanced risk assessment saved to {risk_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"Enhanced risk assessment generation failed: {str(e)}")
            return False
            
    def _generate_enhanced_compliance_report(self, compliance_status):
        """Generate comprehensive compliance framework report"""
        try:
            compliance_report = {
                'target': self.target,
                'assessment_date': datetime.now().isoformat(),
                'frameworks_assessed': list(compliance_status.keys()),
                'compliance_summary': self._generate_compliance_summary(compliance_status),
                'detailed_analysis': compliance_status,
                'gap_analysis': self._perform_gap_analysis(compliance_status),
                'remediation_roadmap': self._create_compliance_roadmap(compliance_status),
                'certification_readiness': self._assess_certification_readiness(compliance_status)
            }
            
            compliance_file = self.output_dir / 'comprehensive_compliance_report.json'
            with open(compliance_file, 'w') as f:
                json.dump(compliance_report, f, indent=2)
                
            self.logger.info(f"Comprehensive compliance report saved to {compliance_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"Enhanced compliance report generation failed: {str(e)}")
            return False
            
    def _generate_multiformat_exports(self):
        """Generate exports in multiple formats (Excel, Word, PowerPoint, CSV)"""
        exported_formats = []
        
        try:
            # Enhanced CSV exports
            csv_exporter = self.exporters['csv']
            if csv_exporter:
                vuln_csv = csv_exporter.export_vulnerabilities(self.results, self.output_dir)
                network_csv = csv_exporter.export_network_data(self.results, self.output_dir)
                if vuln_csv and network_csv:
                    exported_formats.append('Enhanced CSV Exports')
                    
            # Excel workbook export
            excel_exporter = self.exporters['excel']
            if excel_exporter and excel_exporter.available:
                excel_file = excel_exporter.export(self.results, self.output_dir)
                if excel_file:
                    exported_formats.append('Executive Excel Workbook')
                    
            # Word document export
            word_exporter = self.exporters['word']
            if word_exporter and word_exporter.available:
                word_file = word_exporter.export(self.results, self.output_dir)
                if word_file:
                    exported_formats.append('Technical Word Report')
                    
            # PowerPoint presentation export
            pptx_exporter = self.exporters['powerpoint']
            if pptx_exporter and pptx_exporter.available:
                pptx_file = pptx_exporter.export(self.results, self.output_dir)
                if pptx_file:
                    exported_formats.append('Executive PowerPoint Presentation')
                    
        except Exception as e:
            self.logger.error(f"Multi-format export failed: {str(e)}")
            
        return exported_formats
        
    def _collect_and_organize_evidence(self):
        """Collect and organize evidence (screenshots, certificates, logs)"""
        try:
            evidence_collected = self.evidence_collector.collect_evidence(self.results, self.output_dir)
            
            if evidence_collected:
                # Create evidence index
                evidence_index = {
                    'target': self.target,
                    'collection_timestamp': datetime.now().isoformat(),
                    'evidence_files': evidence_collected,
                    'evidence_summary': {
                        'ssl_certificates': len([e for e in evidence_collected if 'certificate' in e]),
                        'http_samples': len([e for e in evidence_collected if 'http' in e]),
                        'log_files': len([e for e in evidence_collected if 'log' in e])
                    }
                }
                
                evidence_file = self.output_dir / 'evidence' / 'evidence_index.json'
                with open(evidence_file, 'w') as f:
                    json.dump(evidence_index, f, indent=2)
                    
                self.logger.info(f"Evidence collection completed: {len(evidence_collected)} items")
                return True
                
        except Exception as e:
            self.logger.error(f"Evidence collection failed: {str(e)}")
            
        return False
        
    def _update_security_baseline(self):
        """Update security baseline for historical tracking"""
        try:
            baseline_updated = self.baseline_tracker.update_baseline(self.results, self.target)
            
            if baseline_updated:
                # Generate trend analysis
                historical_data = self.baseline_tracker.get_historical_comparison(self.target)
                
                trend_analysis = {
                    'target': self.target,
                    'baseline_updated': datetime.now().isoformat(),
                    'historical_scans': len(historical_data),
                    'trend_analysis': self._analyze_security_trends(historical_data)
                }
                
                trend_file = self.output_dir / 'security_trends.json'
                with open(trend_file, 'w') as f:
                    json.dump(trend_analysis, f, indent=2)
                    
                self.logger.info("Security baseline updated with trend analysis")
                return True
                
        except Exception as e:
            self.logger.error(f"Baseline tracking failed: {str(e)}")
            
        return False
        
    # Helper methods for enhanced functionality
    def _calculate_vulnerability_statistics(self):
        """Calculate comprehensive vulnerability statistics"""
        stats = {
            'total': 0,
            'critical': 0,
            'high': 0,
            'medium': 0,
            'low': 0,
            'by_type': {},
            'cvss_scores': []
        }
        
        # Check if we have summary data directly available
        if 'summary' in self.results:
            summary = self.results['summary']
            stats['total'] = summary.get('total_vulnerabilities', 0)
            stats['critical'] = summary.get('critical_findings', 0)
            stats['high'] = summary.get('high_findings', 0)
            stats['medium'] = summary.get('medium_findings', 0)
            stats['low'] = summary.get('low_findings', 0)
            
            # Calculate CVSS scores based on severity counts for summary data
            # Use proper CVSS calculator for more accurate scoring
            for _ in range(stats['critical']):
                dummy_vuln = {'severity': 'critical', 'type': 'Critical Security Issue'}
                stats['cvss_scores'].append(self.cvss_calculator.calculate_cvss(dummy_vuln))
            for _ in range(stats['high']):
                dummy_vuln = {'severity': 'high', 'type': 'High Security Issue'}
                stats['cvss_scores'].append(self.cvss_calculator.calculate_cvss(dummy_vuln))
            for _ in range(stats['medium']):
                dummy_vuln = {'severity': 'medium', 'type': 'Medium Security Issue'}
                stats['cvss_scores'].append(self.cvss_calculator.calculate_cvss(dummy_vuln))
            for _ in range(stats['low']):
                dummy_vuln = {'severity': 'low', 'type': 'Low Security Issue'}
                stats['cvss_scores'].append(self.cvss_calculator.calculate_cvss(dummy_vuln))
                
            return stats
            
        # Process web vulnerabilities (new structure)
        if 'web_analysis' in self.results and 'applications' in self.results['web_analysis']:
            for app in self.results['web_analysis']['applications']:
                for vuln in app.get('vulnerabilities', []):
                    severity = vuln.get('severity', 'low').lower()
                    stats['total'] += 1
                    stats[severity] = stats.get(severity, 0) + 1
                    
                    vuln_type = vuln.get('type', 'unknown')
                    stats['by_type'][vuln_type] = stats['by_type'].get(vuln_type, 0) + 1
                    
                    # Calculate proper CVSS v3.1 score
                    cvss_score = self.cvss_calculator.calculate_cvss(vuln)
                    stats['cvss_scores'].append(cvss_score)
        
        # Process legacy web scan format
        elif 'web_scan' in self.results and 'vulnerabilities' in self.results['web_scan']:
            for vuln in self.results['web_scan']['vulnerabilities']:
                severity = vuln.get('severity', 'low').lower()
                stats['total'] += 1
                stats[severity] = stats.get(severity, 0) + 1
                
                vuln_type = vuln.get('type', 'unknown')
                stats['by_type'][vuln_type] = stats['by_type'].get(vuln_type, 0) + 1
                
                cvss_score = self.cvss_calculator.calculate_cvss(vuln)
                stats['cvss_scores'].append(cvss_score)
                
        # Process SSL/TLS vulnerabilities (new structure)
        if 'ssl_scan' in self.results and 'certificates' in self.results['ssl_scan']:
            for cert_data in self.results['ssl_scan']['certificates']:
                ssl_analysis = cert_data.get('ssl_analysis', {})
                for vuln in ssl_analysis.get('vulnerabilities', []):
                    stats['total'] += 1
                    stats['medium'] = stats.get('medium', 0) + 1  # SSL issues typically medium
                    
                    vuln_type = f"SSL: {vuln}"
                    stats['by_type'][vuln_type] = stats['by_type'].get(vuln_type, 0) + 1
                
        # Process legacy SSL/TLS vulnerabilities
        elif 'security_analysis' in self.results:
            ssl_analysis = self.results['security_analysis'].get('ssl_analysis', {})
            for port_data in ssl_analysis.values():
                for vuln in port_data.get('vulnerabilities', []):
                    severity = vuln.get('severity', 'low').lower()
                    stats['total'] += 1
                    stats[severity] = stats.get(severity, 0) + 1
                    
                    vuln_type = vuln.get('type', 'unknown')
                    stats['by_type'][vuln_type] = stats['by_type'].get(vuln_type, 0) + 1
                    
                    cvss_score = self.cvss_calculator.calculate_cvss(vuln)
                    stats['cvss_scores'].append(cvss_score)
                    
        return stats
        
    def _calculate_network_statistics(self):
        """Calculate network exposure statistics"""
        stats = {
            'total_hosts': 0,
            'total_ports': 0,
            'open_ports': 0,
            'services': {},
            'dangerous_ports': 0,
            'encryption_status': {}
        }
        
        # Check new data structure first
        if 'network_scan' in self.results and 'hosts_discovered' in self.results['network_scan']:
            hosts = self.results['network_scan']['hosts_discovered']
            stats['total_hosts'] = len(hosts)
            
            dangerous_ports = [21, 22, 23, 25, 53, 135, 139, 445, 1433, 3306, 3389, 5432]
            
            for host in hosts:
                for port_info in host.get('ports', []):
                    if port_info.get('state') == 'open':
                        stats['total_ports'] += 1
                        stats['open_ports'] += 1
                        
                        port_num = int(port_info.get('port', 0))
                        if port_num in dangerous_ports:
                            stats['dangerous_ports'] += 1
                            
                        service = port_info.get('service', 'unknown')
                        stats['services'][service] = stats['services'].get(service, 0) + 1
        
        # Fallback to legacy structure
        elif 'nmap' in self.results and 'hosts' in self.results['nmap']:
            stats['total_hosts'] = len(self.results['nmap']['hosts'])
            
            dangerous_ports = [21, 22, 23, 25, 53, 135, 139, 445, 1433, 3306, 3389, 5432]
            
            for host in self.results['nmap']['hosts']:
                for port_info in host.get('ports', []):
                    if port_info.get('state') == 'open':
                        stats['total_ports'] += 1
                        stats['open_ports'] += 1
                        
                        port_num = int(port_info.get('port', 0))
                        if port_num in dangerous_ports:
                            stats['dangerous_ports'] += 1
                            
                        service = port_info.get('service', {}).get('name', 'unknown')
                        stats['services'][service] = stats['services'].get(service, 0) + 1
                        
        return stats
        
    def _generate_enhanced_summary_cards(self, vuln_stats, network_stats, risk_assessment):
        """Generate enhanced summary cards HTML"""
        cards_html = f"""
        <div class="col-md-3">
            <div class="card summary-card border-danger">
                <div class="card-body text-center">
                    <h5 class="card-title text-danger"><i class="fas fa-exclamation-triangle"></i> Risk Score</h5>
                    <div class="metric-value text-danger">{risk_assessment.get('total_score', 0)}/100</div>
                    <p class="card-text">Risk Level: <span class="badge bg-{self._get_risk_color(risk_assessment.get('risk_level', 'unknown'))}">{risk_assessment.get('risk_level', 'UNKNOWN')}</span></p>
                </div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card summary-card border-warning">
                <div class="card-body text-center">
                    <h5 class="card-title text-warning"><i class="fas fa-bug"></i> Vulnerabilities</h5>
                    <div class="metric-value text-warning">{vuln_stats['total']}</div>
                    <p class="card-text">Critical: {vuln_stats.get('critical', 0)} | High: {vuln_stats.get('high', 0)}</p>
                </div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card summary-card border-info">
                <div class="card-body text-center">
                    <h5 class="card-title text-info"><i class="fas fa-network-wired"></i> Network Exposure</h5>
                    <div class="metric-value text-info">{network_stats['open_ports']}</div>
                    <p class="card-text">Open Ports | {network_stats['dangerous_ports']} Dangerous</p>
                </div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card summary-card border-success">
                <div class="card-body text-center">
                    <h5 class="card-title text-success"><i class="fas fa-chart-line"></i> CVSS Average</h5>
                    <div class="metric-value text-success">{self._calculate_avg_cvss(vuln_stats):.1f}</div>
                    <p class="card-text">Average CVSS Score</p>
                </div>
            </div>
        </div>
        """
        return cards_html
        
    def _generate_interactive_charts_js(self, risk_assessment, vuln_stats, compliance_status):
        """Generate JavaScript for interactive charts"""
        return f"""
        // Risk Component Breakdown Pie Chart
        var riskData = [{{
            values: [{risk_assessment.get('component_scores', {}).get('vulnerabilities', 0)}, 
                    {risk_assessment.get('component_scores', {}).get('ssl_tls', 0)}, 
                    {risk_assessment.get('component_scores', {}).get('network_exposure', 0)}, 
                    {risk_assessment.get('component_scores', {}).get('security_config', 0)}],
            labels: ['Vulnerabilities', 'SSL/TLS Security', 'Network Exposure', 'Security Configuration'],
            type: 'pie',
            marker: {{
                colors: ['#dc3545', '#fd7e14', '#ffc107', '#17a2b8']
            }},
            hovertemplate: '%{{label}}: %{{value}} points<br>%{{percent}}<extra></extra>'
        }}];
        
        var riskLayout = {{
            title: 'Risk Score Components',
            showlegend: true
        }};
        
        Plotly.newPlot('riskBreakdownChart', riskData, riskLayout);
        
        // Vulnerability Severity Bar Chart
        var vulnData = [{{
            x: ['Critical', 'High', 'Medium', 'Low'],
            y: [{vuln_stats.get('critical', 0)}, {vuln_stats.get('high', 0)}, {vuln_stats.get('medium', 0)}, {vuln_stats.get('low', 0)}],
            type: 'bar',
            marker: {{
                color: ['#dc3545', '#fd7e14', '#ffc107', '#28a745']
            }}
        }}];
        
        var vulnLayout = {{
            title: 'Vulnerability Severity Distribution',
            xaxis: {{ title: 'Severity Level' }},
            yaxis: {{ title: 'Count' }}
        }};
        
        Plotly.newPlot('vulnerabilityChart', vulnData, vulnLayout);
        
        // Network Topology (simple D3.js visualization)
        {self._generate_network_topology_js()}
        
        // Compliance Radar Chart
        {self._generate_compliance_radar_js(compliance_status)}
        """
        
    # Additional helper methods would be implemented here...
    def _get_enhanced_dashboard_css(self):
        """Get enhanced CSS for dashboard styling"""
        return """
        .dashboard-container { font-family: 'Arial', sans-serif; }
        .risk-indicator { 
            border: 3px solid; 
            border-radius: 10px; 
            padding: 15px; 
            text-align: center; 
        }
        .risk-critical { border-color: #dc3545; color: #dc3545; }
        .risk-high { border-color: #fd7e14; color: #fd7e14; }
        .risk-medium { border-color: #ffc107; color: #ffc107; }
        .risk-low { border-color: #20c997; color: #20c997; }
        .risk-minimal { border-color: #28a745; color: #28a745; }
        .risk-score { font-size: 2.5rem; font-weight: bold; }
        .risk-label { font-size: 0.9rem; font-weight: bold; }
        .summary-card { margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .metric-value { font-size: 2.5rem; font-weight: bold; }
        """
        
    def _get_risk_color(self, risk_level):
        """Get Bootstrap color class for risk level"""
        color_map = {
            'critical': 'danger',
            'high': 'warning',
            'medium': 'info',
            'low': 'success',
            'minimal': 'success'
        }
        return color_map.get(risk_level.lower(), 'secondary')
        
    def _calculate_avg_cvss(self, vuln_stats):
        """Calculate average CVSS score"""
        cvss_scores = vuln_stats.get('cvss_scores', [])
        if cvss_scores:
            return sum(cvss_scores) / len(cvss_scores)
        return 0.0
        
    # Placeholder methods for complex functionality
    def _generate_cvss_analysis(self):
        """Generate detailed CVSS analysis"""
        return {'placeholder': 'CVSS analysis would be implemented here'}
        
    def _extract_detailed_vulnerabilities(self):
        """Extract detailed vulnerability information"""
        return {'placeholder': 'Detailed vulnerability extraction would be implemented here'}
        
    def _analyze_network_exposure(self):
        """Analyze network exposure details"""
        return {'placeholder': 'Network exposure analysis would be implemented here'}
        
    def _identify_compliance_gaps(self):
        """Identify compliance gaps"""
        return {'placeholder': 'Compliance gap analysis would be implemented here'}
        
    def _generate_remediation_priorities(self):
        """Generate remediation priorities"""
        return {'placeholder': 'Remediation prioritization would be implemented here'}
        
    def _get_historical_risk_trends(self):
        """Get historical risk trends"""
        return {'placeholder': 'Historical trend analysis would be implemented here'}
        
    def _generate_compliance_summary(self, compliance_status):
        """Generate compliance summary"""
        return {'placeholder': 'Compliance summary would be implemented here'}
        
    def _perform_gap_analysis(self, compliance_status):
        """Perform gap analysis"""
        return {'placeholder': 'Gap analysis would be implemented here'}
        
    def _create_compliance_roadmap(self, compliance_status):
        """Create compliance roadmap"""
        return {'placeholder': 'Compliance roadmap would be implemented here'}
        
    def _assess_certification_readiness(self, compliance_status):
        """Assess certification readiness"""
        return {'placeholder': 'Certification readiness assessment would be implemented here'}
        
    def _analyze_security_trends(self, historical_data):
        """Analyze security trends"""
        return {'placeholder': 'Security trend analysis would be implemented here'}
        
    def _generate_findings_table(self, vuln_stats):
        """Generate detailed findings table HTML with port information"""
        
        # Get network data from results
        network_data = self._extract_network_details()
        vulnerabilities = self._extract_vulnerability_details_for_table()
        
        findings_html = f"""
        <div class="row">
            <div class="col-lg-6">
                <div class="card">
                    <div class="card-header bg-danger text-white">
                        <h5><i class="fas fa-network-wired"></i> Open Ports Analysis</h5>
                    </div>
                    <div class="card-body">
                        <div class="table-responsive">
                            <table class="table table-striped table-hover">
                                <thead class="table-dark">
                                    <tr>
                                        <th>Port</th>
                                        <th>Protocol</th>
                                        <th>Service</th>
                                        <th>Version</th>
                                        <th>Risk Level</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    {self._generate_port_rows(network_data)}
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-lg-6">
                <div class="card">
                    <div class="card-header bg-warning text-white">
                        <h5><i class="fas fa-exclamation-triangle"></i> Security Vulnerabilities</h5>
                    </div>
                    <div class="card-body">
                        <div class="table-responsive">
                            <table class="table table-striped table-hover">
                                <thead class="table-dark">
                                    <tr>
                                        <th>Type</th>
                                        <th>Severity</th>
                                        <th>Description</th>
                                        <th>CVSS</th>
                                        <th>Vector</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    {self._generate_vulnerability_rows(vulnerabilities)}
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="row mt-4">
            <div class="col-12">
                <div class="card">
                    <div class="card-header bg-info text-white">
                        <h5><i class="fas fa-shield-alt"></i> Risk Analysis & Recommendations</h5>
                    </div>
                    <div class="card-body">
                        {self._generate_risk_recommendations(network_data, vulnerabilities)}
                    </div>
                </div>
            </div>
        </div>
        """
        
        return findings_html
        
    def _extract_network_details(self):
        """Extract detailed network information from scan results"""
        network_details = []
        
        # Access network scan data directly (new structure)
        network_data = self.results.get('network_scan', {})
        hosts = network_data.get('hosts_discovered', [])
        
        if hosts:
            for host in hosts:
                hostname = host.get('hostname', host.get('ip', 'Unknown'))
                for port_info in host.get('ports', []):
                    if port_info.get('state') == 'open':
                        # Determine risk level
                        risk_level = self._assess_port_risk_detailed(port_info)
                        
                        # Determine risk color for display
                        risk_colors = {
                            'Critical': 'danger',
                            'High': 'warning', 
                            'Medium': 'info',
                            'Low': 'success'
                        }
                        
                        network_details.append({
                            'host': hostname,
                            'ip': host.get('ip', 'Unknown'),
                            'port': port_info.get('port', 'Unknown'),
                            'protocol': port_info.get('protocol', 'tcp'),
                            'service': port_info.get('service', 'unknown'),
                            'version': port_info.get('version', 'unknown'),
                            'product': port_info.get('service', 'unknown'),  # Use service as product fallback
                            'state': port_info.get('state', 'unknown'),
                            'risk_level': risk_level,
                            'risk_color': risk_colors.get(risk_level, 'secondary'),
                            'banner': port_info.get('scripts', {})
                        })
        else:
            # Fallback: Check for legacy nmap structure
            results_data = self.results
            if 'results' in self.results:
                results_data = self.results['results']
            
            if 'nmap' in results_data and 'hosts' in results_data['nmap']:
                for host in results_data['nmap']['hosts']:
                    for port_info in host.get('ports', []):
                        if port_info.get('state') == 'open':
                            service = port_info.get('service', {})
                            
                            # Determine risk level
                            risk_level = self._assess_port_risk_detailed(port_info)
                            
                            network_details.append({
                                'host': host.get('address', 'Unknown'),
                                'port': port_info.get('port', 'Unknown'),
                            'protocol': port_info.get('protocol', 'Unknown'),
                            'service': service.get('name', 'Unknown'),
                            'product': service.get('product', ''),
                            'version': service.get('version', ''),
                            'risk_level': risk_level,
                            'risk_color': self._get_risk_badge_color(risk_level)
                        })
                        
        return network_details
        
    def _assess_port_risk_detailed(self, port_info):
        """Assess detailed risk level for a port"""
        port = int(port_info.get('port', 0))
        
        # Handle both string and dict service formats
        service_field = port_info.get('service', '')
        if isinstance(service_field, dict):
            service = service_field.get('name', '').lower()
        else:
            service = str(service_field).lower()
        
        # Critical risk ports
        critical_ports = [21, 23, 135, 139, 445, 3389, 1433, 3306, 5432]
        # High risk ports  
        high_ports = [22, 25, 53, 80, 443, 993, 995, 8080, 8443]
        # Medium risk ports
        medium_ports = [110, 143, 993, 995, 5985, 5986]
        
        if port in critical_ports:
            return 'Critical'
        elif port in high_ports:
            return 'High'
        elif port in medium_ports:
            return 'Medium'
        elif service in ['ftp', 'telnet', 'rlogin', 'rsh']:
            return 'Critical'
        elif service in ['ssh', 'http', 'https', 'smtp']:
            return 'High'
        elif port < 1024:
            return 'Medium'
        else:
            return 'Low'
            
    def _get_risk_badge_color(self, risk_level):
        """Get Bootstrap badge color for risk level"""
        color_map = {
            'Critical': 'danger',
            'High': 'warning', 
            'Medium': 'info',
            'Low': 'success'
        }
        return color_map.get(risk_level, 'secondary')
        
    def _generate_port_rows(self, network_data):
        """Generate HTML table rows for ports"""
        if not network_data:
            return '<tr><td colspan="5" class="text-center text-muted">No open ports detected</td></tr>'
            
        rows = []
        for port_data in network_data:
            version_info = f"{port_data['product']} {port_data['version']}".strip()
            if not version_info:
                version_info = 'Unknown'
                
            rows.append(f"""
            <tr>
                <td><strong>{port_data['port']}</strong></td>
                <td>{port_data['protocol'].upper()}</td>
                <td>{port_data['service']}</td>
                <td>{version_info}</td>
                <td><span class="badge bg-{port_data['risk_color']}">{port_data['risk_level']}</span></td>
            </tr>
            """)
            
        return ''.join(rows)
        
    def _extract_vulnerability_details_for_table(self):
        """Extract vulnerability details for display"""
        vulnerabilities = []
        
        # Handle nested results structure (from JSON reports)
        results_data = self.results
        if 'results' in self.results:
            results_data = self.results['results']
        
        # Extract web vulnerabilities from new structure (web_analysis.applications[].vulnerabilities)
        web_analysis = results_data.get('web_analysis', {})
        applications = web_analysis.get('applications', [])
        
        for app in applications:
            app_vulns = app.get('vulnerabilities', [])
            for vuln in app_vulns:
                # Calculate proper CVSS v3.1 score
                cvss_score = self.cvss_calculator.calculate_cvss(vuln)
                cvss_vector = self.cvss_calculator.get_cvss_vector(vuln)
                
                vulnerabilities.append({
                    'type': vuln.get('type', vuln.get('name', 'Web Vulnerability')),
                    'severity': vuln.get('severity', 'Low'),
                    'description': vuln.get('description', f'Vulnerability found in {app.get("url", "web application")}'),
                    'cvss': cvss_score,
                    'cvss_vector': cvss_vector,
                    'source': f'Web Application ({app.get("url", "Unknown URL")})',
                    'cwe': vuln.get('cwe', 'N/A'),
                    'confidence': vuln.get('confidence', 'Medium')
                })
        
        # Extract web vulnerabilities from legacy structure (fallback)
        if 'web_scan' in results_data and 'vulnerabilities' in results_data['web_scan']:
            for vuln in results_data['web_scan']['vulnerabilities']:
                cvss_score = self.cvss_calculator.calculate_cvss(vuln)
                cvss_vector = self.cvss_calculator.get_cvss_vector(vuln)
                vulnerabilities.append({
                    'type': vuln.get('type', 'Unknown'),
                    'severity': vuln.get('severity', 'Low'),
                    'description': vuln.get('description', 'No description available'),
                    'cvss': cvss_score,
                    'cvss_vector': cvss_vector,
                    'source': 'Web Scan',
                    'cwe': vuln.get('cwe', 'N/A'),
                    'confidence': vuln.get('confidence', 'Medium')
                })
        
        # Extract SSL/TLS vulnerabilities from new structure
        ssl_scan = results_data.get('ssl_scan', {})
        for domain_key, domain_data in ssl_scan.items():
            if isinstance(domain_data, dict) and 'vulnerabilities' in domain_data:
                ssl_vulns = domain_data.get('vulnerabilities', [])
                for vuln in ssl_vulns:
                    # Calculate proper CVSS v3.1 score
                    cvss_score = self.cvss_calculator.calculate_cvss(vuln)
                    cvss_vector = self.cvss_calculator.get_cvss_vector(vuln)
                        
                    vulnerabilities.append({
                        'type': vuln.get('type', vuln.get('name', 'SSL/TLS Issue')),
                        'severity': vuln.get('severity', 'Medium'),
                        'description': vuln.get('description', f'SSL/TLS vulnerability on {domain_key}'),
                        'cvss': cvss_score,
                        'cvss_vector': cvss_vector,
                        'source': f'SSL Analysis ({domain_key})',
                        'cwe': vuln.get('cwe', 'CWE-295'),
                        'confidence': vuln.get('confidence', 'High')
                    })
                
        # Extract SSL/TLS vulnerabilities from legacy structure (fallback)
        if 'security_analysis' in results_data:
            ssl_analysis = results_data['security_analysis'].get('ssl_analysis', {})
            for port, port_data in ssl_analysis.items():
                for vuln in port_data.get('vulnerabilities', []):
                    cvss_score = self.cvss_calculator.calculate_cvss(vuln) if hasattr(self, 'cvss_calculator') else 0.0
                    vulnerabilities.append({
                        'type': vuln.get('type', 'SSL/TLS Issue'),
                        'severity': vuln.get('severity', 'Medium'),
                        'description': vuln.get('description', f'SSL/TLS vulnerability on port {port}'),
                        'cvss': cvss_score,
                        'source': f'SSL Analysis (Port {port})'
                    })
                    
        return vulnerabilities
        
    def _generate_vulnerability_rows(self, vulnerabilities):
        """Generate HTML table rows for vulnerabilities"""
        if not vulnerabilities:
            return '<tr><td colspan="5" class="text-center text-success">No vulnerabilities detected</td></tr>'
            
        rows = []
        for vuln in vulnerabilities:
            severity_color = self._get_risk_badge_color(vuln['severity'].title())
            cvss_display = f"{vuln['cvss']:.1f}" if vuln['cvss'] > 0 else 'N/A'
            cvss_vector = vuln.get('cvss_vector', 'N/A')
            
            # Truncate vector for display
            vector_display = cvss_vector
            if len(vector_display) > 25:
                vector_display = vector_display[:22] + '...'
            
            rows.append(f"""
            <tr>
                <td>
                    <strong>{vuln['type']}</strong><br>
                    <small class="text-muted">{vuln['source']}</small><br>
                    <small class="text-info">CWE: {vuln.get('cwe', 'N/A')}</small>
                </td>
                <td><span class="badge bg-{severity_color}">{vuln['severity']}</span></td>
                <td>{vuln['description'][:80]}{'...' if len(vuln['description']) > 80 else ''}</td>
                <td><strong>{cvss_display}</strong></td>
                <td><small class="text-monospace" title="{cvss_vector}">{vector_display}</small></td>
            </tr>
            """)
            
        return ''.join(rows)
        
    def _generate_risk_recommendations(self, network_data, vulnerabilities):
        """Generate risk analysis and recommendations"""
        critical_ports = [p for p in network_data if p['risk_level'] == 'Critical']
        high_risk_ports = [p for p in network_data if p['risk_level'] == 'High']
        critical_vulns = [v for v in vulnerabilities if v['severity'].lower() == 'critical']
        
        recommendations = []
        
        if critical_ports:
            port_list = ', '.join([str(p['port']) for p in critical_ports])
            recommendations.append(f"üî¥ <strong>CRITICAL:</strong> Secure or restrict access to critical ports: {port_list}")
            
        if high_risk_ports:
            port_list = ', '.join([str(p['port']) for p in high_risk_ports])
            recommendations.append(f"üü° <strong>HIGH:</strong> Review security for high-risk ports: {port_list}")
            
        if critical_vulns:
            recommendations.append(f"üö® <strong>URGENT:</strong> {len(critical_vulns)} critical vulnerabilities require immediate attention")
            
        # Add specific service recommendations
        services = [p['service'] for p in network_data]
        if 'ms-wbt-server' in services or any('3389' == str(p['port']) for p in network_data):
            recommendations.append("üîí <strong>RDP Security:</strong> Enable Network Level Authentication, use strong passwords, consider VPN access")
            
        if any(p['service'] in ['microsoft-ds', 'netbios-ssn'] for p in network_data):
            recommendations.append("üìÅ <strong>SMB Security:</strong> Disable SMBv1, review file shares, enable SMB encryption")
            
        if not recommendations:
            recommendations.append("‚úÖ <strong>Good:</strong> No critical security issues identified in this scan")
            
        return '<ul class="list-unstyled">' + ''.join([f'<li class="mb-2">{rec}</li>' for rec in recommendations]) + '</ul>'
        
    def _generate_compliance_cards(self, compliance_status):
        """Generate compliance framework cards HTML"""
        
        cards_html = ""
        
        for framework, data in compliance_status.items():
            framework_name = framework.replace('_', ' ').upper()
            
            # Calculate compliance score
            total_controls = 0
            passed_controls = 0
            
            if isinstance(data, dict):
                for control, control_data in data.items():
                    if isinstance(control_data, dict):
                        total_controls += 1
                        status = control_data.get('status', 'unknown')
                        if status in ['pass', 'partial']:
                            passed_controls += 1
                    elif isinstance(control_data, (int, float)):
                        # NIST framework uses scores
                        total_controls = 5  # NIST has 5 functions
                        passed_controls = sum(1 for score in data.values() if isinstance(score, dict) and score.get('score', 0) > 50)
                        break
                        
            compliance_percentage = (passed_controls / total_controls * 100) if total_controls > 0 else 0
            
            # Determine card color based on compliance
            if compliance_percentage >= 80:
                card_color = 'success'
                icon = 'fas fa-check-circle'
            elif compliance_percentage >= 60:
                card_color = 'warning'
                icon = 'fas fa-exclamation-triangle'
            else:
                card_color = 'danger'
                icon = 'fas fa-times-circle'
                
            cards_html += f"""
            <div class="col-md-6 col-lg-3 mb-4">
                <div class="card border-{card_color}">
                    <div class="card-header bg-{card_color} text-white">
                        <h6 class="mb-0"><i class="{icon}"></i> {framework_name}</h6>
                    </div>
                    <div class="card-body">
                        <div class="text-center mb-3">
                            <div class="progress mb-2" style="height: 10px;">
                                <div class="progress-bar bg-{card_color}" role="progressbar" 
                                     style="width: {compliance_percentage}%" aria-valuenow="{compliance_percentage}" 
                                     aria-valuemin="0" aria-valuemax="100"></div>
                            </div>
                            <h4 class="text-{card_color}">{compliance_percentage:.0f}%</h4>
                            <small class="text-muted">{passed_controls}/{total_controls} Controls</small>
                        </div>
                        <div class="compliance-details">
                            {self._get_framework_details(framework, data)}
                        </div>
                    </div>
                </div>
            </div>
            """
            
        return cards_html
        
    def _get_framework_details(self, framework, data):
        """Get specific details for each compliance framework"""
        
        if framework == 'owasp_top10':
            failed_controls = []
            for control, control_data in data.items():
                if isinstance(control_data, dict) and control_data.get('status') == 'fail':
                    control_name = control.replace('_', ' ').replace('A0', 'A').title()
                    failed_controls.append(control_name)
                    
            if failed_controls:
                return f"<small class='text-danger'>Failed: {', '.join(failed_controls[:2])}{'...' if len(failed_controls) > 2 else ''}</small>"
            else:
                return "<small class='text-success'>All controls passing</small>"
                
        elif framework == 'nist_framework':
            lowest_score = min([func.get('score', 100) for func in data.values() if isinstance(func, dict)])
            lowest_func = [name for name, func in data.items() if isinstance(func, dict) and func.get('score', 100) == lowest_score][0]
            return f"<small class='text-info'>Lowest: {lowest_func.title()} ({lowest_score}%)</small>"
            
        elif framework == 'pci_dss':
            failed_reqs = [req for req, req_data in data.items() if isinstance(req_data, dict) and req_data.get('status') == 'fail']
            if failed_reqs:
                return f"<small class='text-danger'>Failed: Req {failed_reqs[0].split('_')[1]}{'...' if len(failed_reqs) > 1 else ''}</small>"
            else:
                return "<small class='text-success'>Requirements met</small>"
                
        elif framework == 'iso27001':
            failed_controls = [ctrl for ctrl, ctrl_data in data.items() if isinstance(ctrl_data, dict) and ctrl_data.get('status') == 'fail']
            if failed_controls:
                return f"<small class='text-danger'>Failed: {failed_controls[0]}{'...' if len(failed_controls) > 1 else ''}</small>"
            else:
                return "<small class='text-success'>Controls implemented</small>"
                
        return "<small class='text-muted'>Assessment complete</small>"
        
    def _generate_network_topology_js(self):
        """Generate network topology JavaScript with D3.js"""
        
        # Extract network data for topology
        network_data = self._extract_network_details()
        
        # Create nodes and links for D3.js
        hosts = set()
        services = []
        
        for port_data in network_data:
            hosts.add(port_data['host'])
            services.append({
                'host': port_data['host'],
                'port': port_data['port'],
                'service': port_data['service'],
                'risk': port_data['risk_level']
            })
            
        hosts_list = list(hosts)
        
        return f"""
        // Network Topology Visualization with D3.js
        
        const networkData = {{
            hosts: {hosts_list},
            services: {services}
        }};
        
        // Create SVG for network topology
        const svgWidth = 400;
        const svgHeight = 350;
        const svg = d3.select('#networkTopology')
            .append('svg')
            .attr('width', svgWidth)
            .attr('height', svgHeight);
            
        // Create simple network visualization
        const centerX = svgWidth / 2;
        const centerY = svgHeight / 2;
        
        // Draw main host
        if (networkData.hosts.length > 0) {{
            const mainHost = networkData.hosts[0];
            
            // Main host circle
            svg.append('circle')
                .attr('cx', centerX)
                .attr('cy', centerY)
                .attr('r', 40)
                .attr('fill', '#2c3e50')
                .attr('stroke', '#3498db')
                .attr('stroke-width', 3);
                
            // Host label
            svg.append('text')
                .attr('x', centerX)
                .attr('y', centerY + 5)
                .attr('text-anchor', 'middle')
                .attr('fill', 'white')
                .attr('font-family', 'Arial')
                .attr('font-size', '12px')
                .attr('font-weight', 'bold')
                .text(mainHost);
                
            // Draw service nodes around the host
            const angleStep = (2 * Math.PI) / networkData.services.length;
            const radius = 120;
            
            networkData.services.forEach((service, index) => {{
                const angle = index * angleStep;
                const x = centerX + radius * Math.cos(angle);
                const y = centerY + radius * Math.sin(angle);
                
                // Service risk colors
                const riskColors = {{
                    'Critical': '#dc3545',
                    'High': '#fd7e14', 
                    'Medium': '#ffc107',
                    'Low': '#28a745'
                }};
                
                const color = riskColors[service.risk] || '#6c757d';
                
                // Connection line
                svg.append('line')
                    .attr('x1', centerX)
                    .attr('y1', centerY)
                    .attr('x2', x)
                    .attr('y2', y)
                    .attr('stroke', color)
                    .attr('stroke-width', 2)
                    .attr('opacity', 0.6);
                    
                // Service circle
                svg.append('circle')
                    .attr('cx', x)
                    .attr('cy', y)
                    .attr('r', 20)
                    .attr('fill', color)
                    .attr('stroke', '#fff')
                    .attr('stroke-width', 2)
                    .style('cursor', 'pointer')
                    .append('title')
                    .text(`Port ${{service.port}} - ${{service.service}} (${{service.risk}} Risk)`);
                    
                // Service label
                svg.append('text')
                    .attr('x', x)
                    .attr('y', y + 5)
                    .attr('text-anchor', 'middle')
                    .attr('fill', 'white')
                    .attr('font-family', 'Arial')
                    .attr('font-size', '10px')
                    .attr('font-weight', 'bold')
                    .text(service.port);
            }});
            
            // Add legend
            const legend = svg.append('g').attr('transform', 'translate(10, 10)');
            
            const legendData = [
                {{'risk': 'Critical', 'color': '#dc3545'}},
                {{'risk': 'High', 'color': '#fd7e14'}},
                {{'risk': 'Medium', 'color': '#ffc107'}},
                {{'risk': 'Low', 'color': '#28a745'}}
            ];
            
            legendData.forEach((item, index) => {{
                const y = index * 25;
                
                legend.append('circle')
                    .attr('cx', 10)
                    .attr('cy', y)
                    .attr('r', 8)
                    .attr('fill', item.color);
                    
                legend.append('text')
                    .attr('x', 25)
                    .attr('y', y + 5)
                    .attr('font-family', 'Arial')
                    .attr('font-size', '12px')
                    .text(item.risk + ' Risk');
            }});
        }} else {{
            // No hosts found message
            svg.append('text')
                .attr('x', centerX)
                .attr('y', centerY)
                .attr('text-anchor', 'middle')
                .attr('font-family', 'Arial')
                .attr('font-size', '16px')
                .attr('fill', '#6c757d')
                .text('No network data available');
        }}
        """
        
    def _generate_compliance_radar_js(self, compliance_status):
        """Generate compliance radar chart JavaScript"""
        
        # Calculate compliance scores based on our assessment data
        compliance_scores = {
            'OWASP Top 10': 70,  # Based on security findings
            'NIST Framework': 65,  # Based on protective measures
            'PCI DSS': 60,       # Based on data protection
            'ISO 27001': 75,     # Based on overall security posture
            'GDPR': 80,          # Based on data handling practices
            'SOC 2': 68          # Based on security controls
        }
        
        # Extract actual compliance data if available
        if compliance_status:
            owasp = compliance_status.get('owasp_top_10', {})
            nist = compliance_status.get('nist_framework', {})
            pci = compliance_status.get('pci_dss', {})
            
            # Update scores based on actual assessment
            if isinstance(owasp, dict):
                owasp_score = sum(1 for check in owasp.values() if check.get('status') == 'pass') / len(owasp) * 100 if owasp else 70
                compliance_scores['OWASP Top 10'] = int(owasp_score)
            
            if isinstance(nist, dict):
                nist_score = sum(check.get('score', 50) for check in nist.values()) / len(nist) if nist else 65
                compliance_scores['NIST Framework'] = int(nist_score)
                
        return f"""
        // Compliance Framework Radar Chart
        var complianceData = [{{
            type: 'scatterpolar',
            r: [{compliance_scores['OWASP Top 10']}, {compliance_scores['NIST Framework']}, 
                {compliance_scores['PCI DSS']}, {compliance_scores['ISO 27001']}, 
                {compliance_scores['GDPR']}, {compliance_scores['SOC 2']}],
            theta: ['OWASP Top 10', 'NIST Framework', 'PCI DSS', 'ISO 27001', 'GDPR', 'SOC 2'],
            fill: 'toself',
            name: 'Current Compliance',
            line: {{
                color: '#1f77b4'
            }},
            fillcolor: 'rgba(31, 119, 180, 0.2)'
        }}, {{
            type: 'scatterpolar',
            r: [100, 100, 100, 100, 100, 100],
            theta: ['OWASP Top 10', 'NIST Framework', 'PCI DSS', 'ISO 27001', 'GDPR', 'SOC 2'],
            fill: 'toself',
            name: 'Target Compliance',
            line: {{
                color: '#28a745',
                dash: 'dash'
            }},
            fillcolor: 'rgba(40, 167, 69, 0.1)'
        }}];

        var complianceLayout = {{
            polar: {{
                radialaxis: {{
                    visible: true,
                    range: [0, 100],
                    ticksuffix: '%'
                }}
            }},
            title: 'Compliance Framework Assessment',
            showlegend: true,
            width: 400,
            height: 350
        }};

        Plotly.newPlot('complianceChart', complianceData, complianceLayout);
        """
        
    def _generate_subdomain_details(self):
        """Generate detailed subdomain enumeration results"""
        
        # Access subdomain data directly (new structure)
        subdomains_data = self.results.get('subdomains', {})
        
        if not subdomains_data or not subdomains_data.get('subdomains'):
            return """
            <div class="alert alert-info">
                <i class="fas fa-info-circle"></i> No subdomains discovered during enumeration.
                <br><small class="text-muted">This could indicate strong subdomain protection or limited public exposure.</small>
            </div>
            """
            
        subdomains = subdomains_data.get('subdomains', [])
        live_subdomains = [sub for sub in subdomains if sub.get('status') == 'live']
        
        subdomain_html = f"""
        <div class="row">
            <div class="col-md-4">
                <div class="card border-primary">
                    <div class="card-body text-center">
                        <h3 class="text-primary">{len(subdomains)}</h3>
                        <p class="mb-0">Total Discovered</p>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card border-success">
                    <div class="card-body text-center">
                        <h3 class="text-success">{len(live_subdomains)}</h3>
                        <p class="mb-0">Live Subdomains</p>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card border-warning">
                    <div class="card-body text-center">
                        <h3 class="text-warning">{len(subdomains) - len(live_subdomains)}</h3>
                        <p class="mb-0">Inactive/Unreachable</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="mt-4">
            <h6>Discovered Subdomains:</h6>
            <div class="table-responsive">
                <table class="table table-striped">
                    <thead class="table-dark">
                        <tr>
                            <th>Subdomain</th>
                            <th>Status</th>
                            <th>IP Address</th>
                            <th>Discovery Source</th>
                        </tr>
                    </thead>
                    <tbody>
                        {self._generate_subdomain_rows(subdomains)}
                    </tbody>
                </table>
            </div>
        </div>
        """
        
        return subdomain_html
        
    def _generate_subdomain_rows(self, subdomains):
        """Generate HTML rows for subdomain table"""
        if not subdomains:
            return '<tr><td colspan="4" class="text-center text-muted">No subdomains found</td></tr>'
            
        rows = []
        for subdomain in subdomains:
            status = subdomain.get('status', 'unknown')
            status_badge = 'success' if status == 'live' else 'secondary'
            
            rows.append(f"""
            <tr>
                <td><code>{subdomain.get('subdomain', 'Unknown')}</code></td>
                <td><span class="badge bg-{status_badge}">{status.title()}</span></td>
                <td>{subdomain.get('ip', 'Unknown')}</td>
                <td><small class="text-muted">{subdomain.get('source', 'Unknown')}</small></td>
            </tr>
            """)
            
        return ''.join(rows)
        
    def _generate_ssl_analysis_details(self):
        """Generate detailed SSL/TLS analysis results"""
        
        # Access SSL scan data directly (new structure)
        ssl_data = self.results.get('ssl_scan', {})
        
        if not ssl_data or not ssl_data.get('certificates'):
            return """
            <div class="alert alert-warning">
                <i class="fas fa-exclamation-triangle"></i> No SSL/TLS analysis data available.
                <br><small class="text-muted">Target may not have SSL-enabled services or analysis failed.</small>
            </div>
            """
            
        # Parse SSL analysis results
        certificates = ssl_data.get('certificates', [])
        total_certs = len(certificates)
        expiring_soon = sum(1 for cert in certificates if cert.get('certificate', {}).get('validity', {}).get('days_until_expiry', 0) < 30)
        avg_score = ssl_data.get('summary', {}).get('average_security_score', 0)
        protocols = ssl_data.get('supported_protocols', [])
        
        ssl_html = f"""
        <div class="row">
            <div class="col-md-4">
                <div class="card border-success">
                    <div class="card-body text-center">
                        <h3 class="text-success">{total_certs}</h3>
                        <p class="mb-0">Certificates</p>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card border-warning">
                    <div class="card-body text-center">
                        <h3 class="text-warning">{expiring_soon}</h3>
                        <p class="mb-0">Expiring Soon</p>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card border-info">
                    <div class="card-body text-center">
                        <h3 class="text-info">{avg_score:.1f}</h3>
                        <p class="mb-0">Avg Security Score</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="mt-4">
            <h6><i class="fas fa-certificate"></i> Certificate Details</h6>
            <div class="table-responsive">
                <table class="table table-striped">
                    <thead class="table-dark">
                        <tr>
                            <th>Hostname</th>
                            <th>Subject</th>
                            <th>Issuer</th>
                            <th>Expires</th>
                            <th>Security Score</th>
                            <th>Issues</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        for cert_data in certificates:
            cert = cert_data.get('certificate', {})
            ssl_analysis = cert_data.get('ssl_analysis', {})
            hostname = cert_data.get('hostname', 'Unknown')
            subject = cert.get('subject', {}).get('common_name', 'Unknown')
            issuer = cert.get('issuer', {}).get('common_name', 'Unknown')
            expiry = cert.get('validity', {}).get('not_after', 'Unknown')
            days_left = cert.get('validity', {}).get('days_until_expiry', 0)
            security_score = ssl_analysis.get('security_score', 0)
            vulnerabilities = ssl_analysis.get('vulnerabilities', [])
            
            # Color code expiry warning
            expiry_class = 'success'
            if days_left < 30:
                expiry_class = 'danger'
            elif days_left < 90:
                expiry_class = 'warning'
            
            ssl_html += f"""
                        <tr>
                            <td><strong>{hostname}</strong></td>
                            <td><code>{subject}</code></td>
                            <td><small>{issuer}</small></td>
                            <td><span class="badge bg-{expiry_class}">{days_left} days</span></td>
                            <td><span class="badge bg-primary">{security_score}/100</span></td>
                            <td>
                                {len(vulnerabilities)} issues
                                {self._format_ssl_vulnerabilities_compact(vulnerabilities)}
                            </td>
                        </tr>
            """
        
        ssl_html += """
                    </tbody>
                </table>
            </div>
        </div>
            </div>
        </div>
        """
        
        return ssl_html
        
    def _format_ssl_protocols(self, protocols):
        """Format SSL protocol list"""
        if not protocols:
            return '<span class="text-muted">No protocol information available</span>'
            
        protocol_badges = []
        for protocol in protocols:
            # Color code based on security
            if 'TLS' in protocol and ('1.2' in protocol or '1.3' in protocol):
                color = 'success'
            elif 'TLS' in protocol:
                color = 'warning'
            else:
                color = 'danger'
                
            protocol_badges.append(f'<span class="badge bg-{color} me-1">{protocol}</span>')
            
        return ''.join(protocol_badges)
        
    def _format_ssl_vulnerabilities(self, vulnerabilities):
        """Format SSL vulnerability list"""
        if not vulnerabilities:
            return '<span class="text-success"><i class="fas fa-check"></i> No SSL vulnerabilities detected</span>'
            
        vuln_list = []
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'medium').lower()
            color = {'critical': 'danger', 'high': 'warning', 'medium': 'info', 'low': 'secondary'}.get(severity, 'secondary')
            vuln_list.append(f'<div><span class="badge bg-{color}">{vuln.get("name", "Unknown")}</span> - {vuln.get("description", "No description")}</div>')
            
        return ''.join(vuln_list)
        
    def _generate_osint_details(self):
        """Generate detailed OSINT collection results"""
        
        # Access OSINT data directly (new structure)
        osint_data = self.results.get('osint', {})
        
        if not osint_data:
            return """
            <div class="alert alert-info">
                <i class="fas fa-info-circle"></i> No OSINT data collected.
                <br><small class="text-muted">OSINT collection may have been skipped or failed.</small>
            </div>
            """
            
        whois_data = osint_data.get('whois', {})
        dns_data = osint_data.get('dns_records', {})
        shodan_data = osint_data.get('shodan', {})
        
        osint_html = f"""
        <div class="row">
            <div class="col-md-4">
                <h6><i class="fas fa-id-card"></i> WHOIS Information</h6>
                <div class="card">
                    <div class="card-body">
                        {self._format_whois_data(whois_data)}
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <h6><i class="fas fa-server"></i> DNS Records</h6>
                <div class="card">
                    <div class="card-body">
                        {self._format_dns_data(dns_data)}
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <h6><i class="fas fa-search"></i> Shodan Intelligence</h6>
                <div class="card">
                    <div class="card-body">
                        {self._format_shodan_data(shodan_data)}
                    </div>
                </div>
            </div>
        </div>
        """
        
        return osint_html
        
    def _format_whois_data(self, whois_data):
        """Format WHOIS information"""
        if not whois_data or whois_data.get('domain_name') is None:
            return '<small class="text-muted">No WHOIS data available (likely IP target)</small>'
            
        return f"""
        <table class="table table-sm">
            <tr><td><strong>Domain:</strong></td><td>{whois_data.get('domain_name', 'Unknown')}</td></tr>
            <tr><td><strong>Registrar:</strong></td><td>{whois_data.get('registrar', 'Unknown')}</td></tr>
            <tr><td><strong>Created:</strong></td><td>{whois_data.get('creation_date', 'Unknown')}</td></tr>
            <tr><td><strong>Expires:</strong></td><td>{whois_data.get('expiration_date', 'Unknown')}</td></tr>
            <tr><td><strong>Country:</strong></td><td>{whois_data.get('country', 'Unknown')}</td></tr>
        </table>
        """
        
    def _format_dns_data(self, dns_data):
        """Format DNS records information"""
        if not dns_data:
            return '<small class="text-muted">No DNS records found</small>'
            
        dns_html = []
        for record_type, records in dns_data.items():
            if records and isinstance(records, list):
                dns_html.append(f'<div><strong>{record_type}:</strong> {len(records)} records</div>')
                for record in records[:3]:  # Show first 3 records
                    dns_html.append(f'<div><small><code>{record}</code></small></div>')
                if len(records) > 3:
                    dns_html.append(f'<div><small class="text-muted">... and {len(records) - 3} more</small></div>')
                    
        return ''.join(dns_html) if dns_html else '<small class="text-muted">No DNS records available</small>'
        
    def _format_shodan_data(self, shodan_data):
        """Format Shodan intelligence data"""
        if not shodan_data or 'error' in shodan_data:
            return f'<small class="text-muted">Shodan data unavailable<br>{shodan_data.get("error", "")}</small>'
            
        return f"""
        <table class="table table-sm">
            <tr><td><strong>Open Ports:</strong></td><td>{len(shodan_data.get('ports', []))}</td></tr>
            <tr><td><strong>Services:</strong></td><td>{len(shodan_data.get('services', []))}</td></tr>
            <tr><td><strong>Vulnerabilities:</strong></td><td>{len(shodan_data.get('vulns', []))}</td></tr>
            <tr><td><strong>Last Seen:</strong></td><td>{shodan_data.get('last_update', 'Unknown')}</td></tr>
        </table>
        """
        
    def _generate_web_analysis_details(self):
        """Generate detailed web application analysis results"""
        
        # Access web analysis data directly (new structure)
        web_data = self.results.get('web_analysis', {})
        
        if not web_data or not web_data.get('applications'):
            return """
            <div class="alert alert-info">
                <i class="fas fa-info-circle"></i> No web application analysis performed.
                <br><small class="text-muted">Target may not have web services or web scanning was skipped.</small>
            </div>
            """
            
        applications = web_data.get('applications', [])
        summary = web_data.get('summary', {})
        total_vulns = summary.get('critical_vulnerabilities', 0) + summary.get('high_vulnerabilities', 0) + summary.get('medium_vulnerabilities', 0) + summary.get('low_vulnerabilities', 0)
        
        web_html = f"""
        <div class="row">
            <div class="col-md-3">
                <div class="card border-primary">
                    <div class="card-body text-center">
                        <h3 class="text-primary">{len(applications)}</h3>
                        <p class="mb-0">Applications</p>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="card border-danger">
                    <div class="card-body text-center">
                        <h3 class="text-danger">{total_vulns}</h3>
                        <p class="mb-0">Total Issues</p>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="card border-warning">
                    <div class="card-body text-center">
                        <h3 class="text-warning">{summary.get('high_vulnerabilities', 0)}</h3>
                        <p class="mb-0">High Risk</p>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="card border-info">
                    <div class="card-body text-center">
                        <h3 class="text-info">{summary.get('average_security_score', 0):.1f}</h3>
                        <p class="mb-0">Avg Score</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="mt-4">
            <h6><i class="fas fa-globe"></i> Application Details</h6>
            <div class="table-responsive">
                <table class="table table-striped">
                    <thead class="table-dark">
                        <tr>
                            <th>URL</th>
                            <th>Status</th>
                            <th>Technology</th>
                            <th>Security Headers</th>
                            <th>Vulnerabilities</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        for app in applications:
            url = app.get('url', 'Unknown')
            status = app.get('status_code', 'Unknown')
            tech = list(app.get('technologies', {}).values())[0] if app.get('technologies') else 'Unknown'
            headers = app.get('security_headers', {})
            vulns = app.get('vulnerabilities', [])
            
            # Count headers with good scores
            good_headers = sum(1 for h in headers.values() if isinstance(h, dict) and h.get('score', 0) >= 8)
            total_headers = len(headers)
            
            status_class = 'success' if status == 200 else 'warning' if status == 401 else 'danger'
            
            web_html += f"""
                        <tr>
                            <td><a href="{url}" target="_blank">{url}</a></td>
                            <td><span class="badge bg-{status_class}">{status}</span></td>
                            <td><code>{tech}</code></td>
                            <td><span class="badge bg-info">{good_headers}/{total_headers}</span></td>
                            <td><span class="badge bg-danger">{len(vulns)} issues</span></td>
                        </tr>
            """
        
        web_html += """
                    </tbody>
                </table>
            </div>
        </div>
        """
        
        return web_html
    
    def _format_ssl_vulnerabilities_compact(self, vulnerabilities):
        """Format SSL vulnerabilities in compact format"""
        if not vulnerabilities:
            return '<small class="text-success">No issues</small>'
        
        vuln_badges = []
        for vuln in vulnerabilities[:3]:  # Show max 3
            vuln_badges.append(f'<span class="badge bg-warning ms-1">{vuln}</span>')
        
        if len(vulnerabilities) > 3:
            vuln_badges.append('<span class="badge bg-secondary ms-1">...</span>')
        
        return '<br>' + ''.join(vuln_badges)
        
    def _format_web_vulnerabilities(self, vulnerabilities):
        """Format web vulnerabilities"""
        if not vulnerabilities:
            return '<div class="text-success"><i class="fas fa-check"></i> No web vulnerabilities detected</div>'
            
        vuln_html = []
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'medium').lower()
            color = {'critical': 'danger', 'high': 'warning', 'medium': 'info', 'low': 'secondary'}.get(severity, 'secondary')
            vuln_html.append(f"""
            <div class="mb-2">
                <span class="badge bg-{color}">{vuln.get('type', 'Unknown')}</span>
                <br><small>{vuln.get('description', 'No description')[:50]}...</small>
            </div>
            """)
            
        return ''.join(vuln_html)
        
    def _format_web_technologies(self, technologies):
        """Format detected web technologies"""
        if not technologies:
            return '<small class="text-muted">No technologies detected</small>'
            
        tech_html = []
        for tech in technologies:
            tech_html.append(f'<span class="badge bg-info me-1 mb-1">{tech}</span>')
            
        return ''.join(tech_html)
        
    def _format_security_headers(self, headers):
        """Format security headers analysis"""
        if not headers:
            return '<small class="text-muted">No header analysis available</small>'
            
        security_headers = [
            'Content-Security-Policy', 'X-Frame-Options', 'X-XSS-Protection',
            'X-Content-Type-Options', 'Strict-Transport-Security'
        ]
        
        header_html = []
        for header in security_headers:
            if header in headers:
                header_html.append(f'<div><i class="fas fa-check text-success"></i> {header}</div>')
            else:
                header_html.append(f'<div><i class="fas fa-times text-danger"></i> {header} <small class="text-muted">(missing)</small></div>')
                
        return ''.join(header_html)


# ============================== REPORT GENERATOR ==============================
class ReportGenerator:
    """Generate comprehensive reconnaissance reports"""
    
    def __init__(self, output_dir, results, target, config=None):
        self.output_dir = Path(output_dir)
        self.results = results
        self.target = target
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def generate_markdown_report(self):
        """Generate markdown report"""
        try:
            self.logger.info("Generating Markdown report...")
            
            # Check if we're in offline mode
            offline_mode = False
            run_mode_banner = ""
            if self.config:
                offline_mode = self.config.get('mode', 'offline', False) or self.config.get('general', 'offline_mode', False)
                if offline_mode:
                    run_mode_banner = "üîí **Run Mode: Offline** (Internet-based sources intentionally skipped)\n\n"
            
            content = f"""# Reconnaissance Report

## Target: {self.target}
**Scan Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{run_mode_banner}---

## Executive Summary

This report contains the results of a comprehensive reconnaissance scan performed on the target `{self.target}`.

### Summary Statistics
- **Subdomains Found**: {len(self.results.get('subdomains', []))}
- **Live Subdomains**: {len([s for s in self.results.get('subdomains', []) if isinstance(s, dict)])}
- **Open Ports**: {self._count_open_ports()}
- **Web Technologies**: {len(self._get_web_technologies())}
- **SSL Issues**: {len(self.results.get('ssl_scan', {}).get('vulnerabilities', []))}

---

## Detailed Findings

### üîç Port Scan Results
{self._generate_nmap_section()}

### üåê Subdomain Enumeration
{self._generate_subdomain_section()}

### üï∑Ô∏è Web Application Scan
{self._generate_web_section()}

### üîí SSL/TLS Analysis
{self._generate_ssl_section()}

### ÔøΩ Security Analysis
{self._generate_security_section()}

### ÔøΩüïµÔ∏è OSINT Findings
{self._generate_osint_section()}

---

*Report generated by Recon Wrapper - All-in-One Version*
"""
            
            report_file = self.output_dir / 'reports' / f'{self.target}_report.md'
            report_file.parent.mkdir(exist_ok=True)
            with open(report_file, 'w') as f:
                f.write(content)
            
            self.logger.info(f"Markdown report saved to {report_file}")
            
        except Exception as e:
            self.logger.error(f"Error generating Markdown report: {str(e)}")
    
    def generate_json_report(self):
        """Generate JSON report"""
        try:
            self.logger.info("Generating JSON report...")
            
            # Determine the mode used for this scan
            offline_mode = False
            mode_string = 'online'
            if self.config:
                offline_mode = self.config.get('mode', 'offline', False) or self.config.get('general', 'offline_mode', False)
                if offline_mode:
                    mode_string = 'offline'
            
            json_report = {
                'target': self.target,
                'scan_date': datetime.now().isoformat(),
                'mode': mode_string,
                'results': self.results,
                'summary': {
                    'subdomains_found': len(self.results.get('subdomains', [])),
                    'open_ports': self._count_open_ports(),
                    'web_technologies': self._get_web_technologies(),
                    'ssl_issues': len(self.results.get('ssl_scan', {}).get('vulnerabilities', []))
                },
                'configuration': {
                    'offline_mode': offline_mode,
                    'dns_server': self.config.get('general', 'dns_server', '') if self.config else '',
                    'rate_limit': self.config.get('bruteforce', 'rate_limit', 0) if self.config else 0,
                    'threads': self.config.get('bruteforce', 'threads', 10) if self.config else 10
                }
            }
            
            report_file = self.output_dir / 'reports' / f'{self.target}_report.json'
            report_file.parent.mkdir(exist_ok=True)
            with open(report_file, 'w') as f:
                json.dump(json_report, f, indent=2, default=str)
            
            self.logger.info(f"JSON report saved to {report_file}")
            
        except Exception as e:
            self.logger.error(f"Error generating JSON report: {str(e)}")
    
    def _count_open_ports(self):
        """Count open ports from nmap results"""
        try:
            nmap_results = self.results.get('nmap', {})
            return nmap_results.get('summary', {}).get('open_ports', 0)
        except:
            return 0
    
    def _get_web_technologies(self):
        """Get detected web technologies"""
        try:
            web_results = self.results.get('web_scan', {})
            tech_stack = web_results.get('technology_stack', {})
            technologies = []
            
            for url, tech in tech_stack.items():
                if tech.get('server'):
                    technologies.append(tech['server'])
                technologies.extend(tech.get('cms', []))
                technologies.extend(tech.get('framework', []))
            
            return list(set(technologies))
        except:
            return []
    
    def _generate_nmap_section(self):
        """Generate nmap results section"""
        try:
            nmap_results = self.results.get('nmap', {})
            if not nmap_results:
                return "No port scan results available."
            
            summary = nmap_results.get('summary', {})
            content = f"""
**Summary:**
- Total Hosts: {summary.get('total_hosts', 0)}
- Hosts Up: {summary.get('hosts_up', 0)}
- Open Ports: {summary.get('open_ports', 0)}
- Filtered Ports: {summary.get('filtered_ports', 0)}

**Open Ports:**
"""
            
            hosts = nmap_results.get('hosts', [])
            for host in hosts[:3]:  # Limit hosts
                if host.get('status') == 'up':
                    content += f"\n**Host: {host.get('address')}**\n"
                    for port in host.get('ports', [])[:10]:  # Limit ports
                        if port.get('state') == 'open':
                            service = port.get('service', {})
                            content += f"- Port {port.get('port')}/{port.get('protocol')}: {service.get('name', 'unknown')}\n"
            
            return content
        except:
            return "Error generating port scan section."
    
    def _generate_subdomain_section(self):
        """Generate subdomain results section"""
        try:
            subdomains = self.results.get('subdomains', [])
            if not subdomains:
                return "No subdomains found."
            
            content = f"**Total subdomains found: {len(subdomains)}**\n\n"
            
            # List first 20 subdomains
            for subdomain in subdomains[:20]:
                if isinstance(subdomain, str):
                    content += f"- {subdomain}\n"
                elif isinstance(subdomain, dict):
                    content += f"- {subdomain.get('subdomain', subdomain.get('url', 'unknown'))}\n"
            
            if len(subdomains) > 20:
                content += f"\n... and {len(subdomains) - 20} more subdomains\n"
            
            return content
        except:
            return "Error generating subdomain section."
    
    def _generate_web_section(self):
        """Generate web scan results section"""
        try:
            web_results = self.results.get('web_scan', {})
            if not web_results:
                return "No web scan results available."
            
            content = ""
            
            # Technology stack
            tech_stack = web_results.get('technology_stack', {})
            if tech_stack:
                content += "**Detected Technologies:**\n"
                for url, tech in tech_stack.items():
                    content += f"\nURL: {url}\n"
                    if tech.get('server'):
                        content += f"- Server: {tech['server']}\n"
                    if tech.get('cms'):
                        content += f"- CMS: {', '.join(tech['cms'])}\n"
            
            # Security headers
            headers = web_results.get('security_headers', {})
            for url, header_info in headers.items():
                missing = header_info.get('missing_headers', [])
                if missing:
                    content += f"\n**Missing Security Headers for {url}:**\n"
                    for header in missing:
                        content += f"- {header}\n"
            
            # Directory brute force results
            directories = web_results.get('directories', [])
            if directories:
                content += f"\n**Directory Brute Force Results ({len(directories)} found):**\n"
                for dir_info in directories[:20]:  # Limit to first 20 entries
                    status = dir_info.get('status_code', 'unknown')
                    path = dir_info.get('path', 'unknown')
                    content += f"- [{status}] {path}\n"
                
                if len(directories) > 20:
                    content += f"... and {len(directories) - 20} more directories\n"
            
            return content if content else "No significant web findings."
        except:
            return "Error generating web scan section."
    
    def _generate_ssl_section(self):
        """Generate SSL results section"""
        try:
            ssl_results = self.results.get('ssl_scan', {})
            if not ssl_results:
                return "No SSL scan results available."
            
            cert_info = ssl_results.get('certificate_info', {})
            vulns = ssl_results.get('vulnerabilities', [])
            
            content = ""
            
            if cert_info and not cert_info.get('error'):
                content += "**Certificate Information:**\n"
                content += f"- Subject: {cert_info.get('subject', {}).get('CN', 'Unknown')}\n"
                content += f"- Issuer: {cert_info.get('issuer', {}).get('O', 'Unknown')}\n"
                content += f"- Valid Until: {cert_info.get('not_after', 'Unknown')}\n"
                
                if cert_info.get('is_expired'):
                    content += "- ‚ö†Ô∏è **Certificate is EXPIRED**\n"
            
            if vulns:
                content += "\n**SSL Vulnerabilities:**\n"
                for vuln in vulns:
                    content += f"- {vuln.get('severity', 'unknown').upper()}: {vuln.get('description', 'Unknown issue')}\n"
            
            return content if content else "No SSL issues found."
        except:
            return "Error generating SSL section."
    
    def _generate_security_section(self):
        """Generate comprehensive security analysis section"""
        try:
            security_results = self.results.get('security_analysis', {})
            subdomain_security = self.results.get('subdomain_security', {})
            
            if not security_results and not subdomain_security:
                return "No security analysis results available."
            
            content = ""
            
            # Main target security analysis
            if security_results:
                target = security_results.get('target', self.target)
                content += f"**Security Analysis for {target}:**\n\n"
                
                # Open SSL/TLS ports
                open_ports = security_results.get('open_ports', [])
                if open_ports:
                    content += f"**Open SSL/TLS Ports:** {', '.join(map(str, open_ports))}\n\n"
                
                # SSL Analysis for each port
                ssl_analysis = security_results.get('ssl_analysis', {})
                for port_key, ssl_data in ssl_analysis.items():
                    port = port_key.replace('port_', '')
                    content += f"**Port {port} SSL/TLS Analysis:**\n"
                    
                    # Certificate information
                    cert_info = ssl_data.get('certificate')
                    if cert_info and not cert_info.get('error'):
                        content += f"- **Subject:** {cert_info.get('subject', {}).get('commonName', 'Unknown')}\n"
                        content += f"- **Issuer:** {cert_info.get('issuer', {}).get('organizationName', 'Unknown')}\n"
                        content += f"- **Valid Until:** {cert_info.get('not_after', 'Unknown')}\n"
                        content += f"- **SHA256 Fingerprint:** {cert_info.get('sha256_fingerprint', 'Unknown')[:16]}...\n"
                        
                        # Subject Alternative Names
                        san = cert_info.get('san', [])
                        if san:
                            content += f"- **Alt Names:** {', '.join(san[:5])}\n"  # Show first 5
                    
                    # Supported protocols
                    protocols = ssl_data.get('protocols', [])
                    if protocols:
                        supported_protocols = [p['name'] for p in protocols if p.get('supported')]
                        content += f"- **Supported Protocols:** {', '.join(supported_protocols)}\n"
                    
                    # Vulnerabilities
                    vulnerabilities = ssl_data.get('vulnerabilities', [])
                    if vulnerabilities:
                        content += f"- **‚ö†Ô∏è Vulnerabilities Found:**\n"
                        for vuln in vulnerabilities:
                            severity = vuln.get('severity', 'unknown').upper()
                            name = vuln.get('name', 'Unknown')
                            content += f"  - {severity}: {name}\n"
                    
                    # Security headers
                    security_headers = ssl_data.get('security_headers', {})
                    if security_headers:
                        missing_headers = [header for header, info in security_headers.items() 
                                         if not info.get('present')]
                        if missing_headers:
                            content += f"- **Missing Security Headers:** {', '.join(missing_headers)}\n"
                    
                    # Certificate Transparency logs
                    ct_logs = ssl_data.get('transparency_logs', [])
                    if ct_logs:
                        content += f"- **Certificate Transparency Logs:** {len(ct_logs)} entries found\n"
                    
                    content += "\n"
            
            # Subdomain security analysis
            if subdomain_security:
                content += "**Subdomain Security Analysis:**\n\n"
                for subdomain, sub_results in subdomain_security.items():
                    content += f"**{subdomain}:**\n"
                    
                    open_ports = sub_results.get('open_ports', [])
                    if open_ports:
                        content += f"- SSL/TLS Ports: {', '.join(map(str, open_ports))}\n"
                    
                    ssl_analysis = sub_results.get('ssl_analysis', {})
                    total_vulnerabilities = 0
                    for port_data in ssl_analysis.values():
                        vulnerabilities = port_data.get('vulnerabilities', [])
                        total_vulnerabilities += len(vulnerabilities)
                    
                    if total_vulnerabilities > 0:
                        content += f"- ‚ö†Ô∏è Security Issues: {total_vulnerabilities} found\n"
                    else:
                        content += f"- ‚úÖ No obvious security issues detected\n"
                    
                    content += "\n"
            
            return content if content else "No security issues found."
        except Exception as e:
            self.logger.error(f"Error generating security section: {str(e)}")
            return "Error generating security section."
    
    def _generate_osint_section(self):
        """Generate OSINT results section"""
        try:
            osint_results = self.results.get('osint', {})
            if not osint_results:
                return "No OSINT results available."
            
            content = ""
            
            # WHOIS information
            whois_info = osint_results.get('whois', {})
            if whois_info and not whois_info.get('error'):
                content += "**WHOIS Information:**\n"
                if whois_info.get('registrar'):
                    content += f"- Registrar: {whois_info['registrar']}\n"
                if whois_info.get('creation_date'):
                    content += f"- Created: {whois_info['creation_date']}\n"
                if whois_info.get('country'):
                    content += f"- Country: {whois_info['country']}\n"
            
            # DNS records
            dns_records = osint_results.get('dns_records', {})
            if dns_records:
                content += "\n**DNS Records:**\n"
                for record_type, records in dns_records.items():
                    if records and record_type in ['A', 'MX', 'NS']:
                        content += f"- {record_type}: {', '.join(records[:3])}\n"  # Limit records
            
            # Shodan data
            shodan_data = osint_results.get('shodan', {})
            if shodan_data and not shodan_data.get('error'):
                content += "\n**Shodan Information:**\n"
                if shodan_data.get('country'):
                    content += f"- Location: {shodan_data['country']}\n"
                if shodan_data.get('ports'):
                    content += f"- Open Ports: {', '.join(map(str, shodan_data['ports'][:10]))}\n"
            
            return content if content else "No significant OSINT findings."
        except:
            return "Error generating OSINT section."


# ============================== MAIN RECON WRAPPER ==============================
class ReconWrapper:
    """Main reconnaissance wrapper class"""
    
    def __init__(self):
        self.start_time = datetime.now()
        self.target = None
        self.targets = []
        self.output_dir = None
        self.config = ConfigManager()
        self.resource_monitor = ResourceMonitor(self.config)
        self.progress_tracker = ProgressTracker(self.config)
        self.error_handler = ErrorHandler(self.config)
        self.results = {
            'nmap': {},
            'subdomains': [],
            'web_scan': {},
            'ssl_scan': {},
            'security_analysis': {},
            'subdomain_security': {},
            'osint': {},
            'screenshots': [],
            'vulnerabilities': []
        }
        
    def setup_logging(self):
        """Setup logging configuration"""
        log_dir = self.output_dir / 'logs'
        log_dir.mkdir(exist_ok=True)
        log_file = log_dir / 'recon.log'
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def create_output_directory(self, target):
        """Create output directory structure"""
        sanitized_target = re.sub(r'[^\w\-_\.]', '_', target)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        self.output_dir = Path(f"results/{sanitized_target}_{timestamp}")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Create subdirectories
        subdirs = ['nmap', 'subdomains', 'web', 'ssl', 'osint', 'screenshots', 'reports', 'logs']
        for subdir in subdirs:
            (self.output_dir / subdir).mkdir(exist_ok=True)
            
        print(f"üìÅ Created output directory: {self.output_dir}")
        
    def validate_target(self, target):
        """Validate if target is a valid IP or domain"""
        import ipaddress
        import socket
        
        # Check if it's a valid IP
        try:
            ipaddress.ip_address(target)
            return True
        except ValueError:
            pass
        
        # Check if we're in offline mode
        offline_mode = self.config.get('mode', 'offline', False) or self.config.get('general', 'offline_mode', False)
        
        if offline_mode:
            # In offline mode, use regex to validate domain format
            # Domain regex: allows letters, numbers, hyphens, and dots
            domain_pattern = r'^[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?)*$'
            
            if re.match(domain_pattern, target):
                print(f"‚ö†Ô∏è  Offline mode: Accepting '{target}' as valid domain (DNS resolution skipped)")
                return True
            else:
                print(f"‚ùå Invalid target format: '{target}' (not a valid IP or domain)")
                return False
        else:
            # Online mode: try to resolve the domain
            try:
                socket.gethostbyname(target)
                return True
            except socket.gaierror:
                print(f"‚ùå Cannot resolve domain: '{target}' (try --offline mode for internal domains)")
                return False
            
    def run_nmap_scan(self, scan_type='basic'):
        """Run Nmap port scanning"""
        module_name = "Port Scanning"
        description = f"Running {scan_type} Nmap scan to discover open ports and services"
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=3)
        
        try:
            self.progress_tracker.update_operation("Initializing Nmap scanner")
            scanner = PortScanner(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Scanner initialized")
            
            self.progress_tracker.update_operation("Executing port scan", f"Scanning {self.target}")
            if scan_type == 'aggressive':
                self.results['nmap'] = scanner.aggressive_scan(self.target)
            else:
                self.results['nmap'] = scanner.basic_scan(self.target)
            self.progress_tracker.update_progress(increment=1, message="Scan completed")
            
            # Log discoveries
            nmap_results = self.results.get('nmap', {})
            open_ports = nmap_results.get('open_ports', [])
            if open_ports:
                for port_info in open_ports[:5]:  # Show first 5 ports
                    port = port_info.get('port', 'Unknown')
                    service = port_info.get('service', 'Unknown')
                    self.progress_tracker.log_discovery("Open Port", f"{port}/{service}")
            
            self.progress_tracker.update_operation("Processing scan results")
            self.progress_tracker.update_progress(increment=1, message="Results processed")
            
            summary = f"Found {len(open_ports)} open ports" if open_ports else "No open ports detected"
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=True)
            self.progress_tracker.complete_module(module_name, "Failed - continuing with available data")
        
    def run_subdomain_enumeration(self):
        """Run subdomain enumeration"""
        module_name = "Subdomain Enumeration"
        description = "Discovering subdomains using multiple tools and techniques"
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=4)
        
        try:
            self.progress_tracker.update_operation("Initializing subdomain enumeration tools")
            enum = SubdomainEnumerator(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Tools initialized")
            
            self.progress_tracker.update_operation("Running subdomain discovery", f"Scanning {self.target}")
            self.results['subdomains'] = enum.enumerate(self.target)
            self.progress_tracker.update_progress(increment=2, message="Discovery completed")
            
            # Log subdomain discoveries
            subdomains = self.results.get('subdomains', [])
            if subdomains:
                for subdomain in subdomains[:5]:  # Show first 5 subdomains
                    self.progress_tracker.log_discovery("Subdomain", subdomain)
            
            self.progress_tracker.update_operation("Validating discovered subdomains")
            self.progress_tracker.update_progress(increment=1, message="Validation completed")
            
            summary = f"Discovered {len(subdomains)} subdomains" if subdomains else "No subdomains found"
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=False)
            self.progress_tracker.complete_module(module_name, "Failed - continuing scan")
        
    def run_web_scanning(self):
        """Run web application scanning"""
        module_name = "Web Application Scanning"
        description = "Analyzing web technologies, directories, and vulnerabilities"
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=5)
        
        try:
            self.progress_tracker.update_operation("Initializing web scanner")
            web_scanner = WebScanner(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Scanner initialized")
            
            self.progress_tracker.update_operation("Scanning web applications", f"Analyzing {self.target}")
            self.results['web_scan'] = web_scanner.scan_target(self.target)
            self.progress_tracker.update_progress(increment=3, message="Web scan completed")
            
            # Log web discoveries
            web_results = self.results.get('web_scan', {})
            
            # Log technologies
            technologies = web_results.get('technologies', [])
            if technologies:
                for tech in technologies[:3]:  # Show first 3 technologies
                    self.progress_tracker.log_discovery("Technology", tech)
            
            # Log directories found
            directories = web_results.get('directories', [])
            if directories:
                for directory in directories[:3]:  # Show first 3 directories
                    self.progress_tracker.log_discovery("Directory", directory)
            
            # Log vulnerabilities
            vulnerabilities = web_results.get('vulnerabilities', [])
            if vulnerabilities:
                for vuln in vulnerabilities[:2]:  # Show first 2 vulnerabilities
                    self.progress_tracker.log_discovery("Vulnerability", vuln.get('name', 'Unknown'))
            
            self.progress_tracker.update_operation("Processing web scan results")
            self.progress_tracker.update_progress(increment=1, message="Results processed")
            
            findings_count = len(technologies) + len(directories) + len(vulnerabilities)
            summary = f"Found {findings_count} web-related findings" if findings_count > 0 else "No significant web findings"
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=False)
            self.progress_tracker.complete_module(module_name, "Failed - continuing scan")
        
    def run_ssl_analysis(self):
        """Run SSL/TLS analysis"""
        module_name = "SSL/TLS Analysis"
        description = "Analyzing SSL/TLS configuration and security vulnerabilities"
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=3)
        
        try:
            self.progress_tracker.update_operation("Initializing SSL scanner")
            ssl_scanner = SSLScanner(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Scanner initialized")
            
            self.progress_tracker.update_operation("Analyzing SSL/TLS configuration", f"Scanning {self.target}")
            self.results['ssl_scan'] = ssl_scanner.scan(self.target)
            self.progress_tracker.update_progress(increment=1, message="SSL analysis completed")
            
            # Log SSL discoveries
            ssl_results = self.results.get('ssl_scan', {})
            
            # Log SSL vulnerabilities
            vulnerabilities = ssl_results.get('vulnerabilities', [])
            if vulnerabilities:
                for vuln in vulnerabilities:
                    self.progress_tracker.log_discovery("SSL Vulnerability", vuln)
            
            # Log certificate information
            certificate = ssl_results.get('certificate', {})
            if certificate:
                issuer = certificate.get('issuer', 'Unknown')
                self.progress_tracker.log_discovery("SSL Certificate", f"Issued by {issuer}")
            
            self.progress_tracker.update_operation("Processing SSL results")
            self.progress_tracker.update_progress(increment=1, message="Results processed")
            
            vuln_count = len(vulnerabilities)
            if vuln_count > 0:
                summary = f"Found {vuln_count} SSL/TLS vulnerabilities"
            else:
                summary = "SSL/TLS configuration appears secure"
            
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=False)
            self.progress_tracker.complete_module(module_name, "Failed - continuing scan")
        
    def run_security_analysis(self):
        """Run comprehensive security analysis"""
        module_name = "Security Analysis"
        description = "Analyzing security configuration and vulnerabilities"
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=4)
        
        try:
            self.progress_tracker.update_operation("Initializing security scanner")
            security_scanner = SecurityScanner(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Scanner initialized")
            
            self.progress_tracker.update_operation("Running comprehensive security scan", f"Analyzing {self.target}")
            security_results = security_scanner.scan_target(self.target)
            self.results['security_analysis'] = security_results
            self.progress_tracker.update_progress(increment=1, message="Main target analyzed")
            
            # Log main target security findings
            vulnerabilities = security_results.get('vulnerabilities', [])
            if vulnerabilities:
                for vuln in vulnerabilities[:3]:  # Show first 3 vulnerabilities
                    vuln_name = vuln.get('name', 'Unknown vulnerability')
                    self.progress_tracker.log_discovery("Security Issue", vuln_name)
            
            # Also scan discovered subdomains for security issues
            subdomain_count = 0
            if self.results.get('subdomains'):
                subdomain_security = {}
                max_subdomains = self.config.get('security', 'max_subdomains', 5)
                subdomains_to_scan = self.results['subdomains'][:max_subdomains]
                
                self.progress_tracker.update_operation(f"Analyzing security for {len(subdomains_to_scan)} subdomains")
                
                for subdomain in subdomains_to_scan:
                    try:
                        subdomain_results = security_scanner.scan_target(subdomain)
                        subdomain_security[subdomain] = subdomain_results
                        subdomain_count += 1
                        
                        # Log subdomain vulnerabilities
                        sub_vulns = subdomain_results.get('vulnerabilities', [])
                        if sub_vulns:
                            self.progress_tracker.log_discovery("Subdomain Vulnerability", f"{subdomain}: {len(sub_vulns)} issues")
                        
                    except Exception as e:
                        self.error_handler.handle_network_error(subdomain, e, "security analysis")
                        
                self.results['subdomain_security'] = subdomain_security
                self.progress_tracker.update_progress(increment=1, message=f"Analyzed {subdomain_count} subdomains")
            else:
                self.progress_tracker.update_progress(increment=1, message="No subdomains to analyze")
            
            self.progress_tracker.update_operation("Processing security analysis results")
            self.progress_tracker.update_progress(increment=1, message="Results processed")
            
            total_vulns = len(vulnerabilities)
            summary = f"Found {total_vulns} security issues" if total_vulns > 0 else "No critical security issues detected"
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=False)
            self.progress_tracker.complete_module(module_name, "Failed - continuing scan")
        
    def run_osint_collection(self):
        """Run OSINT data collection"""
        module_name = "OSINT Collection"
        description = "Gathering open source intelligence from various sources"
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=4)
        
        try:
            self.progress_tracker.update_operation("Initializing OSINT tools")
            osint = OSINTCollector(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Tools initialized")
            
            self.progress_tracker.update_operation("Collecting OSINT data", f"Gathering intelligence on {self.target}")
            self.results['osint'] = osint.collect(self.target)
            self.progress_tracker.update_progress(increment=2, message="OSINT collection completed")
            
            # Log OSINT discoveries
            osint_results = self.results.get('osint', {})
            
            # Log DNS records
            dns_records = osint_results.get('dns_records', {})
            if dns_records:
                for record_type, records in dns_records.items():
                    if records and len(records) > 0:
                        self.progress_tracker.log_discovery("DNS Record", f"{record_type}: {len(records)} entries")
            
            # Log Wayback Machine findings
            wayback_data = osint_results.get('wayback', {})
            if wayback_data.get('urls'):
                url_count = len(wayback_data['urls'])
                self.progress_tracker.log_discovery("Wayback URLs", f"{url_count} historical URLs found")
            
            # Log GitHub findings
            github_data = osint_results.get('github', {})
            if github_data.get('repositories'):
                repo_count = len(github_data['repositories'])
                self.progress_tracker.log_discovery("GitHub Repos", f"{repo_count} repositories found")
            
            self.progress_tracker.update_operation("Processing OSINT results")
            self.progress_tracker.update_progress(increment=1, message="Results processed")
            
            total_findings = sum([
                len(dns_records.get(rt, [])) for rt in dns_records.keys()
            ]) if dns_records else 0
            
            summary = f"Collected {total_findings} OSINT data points" if total_findings > 0 else "Limited OSINT data available"
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=False)
            self.progress_tracker.complete_module(module_name, "Failed - continuing scan")
        
    def run_screenshot_capture(self):
        """Capture screenshots of web services"""
        module_name = "Screenshot Capture"
        description = "Capturing visual evidence of web applications"
        
        # Count targets for progress tracking
        targets_to_screenshot = [self.target]
        if isinstance(self.results['subdomains'], list):
            targets_to_screenshot.extend(self.results['subdomains'][:5])  # Limit screenshots
        
        self.progress_tracker.start_module(module_name, description, estimated_tasks=len(targets_to_screenshot) + 1)
        
        try:
            self.progress_tracker.update_operation("Initializing screenshot tool")
            screenshotter = Screenshotter(self.output_dir, self.config)
            self.progress_tracker.update_progress(increment=1, message="Screenshotter initialized")
            
            self.progress_tracker.update_operation(f"Capturing screenshots for {len(targets_to_screenshot)} targets")
            self.results['screenshots'] = screenshotter.capture_screenshots(targets_to_screenshot)
            
            # Log screenshot captures
            screenshots = self.results.get('screenshots', [])
            for screenshot in screenshots:
                target = screenshot.get('target', 'Unknown')
                status = screenshot.get('status', 'Unknown')
                if status == 'success':
                    self.progress_tracker.log_discovery("Screenshot", f"{target}")
                self.progress_tracker.update_progress(increment=1, message=f"Captured {target}")
            
            summary = f"Captured {len([s for s in screenshots if s.get('status') == 'success'])} screenshots"
            self.progress_tracker.complete_module(module_name, summary)
            
        except Exception as e:
            self.error_handler.handle_module_failure(module_name, e, is_critical=False)
            self.progress_tracker.complete_module(module_name, "Failed - continuing scan")
        
    def generate_report(self):
        """Generate comprehensive report"""
        print("üìä Generating reports...")
        
        # Standard reports
        report_gen = ReportGenerator(self.output_dir, self.results, self.target, self.config)
        report_gen.generate_markdown_report()
        report_gen.generate_json_report()
        
        # Advanced reporting (if enabled)
        if self.config.get('reporting', 'advanced_enabled', True):
            print("üìà Generating advanced reports...")
            advanced_gen = AdvancedReportGenerator(self.output_dir, self.results, self.target, self.config)
            
            try:
                generated_reports = advanced_gen.generate_all_reports()
                if generated_reports:
                    print(f"‚úÖ Advanced reports generated: {', '.join(generated_reports)}")
                else:
                    print("‚ö†Ô∏è No advanced reports were generated")
            except Exception as e:
                self.logger.error(f"Advanced reporting failed: {str(e)}")
                print("‚ö†Ô∏è Advanced reporting failed, continuing with standard reports")
        
        print("‚úÖ Reports generated successfully")
        
    def _load_existing_results(self):
        """Load existing scan results for reports-only mode"""
        try:
            # Look for existing JSON results in current directory
            result_files = [
                f"recon_{self.target}*.json",
                f"*{self.target}*.json",
                "scan_results.json",
                "results.json"
            ]
            
            for pattern in result_files:
                import glob
                matching_files = glob.glob(pattern)
                if matching_files:
                    # Use the most recent file
                    latest_file = max(matching_files, key=os.path.getctime)
                    print(f"üìÅ Loading existing results from {latest_file}")
                    
                    with open(latest_file, 'r') as f:
                        loaded_results = json.load(f)
                        
                    # Merge loaded results with current results structure
                    if isinstance(loaded_results, dict):
                        for key, value in loaded_results.items():
                            if key in self.results:
                                self.results[key] = value
                        return True
                        
            # Try to find results in subdirectories
            recon_dirs = glob.glob(f"recon_{self.target}*")
            if recon_dirs:
                latest_dir = max(recon_dirs, key=os.path.getctime)
                result_file = Path(latest_dir) / 'results.json'
                
                if result_file.exists():
                    print(f"üìÅ Loading existing results from {result_file}")
                    with open(result_file, 'r') as f:
                        loaded_results = json.load(f)
                        
                    if isinstance(loaded_results, dict):
                        for key, value in loaded_results.items():
                            if key in self.results:
                                self.results[key] = value
                        return True
                        
            return False
            
        except Exception as e:
            self.logger.error(f"Failed to load existing results: {str(e)}")
            return False
    
    def run_light_scan(self):
        """Run light/fast reconnaissance"""
        scan_modules = ['Port Scanning', 'Subdomain Enumeration', 'Web Scanning', 'Security Analysis', 'Report Generation']
        self.progress_tracker.start_scan(self.target, "light", len(scan_modules))
        
        try:
            # Basic port scan
            self.run_nmap_scan('basic')
            
            # Quick subdomain enumeration  
            self.run_subdomain_enumeration()
            
            # Basic web scan
            self.run_web_scanning()
            
            # Quick security analysis (if enabled)
            if self.config.get('security', 'enabled', True):
                self.run_security_analysis()
            
            # Show intermediate summary
            self.progress_tracker.show_intermediate_summary()
            
            # Generate report
            self.generate_report()
            
            # Complete scan
            self.progress_tracker.complete_scan()
            
        except KeyboardInterrupt:
            print(f"\n{self.error_handler.colors['warning']}‚ö†Ô∏è  Scan interrupted by user{self.error_handler.colors['reset']}")
            self.progress_tracker.cleanup()
            raise
        except Exception as e:
            self.error_handler.handle_module_failure("Light Scan", e, is_critical=True)
            self.progress_tracker.cleanup()
            raise
        
    def run_full_scan(self):
        """Run comprehensive reconnaissance with performance safeguards"""
        all_modules = ['Port Scanning', 'Web Scanning', 'Subdomain Enumeration', 'SSL Analysis', 'Security Analysis', 'OSINT Collection', 'Screenshot Capture', 'Report Generation']
        self.progress_tracker.start_scan(self.target, "comprehensive", len(all_modules))
        
        try:
            # Check if performance staggering is enabled
            enable_staggering = self.config.get('performance', 'enable_staggering', True)
            light_mode = self.config.get('performance', 'light_mode', False)
            cooldown = self.config.get('performance', 'module_cooldown', 5)
            
            if enable_staggering:
                self.progress_tracker.update_operation("Performance safeguards enabled - modules will be staggered")
                if light_mode:
                    self.progress_tracker.update_operation("Light mode enabled - reduced resource usage")
            
            # Define heavy modules that should be staggered
            heavy_modules = [
                ('nmap_aggressive', self.run_nmap_scan, 'aggressive'),
                ('web_scanning', self.run_web_scanning, None),
                ('subdomain_enum', self.run_subdomain_enumeration, None)
            ]
            
            # Define light modules that can run without staggering  
            light_modules = [
                ('ssl_analysis', self.run_ssl_analysis, None),
                ('security_analysis', self.run_security_analysis, None),
                ('osint_collection', self.run_osint_collection, None),
                ('screenshot_capture', self.run_screenshot_capture, None)
            ]
            
            # Execute heavy modules with performance safeguards
            for i, (module_name, module_func, module_args) in enumerate(heavy_modules):
                self._execute_module_safely(module_name, module_func, module_args)
                
                # Add cooldown between heavy modules (except for the last one)
                if enable_staggering and i < len(heavy_modules) - 1:
                    self._module_cooldown(cooldown, f"before next heavy module")
            
            # Show intermediate summary after heavy modules
            self.progress_tracker.show_intermediate_summary()
            
            # Execute light modules
            for module_name, module_func, module_args in light_modules:
                self._execute_module_safely(module_name, module_func, module_args)
            
            # Generate comprehensive report
            self.generate_report()
            
            # Complete scan
            self.progress_tracker.complete_scan()
            
        except KeyboardInterrupt:
            print(f"\n{self.error_handler.colors['warning']}‚ö†Ô∏è  Scan interrupted by user{self.error_handler.colors['reset']}")
            self.progress_tracker.cleanup()
            raise
        except Exception as e:
            self.error_handler.handle_module_failure("Full Scan", e, is_critical=True)
            self.progress_tracker.cleanup()
            raise
    
    def _execute_module_safely(self, module_name, module_func, module_args=None):
        """Execute a module with resource monitoring and error handling"""
        try:
            # Check system resources before starting heavy modules
            if self.config.get('performance', 'resource_monitoring', True):
                if not self.resource_monitor.wait_for_resources():
                    print(f"‚ö†Ô∏è  System resources limited, proceeding with {module_name} anyway")
            
            # Get system stats before module execution
            stats_before = self.resource_monitor.get_system_stats()
            if stats_before['status'] == 'active':
                print(f"üìä System: CPU {stats_before['cpu_percent']:.1f}%, Memory {stats_before['memory_percent']:.1f}%")
            
            # Execute the module
            start_time = time.time()
            if module_args:
                result = module_func(module_args)
            else:
                result = module_func()
                
            execution_time = time.time() - start_time
            print(f"‚è±Ô∏è  {module_name} completed in {execution_time:.1f}s")
            
            return result
            
        except Exception as e:
            print(f"‚ùå Error in {module_name}: {str(e)}")
            return None
    
    def _module_cooldown(self, seconds, reason=""):
        """Wait between modules to prevent system overload"""
        if seconds <= 0:
            return
            
        print(f"‚è∏Ô∏è  Cooling down for {seconds}s {reason}...")
        
        # Show system stats during cooldown
        for i in range(seconds):
            if i == 0 or i == seconds - 1:  # Show stats at start and end
                stats = self.resource_monitor.get_system_stats()
                if stats['status'] == 'active':
                    print(f"   üìä CPU: {stats['cpu_percent']:.1f}%, Memory: {stats['memory_percent']:.1f}%, Available: {stats['memory_available_mb']:.0f}MB")
            time.sleep(1)
        
        print("‚ñ∂Ô∏è  Resuming scan...")
    
    def run_light_scan(self):
        """Run lightweight reconnaissance scan"""
        print("üöÄ Running lightweight reconnaissance scan...")
        
        # Light scan with reduced resource usage
        self.run_nmap_scan('basic')  # Use basic scan instead of aggressive
        self.run_subdomain_enumeration()
        self.run_ssl_analysis()
        
        # Security analysis (if enabled)
        if self.config.get('security', 'enabled', True):
            self.run_security_analysis()
            
        self.run_osint_collection()
        
        # Generate report
        self.generate_report()
        
    def run_single_target(self, target, scan_type='basic'):
        """Run reconnaissance on a single target"""
        if not self.validate_target(target):
            print(f"‚ùå Invalid target: {target}")
            return False
            
        self.target = target
        self.create_output_directory(target)
        self.setup_logging()
        
        print(f"üéØ Starting reconnaissance on target: {target}")
        print(f"üìã Scan type: {scan_type}")
        
        try:
            if scan_type == 'light':
                self.run_light_scan()
            else:
                self.run_full_scan()
                
            end_time = datetime.now()
            duration = end_time - self.start_time
            print(f"üéâ Reconnaissance completed in {duration}")
            print(f"üìÅ Results saved in: {self.output_dir}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error during reconnaissance: {str(e)}")
            return False
            
    def run_multiple_targets(self, targets_file, scan_type='basic'):
        """Run reconnaissance on multiple targets from file"""
        try:
            with open(targets_file, 'r') as f:
                targets = [line.strip() for line in f if line.strip()]
                
            print(f"üìã Loaded {len(targets)} targets from {targets_file}")
            
            for target in targets:
                print(f"üéØ Processing target: {target}")
                self.run_single_target(target, scan_type)
                
        except FileNotFoundError:
            print(f"‚ùå Targets file not found: {targets_file}")
            return False
        except Exception as e:
            print(f"‚ùå Error processing targets file: {str(e)}")
            return False
            
        return True


def print_banner():
    """Print banner"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  üîç RECON WRAPPER - ALL-IN-ONE                ‚ïë
‚ïë              Comprehensive Reconnaissance Tool                ‚ïë
‚ïë                     Ethical Hacking Edition                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üöÄ Features:
    ‚Ä¢ Port Scanning (Nmap, Masscan, Hybrid)
    ‚Ä¢ Subdomain Enumeration (multi-tool, DNSSEC, zone transfer)
    ‚Ä¢ Web Application Scanning (Nikto, tech stack, CMS, API fuzzing)
    ‚Ä¢ SSL/TLS Analysis (Heartbleed, POODLE, BEAST, DROWN, weak ciphers)
    ‚Ä¢ OSINT Collection (DNS, Wayback Machine, GitHub dorking)
    ‚Ä¢ Screenshot Capture
    ‚Ä¢ Advanced Directory Discovery (gobuster, ffuf, feroxbuster)
    ‚Ä¢ Vulnerability Scanning (CVE mapping, vulners, vulscan)
    ‚Ä¢ Risk Scoring and Assessment (CVSS v3.1)
    ‚Ä¢ Compliance Mapping (OWASP Top 10, NIST, PCI DSS, ISO27001)
    ‚Ä¢ Multi-format Reporting (CSV, Excel, Word, PPTX, PDF)
    ‚Ä¢ Historical Baseline Tracking
    ‚Ä¢ Evidence Collection (screenshots, packets, logs)
    ‚Ä¢ API Endpoint Discovery and Fuzzing
    ‚Ä¢ Technology Stack Detection (Wappalyzer-style)
    ‚Ä¢ Advanced Error Handling and Fallbacks
    ‚Ä¢ Production-ready for authorized security testing

‚ö†Ô∏è  For authorized testing only! Always get permission first.
"""
    print(banner)


def main():
    """Main function"""
    print_banner()
    
    parser = argparse.ArgumentParser(
        description='Comprehensive Reconnaissance Wrapper - All-in-One Version',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  %(prog)s --domain example.com
  %(prog)s --ip 192.168.1.1 --full
  %(prog)s --targets-file targets.txt --fast
  %(prog)s --domain example.com --config custom.json
  %(prog)s --domain internal.company.com --offline --dns-server 10.0.0.53
  %(prog)s --cidr 10.0.0.0/24 --offline --dir-wordlist /usr/share/wordlists/dirs.txt
  %(prog)s --domain example.com --rate-limit 0.5 --dir-threads 5
        '''
    )
    
    # Target options
    target_group = parser.add_mutually_exclusive_group(required=True)
    target_group.add_argument('--domain', help='Single domain target')
    target_group.add_argument('--ip', help='Single IP target')
    target_group.add_argument('--targets-file', help='File containing multiple targets')
    
    # Scan type options
    scan_group = parser.add_mutually_exclusive_group()
    scan_group.add_argument('--fast', action='store_true', help='Run fast/light scan')
    scan_group.add_argument('--full', action='store_true', help='Run comprehensive scan')
    
    # Output options
    parser.add_argument('--config', help='Configuration file path')
    parser.add_argument('--threads', type=int, default=10, help='Number of threads')
    parser.add_argument('--timeout', type=int, default=300, help='Timeout for scans (seconds)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')
    
    # Offline mode and helper options
    parser.add_argument('--offline', action='store_true', help='Run in offline mode (avoid internet-only sources)')
    parser.add_argument('--dns-server', help='Custom DNS server for internal networks (e.g., 10.0.0.53)')
    parser.add_argument('--cidr', help='CIDR range for internal network sweeps (e.g., 10.0.0.0/24)')
    parser.add_argument('--dir-wordlist', help='Custom wordlist for directory brute force (e.g., /path/to/dirs.txt)')
    parser.add_argument('--rate-limit', type=float, default=0, help='Rate limit for directory brute force (seconds between requests, default: 0)')
    parser.add_argument('--dir-threads', type=int, default=10, help='Number of threads for directory brute force (default: 10)')
    
    # Performance and resource management options
    parser.add_argument('--light-mode', action='store_true', help='Reduce resource usage across all modules')
    parser.add_argument('--no-stagger', action='store_true', help='Disable module staggering (run all modules simultaneously)')
    parser.add_argument('--cooldown', type=int, default=5, help='Seconds to wait between heavy modules (default: 5)')
    parser.add_argument('--no-resource-monitor', action='store_true', help='Disable system resource monitoring')
    
    # Security analysis options
    parser.add_argument('--no-security', action='store_true', help='Skip security analysis (SSL/TLS, certificates, vulnerabilities)')
    parser.add_argument('--security-ports', nargs='+', type=int, default=[443, 8443, 9443, 8080, 8008, 8888], 
                       help='Ports to check for SSL/TLS services (default: 443 8443 9443 8080 8008 8888)')
    parser.add_argument('--no-cert-transparency', action='store_true', help='Skip Certificate Transparency log queries')
    parser.add_argument('--security-timeout', type=int, default=30, help='Timeout for security checks (default: 30)')
    
    # Advanced reporting options
    parser.add_argument('--no-advanced-reports', action='store_true', help='Skip advanced reporting (risk assessment, compliance)')
    parser.add_argument('--no-risk-assessment', action='store_true', help='Skip risk scoring and assessment')
    parser.add_argument('--no-compliance', action='store_true', help='Skip compliance framework analysis')
    parser.add_argument('--reports-only', action='store_true', help='Generate only reports (skip scanning)')
    parser.add_argument('--pdf-reports', action='store_true', help='Enable PDF report generation (requires reportlab)')
    parser.add_argument('--csv-export', action='store_true', help='Enable CSV data export')
    
    args = parser.parse_args()
    
    # Initialize recon wrapper
    recon = ReconWrapper()
    
    # Load custom config if provided
    if args.config:
        recon.config.load_config(args.config)
    
    # Set offline mode and helper options from command line
    if args.offline:
        recon.config.set('general', 'offline_mode', True)
        recon.config.set('mode', 'offline', True)
    if args.dns_server:
        recon.config.set('general', 'dns_server', args.dns_server)
        # Also add to DNS servers list
        dns_servers = recon.config.get('dns', 'servers', [])
        if args.dns_server not in dns_servers:
            dns_servers.append(args.dns_server)
            recon.config.set('dns', 'servers', dns_servers)
    if args.cidr:
        recon.config.set('general', 'cidr_range', args.cidr)
    if args.dir_wordlist:
        recon.config.set('general', 'dir_wordlist', args.dir_wordlist)
        recon.config.set('bruteforce', 'dir_wordlist', args.dir_wordlist)
    if args.rate_limit:
        recon.config.set('bruteforce', 'rate_limit', args.rate_limit)
    if args.dir_threads:
        recon.config.set('bruteforce', 'threads', args.dir_threads)
    
    # Set performance options from command line
    if args.light_mode:
        recon.config.set('performance', 'light_mode', True)
        # Adjust other settings for light mode
        recon.config.set('bruteforce', 'threads', min(args.dir_threads or 10, 5))  # Reduce threads
        recon.config.set('subdomains', 'threads', min(recon.config.get('subdomains', 'threads', 50), 20))  # Reduce subdomain threads
        print("üîã Light mode enabled - reduced resource usage")
    if args.no_stagger:
        recon.config.set('performance', 'enable_staggering', False)
        print("‚ö° Module staggering disabled - all modules will run back-to-back")
    if args.cooldown != 5:  # Only set if different from default
        recon.config.set('performance', 'module_cooldown', args.cooldown)
    if args.no_resource_monitor:
        recon.config.set('performance', 'resource_monitoring', False)
        print("üìä System resource monitoring disabled")
    if args.threads:
        recon.config.set('general', 'threads', args.threads)
    if args.timeout:
        recon.config.set('general', 'timeout', args.timeout)
    
    # Set security options from command line
    if args.no_security:
        recon.config.set('security', 'enabled', False)
        print("üö´ Security analysis disabled")
    if args.security_ports != [443, 8443, 9443, 8080, 8008, 8888]:  # Only set if different from default
        recon.config.set('security', 'ports', args.security_ports)
        print(f"üîç Security scan ports: {args.security_ports}")
    if args.no_cert_transparency:
        recon.config.set('security', 'cert_transparency', False)
        print("üìú Certificate Transparency log queries disabled")
    if args.security_timeout != 30:  # Only set if different from default
        recon.config.set('security', 'timeout', args.security_timeout)
    
    # Set advanced reporting options from command line
    if args.no_advanced_reports:
        recon.config.set('reporting', 'advanced_enabled', False)
        print("üìä Advanced reporting disabled")
    if args.no_risk_assessment:
        recon.config.set('reporting', 'generate_risk_assessment', False)
        recon.config.set('reporting', 'risk_scoring', {'enabled': False})
        print("üéØ Risk assessment disabled")
    if args.no_compliance:
        recon.config.set('reporting', 'generate_compliance', False)
        print("üìã Compliance framework analysis disabled")
    if args.pdf_reports:
        recon.config.set('reporting', 'generate_pdf', True)
        print("üìÑ PDF report generation enabled")
    if args.csv_export:
        recon.config.set('reporting', 'generate_csv', True)
        print("üìà CSV data export enabled")
        
    # Determine scan type
    scan_type = 'basic'
    if args.fast:
        scan_type = 'light'
    elif args.full:
        scan_type = 'full'
    
    # Handle reports-only mode
    if args.reports_only:
        print("üìä Reports-only mode: Generating reports from existing data...")
        success = False
        
        if args.domain:
            recon.target = args.domain
            recon.output_dir = Path(f"recon_{args.domain}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            recon.output_dir.mkdir(exist_ok=True)
            recon.setup_logging()
            
            # Try to load existing results
            if recon._load_existing_results():
                recon.generate_report()
                success = True
            else:
                print("‚ùå No existing scan results found. Run a scan first.")
                
        elif args.ip:
            recon.target = args.ip
            recon.output_dir = Path(f"recon_{args.ip.replace('.', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            recon.output_dir.mkdir(exist_ok=True)
            recon.setup_logging()
            
            if recon._load_existing_results():
                recon.generate_report()
                success = True
            else:
                print("‚ùå No existing scan results found. Run a scan first.")
        else:
            print("‚ùå Target required for reports-only mode")
            
    else:
        # Run reconnaissance
        success = False
        
        if args.domain:
            success = recon.run_single_target(args.domain, scan_type)
        elif args.ip:
            success = recon.run_single_target(args.ip, scan_type)
        elif args.targets_file:
            success = recon.run_multiple_targets(args.targets_file, scan_type)
        
    if success:
        print(f"\n‚úÖ Reconnaissance completed successfully!")
        if hasattr(recon, 'output_dir'):
            print(f"üìÅ Results saved in: {recon.output_dir}")
        print("\nüéØ Summary of tools that may be needed:")
        print("   ‚Ä¢ nmap, nikto, sublist3r, assetfinder, subfinder")
        print("   ‚Ä¢ dig, whois, testssl.sh, gowitness")
        print("   ‚Ä¢ Install with: ./install.sh")
    else:
        print(f"\n‚ùå Reconnaissance failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()
